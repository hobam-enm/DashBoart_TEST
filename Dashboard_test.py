# ğŸ“Š Overview / IP ì„±ê³¼ ëŒ€ì‹œë³´ë“œ â€” v2.0 


#region [ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ]
# =====================================================
import re
from typing import List, Dict, Any, Optional 
import time, uuid
import textwrap
import numpy as np
import pandas as pd
import plotly.express as px
from plotly import graph_objects as go
import plotly.io as pio
import streamlit as st
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode
import gspread
from google.oauth2.service_account import Credentials
#endregion


#region [ 1-0. í˜ì´ì§€ ì„¤ì •  ]
# =====================================================
st.set_page_config(
    page_title="(TEST)Drama Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)
#endregion


#region [ 1-1. ì…ì¥ê²Œì´íŠ¸ - URL í† í° ì§€ì† ì¸ì¦ ]
# =====================================================
AUTH_TTL = 12*3600
AUTH_QUERY_KEY = "auth"

def _rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()

@st.cache_resource
def _auth_store():
    return {}

def _now() -> int:
    return int(time.time())

def _issue_token() -> str:
    return uuid.uuid4().hex

def _set_auth_query(token: str):
    try:
        qp = st.query_params
        qp[AUTH_QUERY_KEY] = token
        st.query_params = qp
    except Exception:
        st.experimental_set_query_params(**{AUTH_QUERY_KEY: token})

def _get_auth_query() -> Optional[str]:
    qp = st.query_params
    return qp.get(AUTH_QUERY_KEY)

def _validate_token(token: str) -> bool:
    store = _auth_store()
    ent = store.get(token)
    if not ent:
        return False
    if _now() - ent["ts"] > AUTH_TTL:
        del store[token]
        return False
    return True

def _persist_auth(token: str):
    store = _auth_store()
    store[token] = {"ts": _now()}

def _logout():
    token = _get_auth_query()
    if token:
        store = _auth_store()
        store.pop(token, None)
    try:
        qp = st.query_params
        if AUTH_QUERY_KEY in qp:
            del qp[AUTH_QUERY_KEY]
            st.query_params = qp
    except Exception:
        st.experimental_set_query_params()
    st.session_state.clear()
    _rerun()

def check_password_with_token() -> bool:
    token = _get_auth_query()
    if token and _validate_token(token):
        return True

    with st.sidebar:
        st.markdown("## ğŸ” ë¡œê·¸ì¸")
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="__pwd__")
        login = st.button("ë¡œê·¸ì¸")

    if login:
        secret_pwd = st.secrets.get("DASHBOARD_PASSWORD")
        if secret_pwd and isinstance(pwd, str) and pwd.strip() == str(secret_pwd).strip():
            new_token = _issue_token()
            _persist_auth(new_token)
            _set_auth_query(new_token)
            _rerun()
        else:
            st.sidebar.warning("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return False

if not check_password_with_token():
    st.stop()

#endregion


#region [ 2. ê³µí†µ ìŠ¤íƒ€ì¼ í†µí•© ]
# =====================================================
# [ìˆ˜ì •] 2025-11-13: ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ê°•ì œ ê½‰ ì±„ìš°ê¸° - ìµœì¢…)

st.markdown("""
<style>
/* -------------------------------------------------------------------
   1. [í•µì‹¬] ì‚¬ì´ë“œë°” ê°•ì œ í™•ì¥ (ì—¬ë°± ì œê±°ì˜ ëíŒì™•)
   ------------------------------------------------------------------- */
/* ì‚¬ì´ë“œë°”ì˜ ê°€ì¥ ë°”ê¹¥ ê·¸ë¦‡ */
section[data-testid="stSidebar"] {
    min-width: 200px !important;
}

/* ì‚¬ì´ë“œë°” ë‚´ë¶€ ì»¨í…ì¸  ë˜í¼ (ì´ë†ˆì´ ë²”ì¸ì…ë‹ˆë‹¤) */
section[data-testid="stSidebar"] div[data-testid="stSidebarContent"] {
    padding: 0 !important;       /* ìƒí•˜ì¢Œìš° ì—¬ë°± ì œê±° */
    width: 100% !important;
}

/* ë¸”ë¡ ì»¨í…Œì´ë„ˆ (ì‹¤ì œ ìš”ì†Œë“¤ì´ ë‹´ê¸°ëŠ” ê³³) */
section[data-testid="stSidebar"] .block-container {
    padding-left: 0 !important;
    padding-right: 0 !important;
    padding-top: 1rem !important; /* ìƒë‹¨ ì—¬ë°±ì€ ì¡°ê¸ˆ ë‘  */
    padding-bottom: 2rem !important;
    margin: 0 !important;
    max-width: 100% !important;
}

/* ìˆ˜ì§ ìŠ¤íƒ (ë²„íŠ¼ë“¤ì´ ìŒ“ì´ëŠ” ê³³) ê°„ê²© ì œê±° */
section[data-testid="stSidebar"] div[data-testid="stVerticalBlock"] {
    gap: 0px !important;
}

/* ë²„íŠ¼ ë˜í¼ */
section[data-testid="stSidebar"] .stButton {
    width: 100% !important;
    margin: 0 !important;
    padding: 0 !important;
    border: none !important;
}


/* -------------------------------------------------------------------
   2. [ë””ìì¸] ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ (ë¦¬ìŠ¤íŠ¸í˜•)
   ------------------------------------------------------------------- */
section[data-testid="stSidebar"] .stButton > button {
    width: 100% !important;            /* ê°€ë¡œ ê½‰ ì±„ìš°ê¸° */
    border-radius: 0px !important;     /* ì§ê° ëª¨ì„œë¦¬ */
    margin: 0 !important;              /* ë§ˆì§„ 0 */
    
    /* ë†’ì´ ë° ë‚´ë¶€ ì—¬ë°± ì¡°ì ˆ */
    padding-top: 16px !important;      
    padding-bottom: 16px !important;
    padding-left: 20px !important;     /* ê¸€ì ì™¼ìª½ ì—¬ë°± */
    padding-right: 20px !important;
    
    /* í…Œë‘ë¦¬ ë° ìƒ‰ìƒ */
    border: none !important;
    border-bottom: 1px solid #e0e2e6 !important; /* ì—°í•œ êµ¬ë¶„ì„  */
    background: transparent !important;
    color: #333333 !important;         /* ì§„í•œ íšŒìƒ‰ í…ìŠ¤íŠ¸ */
    font-weight: 600;
    text-align: left;                  /* ê¸€ì ì™¼ìª½ ì •ë ¬ */
    
    box-shadow: none !important;
    transition: background 0.2s, color 0.2s;
}

/* Hover ìƒíƒœ */
section[data-testid="stSidebar"] .stButton > button:hover {
    background: #f5f7f9 !important;    /* ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ì—°í•œ íšŒìƒ‰ */
    color: #000000 !important;
}

/* Active ìƒíƒœ (ì„ íƒëœ ë©”ë‰´) */
section[data-testid="stSidebar"] [data-testid="baseButton-primary"] > button,
section[data-testid="stSidebar"] .stButton > button[kind="primary"] {
    background: #ebf1ff !important;    /* ì„ íƒ ì‹œ ì•„ì£¼ ì—°í•œ íŒŒë‘ ë°°ê²½ */
    color: #0b61ff !important;         /* íŒŒë€ ê¸€ì”¨ */
    border-bottom: 1px solid #0b61ff !important;
    font-weight: 700;
}
/* Active ìƒíƒœ Hover */
section[data-testid="stSidebar"] .stButton > button[kind="primary"]:hover {
    background: #dfe8ff !important;
    color: #0046c7 !important;
}


/* -------------------------------------------------------------------
   3. ê¸°íƒ€ í•„ìˆ˜ ìŠ¤íƒ€ì¼ (ìˆ¨ê¹€ ì²˜ë¦¬ ë“±)
   ------------------------------------------------------------------- */
/* ì‚¬ì´ë“œë°” ë‚´ë¶€ ì¹´ë“œ/ì»¨í…Œì´ë„ˆ íˆ¬ëª…í™” */
section[data-testid="stSidebar"] div[data-testid="stVerticalBlockBorderWrapper"] {
    background: transparent !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
}
section[data-testid="stSidebar"] div[data-testid="stVerticalBlockBorderWrapper"]:hover {
    box-shadow: none !important;
    transform: none !important;
}

/* ë²„íŠ¼ ì•„ì´ì½˜ ìˆ¨ê¹€ */
section[data-testid="stSidebar"] button svg { display: none !important; }

/* ë¼ë²¨/í…ìŠ¤íŠ¸ ì—¬ë°± ì¡°ì • (ë²„íŠ¼ ì™¸ ìš”ì†Œë“¤ì´ ë„ˆë¬´ ë¶™ì§€ ì•Šê²Œ) */
section[data-testid="stSidebar"] .stMarkdown,
section[data-testid="stSidebar"] h1, 
section[data-testid="stSidebar"] h2, 
section[data-testid="stSidebar"] h3 {
    padding-left: 10px; /* íƒ€ì´í‹€ ë“±ì€ ì•½ê°„ ì—¬ë°± ì¤Œ */
    padding-right: 10px;
}
section[data-testid="stSidebar"] div[role="radiogroup"],
section[data-testid="stSidebar"] .stSelectbox, 
section[data-testid="stSidebar"] .stMultiSelect {
    padding-left: 10px; /* í•„í„°ë¥˜ë„ ì—¬ë°± ì¤Œ */
    padding-right: 10px;
}
.sidebar-contact { padding-left: 10px; }


/* -------------------------------------------------------------------
   4. ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ ìŠ¤íƒ€ì¼ (ê¸°ì¡´ ìœ ì§€)
   ------------------------------------------------------------------- */
/* ì•± ë°°ê²½ */
[data-testid="stAppViewContainer"] { background-color: #f8f9fa; }

/* ë©”ì¸ ì¹´ë“œ ìŠ¤íƒ€ì¼ (Hover Floating ì œê±°ë¨) */
div[data-testid="stVerticalBlockBorderWrapper"] {
    background-color: #ffffff;
    border: 1px solid #e9e9e9;
    border-radius: 10px;
    box-shadow: 0 2px 5px rgba(0,0,0,0.03);
    padding: 1.25rem;
    margin-bottom: 1.5rem;
    transition: none !important; /* ì• ë‹ˆë©”ì´ì…˜ ì œê±° */
}
div[data-testid="stVerticalBlockBorderWrapper"]:hover {
    transform: none !important; /* Floating ì œê±° */
    box-shadow: 0 2px 5px rgba(0,0,0,0.03) !important;
}

/* ì˜ˆì™¸ ì²˜ë¦¬ (íˆ¬ëª… ë°°ê²½) */
div[data-testid="stVerticalBlockBorderWrapper"]:has(.kpi-card),
div[data-testid="stVerticalBlockBorderWrapper"]:has(.page-title),
div[data-testid="stVerticalBlockBorderWrapper"]:has(h1),
div[data-testid="stVerticalBlockBorderWrapper"]:has(h2),
div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stSelectbox"]) {
    background: transparent !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
}

/* ê¸°ë³¸ í°íŠ¸/í—¤ë” ì„¤ì • */
html, body, [class*="css"] { font-family: 'Pretendard', sans-serif !important; }
h1, h2, h3 { font-weight: 800; letter-spacing: -0.02em; }

/* KPI Card ìŠ¤íƒ€ì¼ */
.kpi-card {
    background: #ffffff;
    border: 1px solid #e9e9e9;
    border-radius: 10px;
    padding: 20px 15px;
    text-align: center;
    box-shadow: 0 2px 5px rgba(0,0,0,0.03);
    display: flex; flex-direction: column; justify-content: center; height: 100%;
}
.kpi-title { font-size: 15px; font-weight: 600; color: #444; margin-bottom: 10px; }
.kpi-value { font-size: 28px; font-weight: 700; color: #000; line-height: 1.2; }
.kpi-subwrap { margin-top: 10px; font-size: 13px; }
.kpi-subpct { font-weight: 700; }

/* AgGrid */
.ag-theme-streamlit .ag-header { background-color: #f9fafb; font-weight: 700; color: #333; }
.ag-theme-streamlit .ag-root-wrapper { border-radius: 8px; }
.ag-theme-streamlit .ag-row-hover { background-color: #f5f8ff !important; }

</style>
""", unsafe_allow_html=True)
#endregion

#region [ 2.1. ê¸°ë³¸ ì„¤ì • ë° ê³µí†µ ìƒìˆ˜ ]
# =====================================================

# ===== ë„¤ë¹„ê²Œì´ì…˜ ì•„ì´í…œ ì •ì˜ (v2.0) =====
NAV_ITEMS = {
    "Overview": "Overview",
    "IP ì„±ê³¼": "IP ì„±ê³¼ ìì„¸íˆë³´ê¸°",
    "ë°ëª¨ê·¸ë˜í”½": "ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ",
    "ë¹„êµë¶„ì„": "ë¹„êµë¶„ì„",
    "ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ": "ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ",
    "ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸": "ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸",
    "íšŒì°¨ë³„": "íšŒì°¨ ë¹„êµ",
}

# ===== ë°ëª¨ ì»¬ëŸ¼ ìˆœì„œ (í˜ì´ì§€ 2, 3ì—ì„œ ê³µí†µ ì‚¬ìš©) =====
DECADES = ["10ëŒ€","20ëŒ€","30ëŒ€","40ëŒ€","50ëŒ€","60ëŒ€"]
DEMO_COLS_ORDER = [f"{d}ë‚¨ì„±" for d in DECADES] + [f"{d}ì—¬ì„±" for d in DECADES]

# ===== Plotly ê³µí†µ í…Œë§ˆ ì„¤ì • =====
dashboard_theme = go.Layout(
    paper_bgcolor='rgba(0,0,0,0)',
    plot_bgcolor='rgba(0,0,0,0)',
    font=dict(family='sans-serif', size=12, color='#333333'),
    title=dict(font=dict(size=16, color="#111"), x=0.05),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='right',
        x=1,
        bgcolor='rgba(0,0,0,0)'
    ),
    margin=dict(l=20, r=20, t=50, b=20),
    xaxis=dict(
        showgrid=False, 
        zeroline=True, 
        zerolinecolor='#e0e0e0', 
        zerolinewidth=1
    ),
    yaxis=dict(
        showgrid=True, 
        gridcolor='#f0f0f0',
        zeroline=True, 
        zerolinecolor='#e0e0e0'
    ),
)
pio.templates['dashboard_theme'] = go.layout.Template(layout=dashboard_theme)
pio.templates.default = 'dashboard_theme'
# =====================================================
#endregion


#region [ 3. ê³µí†µ í•¨ìˆ˜: ë°ì´í„° ë¡œë“œ / ìœ í‹¸ë¦¬í‹° ]
# =====================================================

# ===== 3.1. ë°ì´í„° ë¡œë“œ (gspread) =====
# [ìˆ˜ì •] read_csv -> gspread + ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ë°©ì‹ìœ¼ë¡œ ë³µêµ¬
@st.cache_data(ttl=600)
def load_data() -> pd.DataFrame:
    """
    [ìˆ˜ì •] Streamlit Secretsì™€ gspreadë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ê³µê°œ Google Sheetì—ì„œ ë°ì´í„°ë¥¼ ì¸ì¦í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤.
    st.secretsì— 'gcp_service_account', 'SHEET_ID', 'SHEET_NAME'ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    # --- 1. Google Sheets ì¸ì¦ ---
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    
    try:
        creds_info = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        client = gspread.authorize(creds)

        # --- 2. ë°ì´í„° ë¡œë“œ ---
        sheet_id = st.secrets["SHEET_ID"]
        # [ìˆ˜ì •] í”¼ë“œë°± 1ë²ˆ ë°˜ì˜: GID ëŒ€ì‹  ëª…í™•í•œ SHEET_NAME í‚¤ë¥¼ ì‚¬ìš©
        worksheet_name = st.secrets["SHEET_NAME"] 
        
        spreadsheet = client.open_by_key(sheet_id)
        worksheet = spreadsheet.worksheet(worksheet_name)
        
        data = worksheet.get_all_records() 
        df = pd.DataFrame(data)

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"Streamlit Secretsì˜ SHEET_NAME ê°’ ('{worksheet_name}')ì— í•´ë‹¹í•˜ëŠ” ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    except KeyError as e:
        st.error(f"Streamlit Secretsì— í•„ìš”í•œ í‚¤({e})ê°€ ì—†ìŠµë‹ˆë‹¤. TOML ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

    # --- 3. ë°ì´í„° ì „ì²˜ë¦¬ (ì›ë³¸ ì½”ë“œì™€ ë™ì¼) ---
    if "ì£¼ì°¨ì‹œì‘ì¼" in df.columns:
        df["ì£¼ì°¨ì‹œì‘ì¼"] = pd.to_datetime(
            df["ì£¼ì°¨ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", # gspreadëŠ” ì´ í˜•ì‹ì„ ì‚¬ìš©
            errors="coerce"
        )
    if "ë°©ì˜ì‹œì‘ì¼" in df.columns:
        df["ë°©ì˜ì‹œì‘ì¼"] = pd.to_datetime(
            df["ë°©ì˜ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", # gspreadëŠ” ì´ í˜•ì‹ì„ ì‚¬ìš©
            errors="coerce"
        )

    if "value" in df.columns:
        v = df["value"].astype(str).str.replace(",", "", regex=False).str.replace("%", "", regex=False)
        df["value"] = pd.to_numeric(v, errors="coerce").fillna(0)

    for c in ["IP", "í¸ì„±", "ì§€í‘œêµ¬ë¶„", "ë§¤ì²´", "ë°ëª¨", "metric", "íšŒì°¨", "ì£¼ì°¨"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip() # gspreadëŠ” .fillna('') ë¶ˆí•„ìš”

    if "íšŒì°¨" in df.columns:
        df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    else:
        df["íšŒì°¨_numeric"] = pd.NA

    return df

# ===== 3.2. UI / í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜ =====

def fmt(v, digits=3, intlike=False):
    """
    ìˆ«ì í¬ë§·íŒ… í—¬í¼ (Noneì´ë‚˜ NaNì€ 'â€“'ë¡œ í‘œì‹œ)
    """
    if v is None or pd.isna(v):
        return "â€“"
    return f"{v:,.0f}" if intlike else f"{v:.{digits}f}"

def kpi(col, title, value):
    """
    Streamlit ì»¬ëŸ¼ ë‚´ì— KPI ì¹´ë“œë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. (CSS .kpi-card í•„ìš”)
    """
    with col:
        st.markdown(
            f'<div class="kpi-card"><div class="kpi-title">{title}</div>'
            f'<div class="kpi-value">{value}</div></div>',
            unsafe_allow_html=True
        )

def render_gradient_title(main_text: str, emoji: str = "ğŸ¬"):
    """
    ì‚¬ì´ë“œë°”ìš© ê·¸ë¼ë””ì–¸íŠ¸ íƒ€ì´í‹€ì„ ë Œë”ë§í•©ë‹ˆë‹¤. (CSS .page-title-wrap í•„ìš”)
    """
    st.markdown(
        f"""
        <div class="page-title-wrap">
          <span class="page-title-emoji">{emoji}</span>
          <span class="page-title-main">{main_text}</span>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ===== 3.3. í˜ì´ì§€ ë¼ìš°íŒ… / ë°ì´í„° í—¬í¼ í•¨ìˆ˜ =====

def get_current_page_default(default="Overview"):
    """
    URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°(?page=...)ì—ì„œ í˜„ì¬ í˜ì´ì§€ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    """
    try:
        qp = st.query_params
        p = qp.get("page", None)
        if p is None:
            return default
        return p if isinstance(p, str) else p[0]
    except Exception:
        qs = st.experimental_get_query_params()
        return (qs.get("page", [default])[0])

def _set_page_query_param(page_key: str):
    """
    URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì— page í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (ë¦¬ë¡œë“œ ì—†ìŒ)
    """
    try:
        qp = st.query_params
        qp["page"] = page_key
        st.query_params = qp
    except Exception:
        st.experimental_set_query_params(page=page_key)

def get_episode_options(df: pd.DataFrame) -> List[str]:
    """ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì°¨ ëª©ë¡ (ë¬¸ìì—´, '00' ì œì™¸, 'ì°¨'/'í™”' ì œê±°)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    valid_options = []
    if "íšŒì°¨_numeric" in df.columns:
        unique_episodes_num = sorted([
            int(ep) for ep in df["íšŒì°¨_numeric"].dropna().unique() if ep > 0
        ])
        if unique_episodes_num:
            max_ep_num = unique_episodes_num[-1]
            for ep_num in unique_episodes_num: valid_options.append(str(ep_num))
            last_ep_str_num = str(max_ep_num)
            if last_ep_str_num in valid_options and valid_options[-1] != last_ep_str_num:
                 valid_options.remove(last_ep_str_num); valid_options.append(last_ep_str_num)
            if len(valid_options) > 0 and "(ë§ˆì§€ë§‰í™”)" not in valid_options[-1]:
                 valid_options[-1] = f"{valid_options[-1]} (ë§ˆì§€ë§‰í™”)"
            return valid_options
        else: return []
    elif "íšŒì°¨" in df.columns:
        raw_options = sorted(df["íšŒì°¨"].dropna().unique())
        for opt in raw_options:
            if not opt.startswith("00"):
                cleaned_opt = re.sub(r"[í™”ì°¨]", "", opt)
                if cleaned_opt.isdigit() and int(cleaned_opt) > 0: 
                    valid_options.append(cleaned_opt)
        return sorted(list(set(valid_options)), key=lambda x: int(x) if x.isdigit() else float('inf')) 
    else: return []

# [ì‹ ê·œ] í”¼ë“œë°± 3ë²ˆ ë°˜ì˜: ì¡°íšŒìˆ˜ í•„í„° ë¡œì§ í†µí•©
def _get_view_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    'ì¡°íšŒìˆ˜' metricë§Œ í•„í„°ë§í•˜ê³ , ìœ íŠœë¸Œ PGC/UGC ê·œì¹™ì„ ì ìš©í•˜ëŠ” ê³µí†µ ìœ í‹¸.
    """
    sub = df[df["metric"] == "ì¡°íšŒìˆ˜"].copy()
    if sub.empty:
        return sub
        
    if "ë§¤ì²´" in sub.columns and "ì„¸ë¶€ì†ì„±1" in sub.columns:
        yt_mask = (sub["ë§¤ì²´"] == "ìœ íŠœë¸Œ")
        attr_mask = sub["ì„¸ë¶€ì†ì„±1"].isin(["PGC", "UGC"])
        sub = sub[~yt_mask | (yt_mask & attr_mask)]
    
    return sub
#endregion


#region [ 4. ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ ]
# =====================================================
current_page = get_current_page_default("Overview")
st.session_state["page"] = current_page

with st.sidebar:

    render_gradient_title("ë“œë¼ë§ˆ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", emoji="")
    st.markdown(
        "<p class='sidebar-contact' style='font-size:12px; color:gray;'>ë¬¸ì˜ : ë¯¸ë””ì–´)ë””ì§€í„¸ë§ˆì¼€íŒ…íŒ€ ë°ì´í„°íŒŒíŠ¸</p>",
        unsafe_allow_html=True
    )
    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)
    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)

    for key, label in NAV_ITEMS.items():
        is_active = (current_page == key)
        
        wrapper_cls = "nav-active" if is_active else "nav-inactive"
        st.markdown(f'<div class="{wrapper_cls}">', unsafe_allow_html=True)

        clicked = st.button(
            label,
            key=f"navbtn__{key}",
            use_container_width=True,
            type=("primary" if is_active else "secondary")
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        if clicked and not is_active:
            st.session_state["page"] = key
            _set_page_query_param(key)
            _rerun()
#endregion


#region [ 5. ê³µí†µ ì§‘ê³„ ìœ í‹¸: KPI ê³„ì‚° ]
# =====================================================
# [ìˆ˜ì •] ê¸°ì¡´ Region 6

def _episode_col(df: pd.DataFrame) -> str:
    """ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” íšŒì°¨ ìˆ«ì ì»¬ëŸ¼ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return "íšŒì°¨_numeric" if "íšŒì°¨_numeric" in df.columns else ("íšŒì°¨_num" if "íšŒì°¨_num" in df.columns else "íšŒì°¨")

def mean_of_ip_episode_sum(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    if sub.empty:
        return None
    ep_col = _episode_col(sub)
    sub = sub.dropna(subset=[ep_col]).copy()
    
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
    per_ip_mean = ep_sum.groupby("IP")["value"].mean()
    return float(per_ip_mean.mean()) if not per_ip_mean.empty else None


def mean_of_ip_episode_mean(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    if sub.empty:
        return None
    ep_col = _episode_col(sub)
    sub = sub.dropna(subset=[ep_col]).copy()
    
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
    per_ip_mean = ep_mean.groupby("IP")["value"].mean()
    return float(per_ip_mean.mean()) if not per_ip_mean.empty else None


def mean_of_ip_sums(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    
    # [ìˆ˜ì •] PGC/UGC í•„í„° ë¡œì§ì„ _get_view_data í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (í”¼ë“œë°± 3ë²ˆ)
    if metric_name == "ì¡°íšŒìˆ˜":
        sub = _get_view_data(df) # [3. ê³µí†µ í•¨ìˆ˜]
    else:
        sub = df[df["metric"] == metric_name].copy()

    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    
    if sub.empty:
        return None
        
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    per_ip_sum = sub.groupby("IP")["value"].sum()
    return float(per_ip_sum.mean()) if not per_ip_sum.empty else None


#endregion


#region [ 6. ê³µí†µ ì§‘ê³„ ìœ í‹¸: ë°ëª¨  ]
# =====================================================
# [ìˆ˜ì •] ê¸°ì¡´ Region 7

# ===== 6.1. ë°ëª¨ ë¬¸ìì—´ íŒŒì‹± ìœ í‹¸ =====
def _gender_from_demo(s: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„(ë‚¨/ì—¬/ê¸°íƒ€)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]): return "ë‚¨"
    return "ê¸°íƒ€"

def gender_from_demo(s: str):
    """ 'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„ (ë‚¨/ì—¬) ì¶”ì¶œ, ê·¸ ì™¸ None (í˜ì´ì§€ 3ìš©) """
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]):     return "ë‚¨"
    return None

def _to_decade_label(x: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì—°ë ¹ëŒ€(10ëŒ€, 20ëŒ€...)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(x))
    if not m: return "ê¸°íƒ€"
    n = int(m.group(0))
    return f"{(n//10)*10}ëŒ€"

def _decade_label_clamped(x: str):
    """ 10ëŒ€~60ëŒ€ ë²”ìœ„ë¡œ ì—°ë ¹ëŒ€ ë¼ë²¨ ìƒì„±, ê·¸ ì™¸ëŠ” None (í˜ì´ì§€ 2, 3ìš©) """
    m = re.search(r"\d+", str(x))
    if not m: return None
    n = int(m.group(0))
    n = max(10, min(60, (n // 10) * 10))
    return f"{n}ëŒ€"

def _decade_key(s: str):
    """ì—°ë ¹ëŒ€ ì •ë ¬ì„ ìœ„í•œ ìˆ«ì í‚¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(s))
    return int(m.group(0)) if m else 999

def _fmt_ep(n):
    """ íšŒì°¨ ë²ˆí˜¸ë¥¼ '01í™”' í˜•íƒœë¡œ í¬ë§·íŒ… (í˜ì´ì§€ 2, 3ìš©) """
    try:
        return f"{int(n):02d}í™”"
    except Exception:
        return str(n)

# ===== 6.2. í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ë Œë”ë§ (í˜ì´ì§€ 1, 2) =====
COLOR_MALE = "#2a61cc"
COLOR_FEMALE = "#d93636"

def render_gender_pyramid(container, title: str, df_src: pd.DataFrame, height: int = 260):

    if df_src.empty:
        container.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_demo = df_src.copy()
    df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
    df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
    df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & df_demo["ì—°ë ¹ëŒ€_ëŒ€"].notna()]

    if df_demo.empty:
        container.info("í‘œì‹œí•  ë°ëª¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    order = sorted(df_demo["ì—°ë ¹ëŒ€_ëŒ€"].unique().tolist(), key=_decade_key)

    pvt = (
        df_demo.groupby(["ì—°ë ¹ëŒ€_ëŒ€","ì„±ë³„"])["value"]
               .sum()
               .unstack("ì„±ë³„")
               .reindex(order)
               .fillna(0)
    )

    male = -pvt.get("ë‚¨", pd.Series(0, index=pvt.index))
    female = pvt.get("ì—¬", pd.Series(0, index=pvt.index))

    max_abs = float(max(male.abs().max(), female.max()) or 1)

    male_share = (male.abs() / male.abs().sum() * 100) if male.abs().sum() else male.abs()
    female_share = (female / female.sum() * 100) if female.sum() else female

    male_text = [f"{v:.1f}%" for v in male_share]
    female_text = [f"{v:.1f}%" for v in female_share]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=pvt.index, x=male, name="ë‚¨",
        orientation="h",
        marker_color=COLOR_MALE,
        text=male_text,
        textposition="inside",
        insidetextanchor="end",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ë‚¨ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([male.abs(), male_share])
    ))
    fig.add_trace(go.Bar(
        y=pvt.index, x=female, name="ì—¬",
        orientation="h",
        marker_color=COLOR_FEMALE,
        text=female_text,
        textposition="inside",
        insidetextanchor="start",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ì—¬ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([female, female_share])
    ))

    fig.update_layout(
        barmode="overlay",
        height=height,
        margin=dict(l=8, r=8, t=48, b=8),
        legend_title=None,
        bargap=0.15,
        bargroupgap=0.05,
    )
    # í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ì „ìš© ë¡œì»¬ ì œëª© (ì „ì—­ í…Œë§ˆ ì˜¤ë²„ë¼ì´ë“œ)
    fig.update_layout(
        title=dict(
            text=title,
            x=0.0, xanchor="left",
            y=0.98, yanchor="top",
            font=dict(size=14)
        )
    )
    fig.update_yaxes(
        categoryorder="array",
        categoryarray=order,
        title=None,
        tickfont=dict(size=12),
        fixedrange=True
    )
    fig.update_xaxes(
        range=[-max_abs*1.05, max_abs*1.05],
        title=None,
        showticklabels=False,
        showgrid=False,
        zeroline=True,
        zerolinewidth=1,
        zerolinecolor="#888",
        fixedrange=True
    )

    container.plotly_chart(fig, use_container_width=True,
                           config={"scrollZoom": False, "staticPlot": False, "displayModeBar": False})

# ===== 6.3. ê·¸ë£¹ ë°ëª¨ í‰ê·  ê³„ì‚° (í˜ì´ì§€ 3) =====
def get_avg_demo_pop_by_episode(df_src: pd.DataFrame, medias: List[str]) -> pd.DataFrame:
    """
    ì—¬ëŸ¬ IPê°€ í¬í•¨ëœ df_srcì—ì„œ, íšŒì°¨ë³„/ë°ëª¨ë³„ *í‰ê· * ì‹œì²­ììˆ˜(ì‹œì²­ì¸êµ¬)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    sub = df_src[
        (df_src["metric"] == "ì‹œì²­ì¸êµ¬") &
        (df_src["ë°ëª¨"].notna()) &
        (df_src["ë§¤ì²´"].isin(medias))
    ].copy()

    if sub.empty:
        return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(gender_from_demo)
    sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)
    sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()

    if "íšŒì°¨_numeric" not in sub.columns:
         sub["íšŒì°¨_numeric"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        
    sub = sub.dropna(subset=["íšŒì°¨_numeric"])
    sub["íšŒì°¨_num"] = sub["íšŒì°¨_numeric"].astype(int)

    sub["ë¼ë²¨"] = sub.apply(lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)

    ip_ep_demo_sum = sub.groupby(["IP", "íšŒì°¨_num", "ë¼ë²¨"])["value"].sum().reset_index()
    ep_demo_mean = ip_ep_demo_sum.groupby(["íšŒì°¨_num", "ë¼ë²¨"])["value"].mean().reset_index()

    pvt = ep_demo_mean.pivot_table(index="íšŒì°¨_num", columns="ë¼ë²¨", values="value").fillna(0)

    for c in DEMO_COLS_ORDER:
        if c not in pvt.columns:
            pvt[c] = 0
    pvt = pvt[DEMO_COLS_ORDER].sort_index()

    pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))
    return pvt.reset_index(drop=True)
#endregion


#region [ 7. í˜ì´ì§€ 1: Overview ]
# =====================================================
# [ìˆ˜ì •] KPI/ì°¨íŠ¸/í…Œì´ë¸”: í‹°ë¹™ VODë¥¼ 'ë‹¹ì¼'ê³¼ 'ì£¼ê°„'ìœ¼ë¡œ ë¶„ë¦¬ (2025-11-12)
def render_overview():
    df = load_data() # [3. ê³µí†µ í•¨ìˆ˜]
  
    # --- í˜ì´ì§€ ì „ìš© í•„í„° ---   
    filter_cols = st.columns(4)
    
    with filter_cols[0]:
        st.markdown("### ğŸ“Š Overview")
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ / íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì‹¤ì‹œê°„ ì‹œì²­ UV
        - **í‹°ë¹™ ë‹¹ì¼ VOD** `íšŒì°¨í‰ê· `: (êµ¬ í‹°ë¹™ í€µ) ë³¸ë°©ì†¡ ë‹¹ì¼ VOD UV
        - **í‹°ë¹™ ì£¼ê°„ VOD** `íšŒì°¨í‰ê· `: íšŒì°¨ ë°©ì˜ì¼ë¶€í„° +6ì¼ê¹Œì§€ì˜ 7ì¼ê°„ VOD UV
        - **ë””ì§€í„¸ ì¡°íšŒ/ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•©
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ í‰ê· 
        - **ì•µì»¤ë“œë¼ë§ˆ ê¸°ì¤€**: í† ì¼ 3%â†‘, ì›”í™” 2%â†‘
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)


    with filter_cols[1]:
        prog_sel = st.multiselect(
            "í¸ì„±", 
            sorted(df["í¸ì„±"].dropna().unique().tolist()),
            placeholder="í¸ì„± ì„ íƒ",
            label_visibility="collapsed"
        )

    if "ë°©ì˜ì‹œì‘ì¼" in df.columns and df["ë°©ì˜ì‹œì‘ì¼"].notna().any():
        date_col_for_filter = "ë°©ì˜ì‹œì‘ì¼"
    else:
        date_col_for_filter = "ì£¼ì°¨ì‹œì‘ì¼"
        
    date_series = df[date_col_for_filter].dropna()
    if not date_series.empty:
        all_years = sorted(date_series.dt.year.unique().tolist(), reverse=True)
        all_months = sorted(date_series.dt.month.unique().tolist())
        
        with filter_cols[2]:
            year_sel = st.multiselect(
                "ì—°ë„", 
                all_years, 
                placeholder="ì—°ë„ ì„ íƒ",
                label_visibility="collapsed"
            )
        with filter_cols[3]:
            month_sel = st.multiselect(
                "ì›”", 
                all_months, 
                placeholder="ì›” ì„ íƒ",
                label_visibility="collapsed"
            )
    else:
        year_sel = None
        month_sel = None

    # --- í•„í„° ì ìš© ---
    f = df.copy()
    if prog_sel:
        f = f[f["í¸ì„±"].isin(prog_sel)]
    if year_sel and date_col_for_filter in f.columns:
        f = f[f[date_col_for_filter].dt.year.isin(year_sel)]
    if month_sel and date_col_for_filter in f.columns:
        f = f[f[date_col_for_filter].dt.month.isin(month_sel)]

    # --- ìš”ì•½ì¹´ë“œ ê³„ì‚° ì„œë¸Œí•¨ìˆ˜ (KPI ê³µí†µ ìœ í‹¸ ì‚¬ìš©) ---
    def avg_of_ip_means(metric_name: str):
        return mean_of_ip_episode_mean(f, metric_name) # [5. ê³µí†µ í•¨ìˆ˜]

    def avg_of_ip_tving_epSum_mean(media_name: str):
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", [media_name]) # [5. ê³µí†µ í•¨ìˆ˜]

    # [ìˆ˜ì •] VOD ë¶„ë¦¬: ë‹¹ì¼ VOD(Quick)
    def avg_of_ip_tving_quick():
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])

    # [ìˆ˜ì •] VOD ë¶„ë¦¬: ì£¼ê°„ VOD (ìˆœìˆ˜ VOD)
    def avg_of_ip_tving_vod_weekly():
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])

    def avg_of_ip_sums(metric_name: str):
        return mean_of_ip_sums(f, metric_name) # [5. ê³µí†µ í•¨ìˆ˜]

    def count_ip_with_min1(metric_name: str):
        sub = f[f["metric"] == metric_name]
        if sub.empty: return 0
        ip_min = sub.groupby("IP")["value"].min()
        return (ip_min == 1).sum()

    def count_anchor_dramas():
        sub = f[f["metric"]=="Tì‹œì²­ë¥ "].groupby(["IP","í¸ì„±"])["value"].mean().reset_index()
        mon_tue = sub[(sub["í¸ì„±"]=="ì›”í™”") & (sub["value"]>2)].shape[0]
        sat_sun = sub[(sub["í¸ì„±"]=="í† ì¼") & (sub["value"]>3)].shape[0]
        return mon_tue + sat_sun

    # --- ìš”ì•½ ì¹´ë“œ ---
    st.caption('â–¶ IPë³„ í‰ê· ')

    # [ìˆ˜ì •] KPI ì¹´ë“œ 4ì—´ -> 5ì—´ë¡œ í™•ì¥ (Quick, VOD ë¶„ë¦¬)
    c1, c2, c3, c4, c5 = st.columns(5)
    st.markdown("<div style='margin-top:20px'></div>", unsafe_allow_html=True)
    c6, c7, c8, c9, c10 = st.columns(5)

    t_rating   = avg_of_ip_means("Tì‹œì²­ë¥ ")
    h_rating   = avg_of_ip_means("Hì‹œì²­ë¥ ")
    tving_live = avg_of_ip_tving_epSum_mean("TVING LIVE")
    tving_quick= avg_of_ip_tving_quick()        # [ì¶”ê°€]
    tving_vod  = avg_of_ip_tving_vod_weekly()   # [ìˆ˜ì •]

    digital_view = avg_of_ip_sums("ì¡°íšŒìˆ˜")
    digital_buzz = avg_of_ip_sums("ì–¸ê¸‰ëŸ‰")
    f_score      = avg_of_ip_means("F_Score")
    fundex_top1 = count_ip_with_min1("F_Total")
    anchor_total = count_anchor_dramas()

    kpi(c1, "ğŸ¯ íƒ€ê¹ƒ ì‹œì²­ë¥ ", fmt(t_rating, digits=3))
    kpi(c2, "ğŸ  ê°€êµ¬ ì‹œì²­ë¥ ", fmt(h_rating, digits=3))
    kpi(c3, "ğŸ“º í‹°ë¹™ LIVE", fmt(tving_live, intlike=True))
    kpi(c4, "âš¡ í‹°ë¹™ ë‹¹ì¼ VOD", fmt(tving_quick, intlike=True)) # [ì¶”ê°€]
    kpi(c5, "â–¶ï¸ í‹°ë¹™ ì£¼ê°„ VOD", fmt(tving_vod, intlike=True))   # [ìˆ˜ì •]
    
    kpi(c6, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", fmt(digital_view, intlike=True))
    kpi(c7, "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", fmt(digital_buzz, intlike=True))
    kpi(c8, "ğŸ”¥ í™”ì œì„± ì ìˆ˜",  fmt(f_score, intlike=True))
    kpi(c9, "ğŸ¥‡ í€ë±ìŠ¤ 1ìœ„", f"{fundex_top1}ì‘í’ˆ")
    kpi(c10, "âš“ ì•µì»¤ë“œë¼ë§ˆ", f"{anchor_total}ì‘í’ˆ")

    st.divider()

    # --- ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ (Stacked Bar) ---
    # [ìˆ˜ì •] ì°¨íŠ¸ë„ KPIì™€ ë™ì¼í•˜ê²Œ Quick/VOD ë¶„ë¦¬
    df_trend = f[f["metric"]=="ì‹œì²­ì¸êµ¬"].copy()
    if not df_trend.empty:
        tv_weekly = df_trend[df_trend["ë§¤ì²´"]=="TV"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
        
        tving_live_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING LIVE"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
        tving_quick_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING QUICK"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum() # [ì¶”ê°€]
        tving_vod_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING VOD"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()     # [ìˆ˜ì •]

        all_dates = sorted(list(
            set(tv_weekly.index) | set(tving_live_weekly.index) | 
            set(tving_quick_weekly.index) | set(tving_vod_weekly.index)
        ))
        
        if all_dates:
            df_bar = pd.DataFrame({"ì£¼ì°¨ì‹œì‘ì¼": all_dates})
            df_bar["TV ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tv_weekly).fillna(0)
            df_bar["í‹°ë¹™ ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_live_weekly).fillna(0)
            df_bar["í‹°ë¹™ ë‹¹ì¼"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_quick_weekly).fillna(0) # [ì¶”ê°€]
            df_bar["í‹°ë¹™ ì£¼ê°„"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_vod_weekly).fillna(0)   # [ìˆ˜ì •]

            df_long = df_bar.melt(id_vars="ì£¼ì°¨ì‹œì‘ì¼",
                                  value_vars=["TV ë³¸ë°©","í‹°ë¹™ ë³¸ë°©","í‹°ë¹™ ë‹¹ì¼","í‹°ë¹™ ì£¼ê°„"],
                                  var_name="êµ¬ë¶„", value_name="ì‹œì²­ììˆ˜")

            def fmt_kor_hover(x):
                if pd.isna(x) or x == 0: return "0"
                val = int(round(x / 10000))
                uk = val // 10000
                man = val % 10000
                if uk > 0: return f"{uk}ì–µ{man:04d}ë§Œ"
                else: return f"{man}ë§Œ"

            df_long["hover_txt"] = df_long["ì‹œì²­ììˆ˜"].apply(fmt_kor_hover)

            fig = px.bar(
                df_long, x="ì£¼ì°¨ì‹œì‘ì¼", y="ì‹œì²­ììˆ˜", color="êµ¬ë¶„", text="ì‹œì²­ììˆ˜",
                title="ğŸ“Š ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜",
                color_discrete_map={
                    "TV ë³¸ë°©": "#1f77b4",
                    "í‹°ë¹™ ë³¸ë°©": "#d62728",
                    "í‹°ë¹™ ë‹¹ì¼": "#64b5f6", # Page 2 Quick Color
                    "í‹°ë¹™ ì£¼ê°„": "#ff7f7f"  # Light Red for VOD (or modify to match theme)
                },
                custom_data=["hover_txt"]
            )
            fig.update_layout(
                xaxis_title=None, yaxis_title=None,
                barmode="stack", legend_title="êµ¬ë¶„",
                title_font=dict(size=20)
            )
            fig.update_traces(
                texttemplate='%{text:,.0f}', 
                textposition="inside",
                hovertemplate="<b>%{x}</b><br>%{data.name}: %{customdata[0]}<extra></extra>"
            )
            
            c_trend, = st.columns(1)
            with c_trend:
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


    st.divider()

    # --- ì£¼ìš”ì‘í’ˆ í…Œì´ë¸” (AgGrid) ---
    st.markdown("#### ğŸ¬ ì „ì²´ ì‘í’ˆ RAW")

    def calculate_overview_performance(df):
        all_ips = df["IP"].unique()
        if len(all_ips) == 0: return pd.DataFrame()

        ep_col = _episode_col(df) # [5. ê³µí†µ í•¨ìˆ˜]
        
        def _get_mean_of_ep_sums(df, metric_name, media_list=None):
            sub = df[df["metric"] == metric_name]
            if media_list: sub = sub[sub["ë§¤ì²´"].isin(media_list)]
            if sub.empty or ep_col not in sub.columns: 
                return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            sub = sub.dropna(subset=[ep_col]).copy()
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value"])
            if sub.empty: return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
            per_ip_mean = ep_sum.groupby("IP")["value"].mean()
            return per_ip_mean.reindex(all_ips).fillna(0) 

        def _get_mean_of_ep_means(df, metric_name):
            sub = df[df["metric"] == metric_name]
            if sub.empty or ep_col not in sub.columns:
                return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            sub = sub.dropna(subset=[ep_col]).copy()
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value"])
            if sub.empty: return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
            per_ip_mean = ep_mean.groupby("IP")["value"].mean()
            return per_ip_mean.reindex(all_ips).fillna(0)
        
        aggs = {}
        aggs["íƒ€ê¹ƒì‹œì²­ë¥ "] = _get_mean_of_ep_means(df, "Tì‹œì²­ë¥ ")
        aggs["ê°€êµ¬ì‹œì²­ë¥ "] = _get_mean_of_ep_means(df, "Hì‹œì²­ë¥ ")
        aggs["í‹°ë¹™LIVE"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
        
        # [ìˆ˜ì •] í…Œì´ë¸” ì»¬ëŸ¼ë„ ë¶„ë¦¬
        aggs["í‹°ë¹™ë‹¹ì¼"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
        aggs["í‹°ë¹™ì£¼ê°„"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING VOD"]) 
        
        aggs["ë””ì§€í„¸ì–¸ê¸‰ëŸ‰"] = df[df["metric"] == "ì–¸ê¸‰ëŸ‰"].groupby("IP")["value"].sum().reindex(all_ips).fillna(0)
        aggs["ë””ì§€í„¸ì¡°íšŒìˆ˜"] = _get_view_data(df).groupby("IP")["value"].sum().reindex(all_ips).fillna(0)
        aggs["í™”ì œì„±ìˆœìœ„"] = df[df["metric"] == "F_Total"].groupby("IP")["value"].min().reindex(all_ips).fillna(0)
        aggs["í™”ì œì„±ì ìˆ˜"] = _get_mean_of_ep_sums(df, "F_Score", media_list=None)

        df_perf = pd.DataFrame(aggs).fillna(0).reset_index().rename(columns={"index": "IP"})
        return df_perf.sort_values("íƒ€ê¹ƒì‹œì²­ë¥ ", ascending=False)

    df_perf = calculate_overview_performance(f)

    fmt_fixed3 = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      return Number(params.value).toFixed(3);
    }""")
    fmt_thousands = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      return Math.round(params.value).toLocaleString();
    }""")
    fmt_rank = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      if (params.value == 0) return 'â€“';
      return Math.round(params.value) + 'ìœ„';
    }""")

    gb = GridOptionsBuilder.from_dataframe(df_perf)
    gb.configure_default_column(
        sortable=True, resizable=True, filter=False,
        cellStyle={'textAlign': 'center'},
        headerClass='centered-header'
    )
    gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
    
    gb.configure_column('IP', header_name='IP', cellStyle={'textAlign':'left'}) 
    gb.configure_column('íƒ€ê¹ƒì‹œì²­ë¥ ', valueFormatter=fmt_fixed3, sort='desc')
    gb.configure_column('ê°€êµ¬ì‹œì²­ë¥ ', valueFormatter=fmt_fixed3)
    gb.configure_column('í‹°ë¹™LIVE', valueFormatter=fmt_thousands)
    # [ìˆ˜ì •] ì»¬ëŸ¼ ë¶„ë¦¬ ë°˜ì˜
    gb.configure_column('í‹°ë¹™ë‹¹ì¼', header_name="í‹°ë¹™ ë‹¹ì¼ VOD", valueFormatter=fmt_thousands)
    gb.configure_column('í‹°ë¹™ì£¼ê°„', header_name="í‹°ë¹™ ì£¼ê°„ VOD", valueFormatter=fmt_thousands)
    
    gb.configure_column('ë””ì§€í„¸ì¡°íšŒìˆ˜', valueFormatter=fmt_thousands)
    gb.configure_column('ë””ì§€í„¸ì–¸ê¸‰ëŸ‰', valueFormatter=fmt_thousands)
    gb.configure_column('í™”ì œì„±ìˆœìœ„', valueFormatter=fmt_rank)
    gb.configure_column('í™”ì œì„±ì ìˆ˜', valueFormatter=fmt_thousands)

    grid_options = gb.build()

    AgGrid(
        df_perf,
        gridOptions=grid_options,
        theme="streamlit",
        height=300,
        fit_columns_on_grid_load=True, 
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )
#endregion


#region [ 8. í˜ì´ì§€ 2: IP ì„±ê³¼ ìì„¸íˆë³´ê¸° ]
# =====================================================
# [ìˆ˜ì •] KPI 2ì—´ ë”ë¯¸ì¹´ë“œ ì¶”ê°€, TVING ì°¨íŠ¸ ë ˆì´ë¸”/ì œëª© ì •ë¦¬, AgGrid ë†’ì´ ìë™í™” (2025-11-12)
def render_ip_detail():

    df_full = load_data() # [3. ê³µí†µ í•¨ìˆ˜]

    filter_cols = st.columns([3, 2, 2])

    with filter_cols[0]:
        st.markdown("<div class='page-title'>ğŸ“ˆ IP ì„±ê³¼ ìì„¸íˆë³´ê¸°</div>", unsafe_allow_html=True)
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ / íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì‹¤ì‹œê°„ ì‹œì²­ UV
        - **í‹°ë¹™ ë‹¹ì¼ VOD** `íšŒì°¨í‰ê· `: (êµ¬ í‹°ë¹™ í€µ) ë³¸ë°©ì†¡ ë‹¹ì¼ VOD UV
        - **í‹°ë¹™ ì£¼ê°„ VOD** `íšŒì°¨í‰ê· `: íšŒì°¨ ë°©ì˜ì¼ë¶€í„° +6ì¼ê¹Œì§€ì˜ 7ì¼ê°„ VOD UV
        - **ë””ì§€í„¸ ì¡°íšŒ/ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•©
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ í‰ê· 
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)

    ip_options = sorted(df_full["IP"].dropna().unique().tolist())
    with filter_cols[1]:
        ip_selected = st.selectbox(
            "IP (ë‹¨ì¼ì„ íƒ)",
            ip_options,
            index=0 if ip_options else None,
            placeholder="IP ì„ íƒ",
            label_visibility="collapsed"
        )

    with filter_cols[2]:
        selected_group_criteria = st.multiselect(
            "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"],
            default=["ë™ì¼ í¸ì„±"],
            placeholder="ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            label_visibility="collapsed",
            key="ip_detail_group"
        )

    if "ë°©ì˜ì‹œì‘ì¼" in df_full.columns and df_full["ë°©ì˜ì‹œì‘ì¼"].notna().any():
        date_col_for_filter = "ë°©ì˜ì‹œì‘ì¼"
    else:
        date_col_for_filter = "ì£¼ì°¨ì‹œì‘ì¼"

    # --- ì„ íƒ IP ë°ì´í„° í•„í„°ë§ ---
    f = df_full[df_full["IP"] == ip_selected].copy()

    if "íšŒì°¨_numeric" in f.columns:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨_numeric"], errors="coerce")
    else:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")
    
    my_max_ep = f["íšŒì°¨_num"].max()

    def _week_to_num(x: str):
        m = re.search(r"-?\d+", str(x))
        return int(m.group(0)) if m else None

    has_week_col = "ì£¼ì°¨" in f.columns
    if has_week_col:
        f["ì£¼ì°¨_num"] = f["ì£¼ì°¨"].apply(_week_to_num)

    try:
        sel_prog = f["í¸ì„±"].dropna().mode().iloc[0]
    except Exception:
        sel_prog = None

    try:
        sel_year = (
            f[date_col_for_filter].dropna().dt.year.mode().iloc[0]
            if date_col_for_filter in f.columns and not f[date_col_for_filter].dropna().empty
            else None
        )
    except Exception:
        sel_year = None

    # --- ë² ì´ìŠ¤(ë¹„êµ ê·¸ë£¹) ë°ì´í„° í•„í„°ë§ ---
    base_raw = df_full.copy()
    group_name_parts = []

    if "ë™ì¼ í¸ì„±" in selected_group_criteria:
        if sel_prog:
            base_raw = base_raw[base_raw["í¸ì„±"] == sel_prog]
            group_name_parts.append(f"'{sel_prog}'")
        else:
            st.warning(f"'{ip_selected}'ì˜ í¸ì„± ì •ë³´ê°€ ì—†ì–´ 'ë™ì¼ í¸ì„±' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")

    if "ë°©ì˜ ì—°ë„" in selected_group_criteria:
        if sel_year:
            base_raw = base_raw[base_raw[date_col_for_filter].dt.year == sel_year]
            group_name_parts.append(f"{int(sel_year)}ë…„")
        else:
            st.warning(f"'{ip_selected}'ì˜ ì—°ë„ ì •ë³´ê°€ ì—†ì–´ 'ë°©ì˜ ì—°ë„' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")

    if not group_name_parts and selected_group_criteria:
        st.warning("ê·¸ë£¹í•‘ ê¸°ì¤€ ì •ë³´ ë¶€ì¡±. ì „ì²´ ë°ì´í„°ì™€ ë¹„êµí•©ë‹ˆë‹¤.", icon="âš ï¸")
        group_name_parts.append("ì „ì²´")
    elif not group_name_parts:
        group_name_parts.append("ì „ì²´")

    if "íšŒì°¨_numeric" in base_raw.columns:
        base_raw["íšŒì°¨_num"] = pd.to_numeric(base_raw["íšŒì°¨_numeric"], errors="coerce")
    else:
        base_raw["íšŒì°¨_num"] = pd.to_numeric(base_raw["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")
    
    if pd.notna(my_max_ep):
        base = base_raw[base_raw["íšŒì°¨_num"] <= my_max_ep].copy()
    else:
        base = base_raw.copy()

    prog_label = " & ".join(group_name_parts) + " í‰ê· "

    st.markdown(
        f"<div class='sub-title'>ğŸ“º {ip_selected} ì„±ê³¼ ìƒì„¸ ë¦¬í¬íŠ¸</div>",
        unsafe_allow_html=True
    )
    st.markdown("---")

    # --- Metric Normalizer & Formatters ---
    def _normalize_metric(s: str) -> str:
        if s is None: return ""
        s2 = re.sub(r"[^A-Za-z0-9ê°€-í£]+", "", str(s)).lower()
        return s2

    def _metric_filter(df: pd.DataFrame, name: str) -> pd.DataFrame:
        target = _normalize_metric(name)
        if "metric_norm" not in df.columns:
            df = df.copy()
            df["metric_norm"] = df["metric"].apply(_normalize_metric)
        return df[df["metric_norm"] == target]

    def fmt_kor(x):
        if pd.isna(x): return "0"
        val = float(x)
        if val == 0: return "0"
        rounded = int(round(val / 10000)) 
        if rounded == 0 and val > 0: return f"{val/10000:.1f}ë§Œ"
        uk = rounded // 10000; man = rounded % 10000
        if uk > 0: return f"{uk}ì–µ{man:04d}ë§Œ" if man > 0 else f"{uk}ì–µ"
        return f"{man}ë§Œ"

    def fmt_live_kor(x):
        if pd.isna(x): return "0"
        val = float(x)
        if val == 0: return "0"
        man = int(val // 10000); cheon = int((val % 10000) // 1000)
        if man > 0: return f"{man}ë§Œ{cheon}ì²œ" if cheon > 0 else f"{man}ë§Œ"
        return f"{cheon}ì²œ" if cheon > 0 else f"{int(val)}"

    def get_axis_ticks(max_val, formatter=fmt_kor):
        if pd.isna(max_val) or max_val <= 0: return None, None
        step = max_val / 4
        power = 10 ** int(np.log10(step))
        base = step / power
        if base < 1.5: step = 1 * power
        elif base < 3.5: step = 2 * power
        elif base < 7.5: step = 5 * power
        else: step = 10 * power
        vals = np.arange(0, max_val + step * 0.1, step)
        texts = [formatter(v) for v in vals]
        return vals, texts
    
    # --- Aggregation Helpers ---
    def _series_ip_metric(base_df: pd.DataFrame, metric_name: str, mode: str = "mean", media: List[str] | None = None):
        if metric_name == "ì¡°íšŒìˆ˜": sub = _get_view_data(base_df)
        else: sub = _metric_filter(base_df, metric_name).copy()
        if media is not None: sub = sub[sub["ë§¤ì²´"].isin(media)]
        if sub.empty: return pd.Series(dtype=float)
        ep_col = _episode_col(sub)
        sub = sub.dropna(subset=[ep_col])
        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value"])
        if sub.empty: return pd.Series(dtype=float)
        
        if mode == "mean":
            ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
            s = ep_mean.groupby("IP")["value"].mean()
        elif mode == "sum": s = sub.groupby("IP")["value"].sum()
        elif mode == "ep_sum_mean":
            ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
            s = ep_sum.groupby("IP")["value"].mean()
        elif mode == "min": s = sub.groupby("IP")["value"].min()
        else: s = sub.groupby("IP")["value"].mean()
        return pd.to_numeric(s, errors="coerce").dropna()

    def _min_of_ip_metric(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty: return None
        s = pd.to_numeric(sub["value"], errors="coerce").dropna()
        return float(s.min()) if not s.empty else None

    def _mean_like_rating(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty: return None
        sub["val"] = pd.to_numeric(sub["value"], errors="coerce")
        sub = sub.dropna(subset=["val"])
        if sub.empty: return None
        if "íšŒì°¨_num" in sub.columns and sub["íšŒì°¨_num"].notna().any():
            g = sub.dropna(subset=["íšŒì°¨_num"]).groupby("íšŒì°¨_num", as_index=False)["val"].mean()
            return float(g["val"].mean())
        if date_col_for_filter in sub.columns and sub[date_col_for_filter].notna().any():
            g = sub.dropna(subset=[date_col_for_filter]).groupby(date_col_for_filter, as_index=False)["val"].mean()
            return float(g["val"].mean())
        return float(sub["val"].mean())

    # --- KPI Calculation ---
    val_T = mean_of_ip_episode_mean(f, "Tì‹œì²­ë¥ ")
    val_H = mean_of_ip_episode_mean(f, "Hì‹œì²­ë¥ ")
    val_live = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    val_quick = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"]) 
    val_vod = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
    val_buzz = mean_of_ip_sums(f, "ì–¸ê¸‰ëŸ‰")
    val_view = mean_of_ip_sums(f, "ì¡°íšŒìˆ˜")
    val_topic_min = _min_of_ip_metric(f, "F_Total")
    val_topic_avg = _mean_like_rating(f, "F_score")

    base_T = mean_of_ip_episode_mean(base, "Tì‹œì²­ë¥ ")
    base_H = mean_of_ip_episode_mean(base, "Hì‹œì²­ë¥ ")
    base_live = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    base_quick = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
    base_vod = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
    base_buzz = mean_of_ip_sums(base, "ì–¸ê¸‰ëŸ‰")
    base_view = mean_of_ip_sums(base, "ì¡°íšŒìˆ˜")
    base_topic_min_series = _series_ip_metric(base, "F_Total", mode="min")
    base_topic_min = float(base_topic_min_series.mean()) if not base_topic_min_series.empty else None
    base_topic_avg = _mean_like_rating(base, "F_score")

    # --- Ranking ---
    def _rank_within_program(base_df, metric_name, ip_name, value, mode="mean", media=None, low_is_good=False):
        s = _series_ip_metric(base_df, metric_name, mode=mode, media=media)
        if s.empty or value is None or pd.isna(value): return (None, 0)
        s = s.dropna()
        if ip_name not in s.index: return (None, int(s.shape[0]))
        ranks = s.rank(method="min", ascending=low_is_good)
        return (int(ranks.loc[ip_name]), int(s.shape[0]))

    rk_T     = _rank_within_program(base, "Tì‹œì²­ë¥ ", ip_selected, val_T,   mode="mean",        media=None)
    rk_H     = _rank_within_program(base, "Hì‹œì²­ë¥ ", ip_selected, val_H,   mode="mean",        media=None)
    rk_live  = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_live,  mode="ep_sum_mean", media=["TVING LIVE"])
    rk_quick = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_quick, mode="ep_sum_mean", media=["TVING QUICK"])
    rk_vod   = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_vod,   mode="ep_sum_mean", media=["TVING VOD"])
    rk_buzz  = _rank_within_program(base, "ì–¸ê¸‰ëŸ‰",   ip_selected, val_buzz,  mode="sum",        media=None)
    rk_view  = _rank_within_program(base, "ì¡°íšŒìˆ˜",   ip_selected, val_view,  mode="sum",        media=None)
    rk_fmin  = _rank_within_program(base, "F_Total",  ip_selected, val_topic_min, mode="min",   media=None, low_is_good=True)
    rk_fscr  = _rank_within_program(base, "F_score",  ip_selected, val_topic_avg, mode="mean",  media=None, low_is_good=False)

    # --- KPI Render Helpers ---
    def _pct_color(val, base_val):
        if val is None or pd.isna(val) or base_val in (None, 0) or pd.isna(base_val): return "#888"
        pct = (val / base_val) * 100
        return "#d93636" if pct > 100 else ("#2a61cc" if pct < 100 else "#444")

    def sublines_html(prog_label: str, rank_tuple: tuple, val, base_val):
        rnk, total = rank_tuple if rank_tuple else (None, 0)
        rank_label = f"{rnk}ìœ„" if (rnk is not None and total > 0) else "â€“ìœ„"
        pct_txt = "â€“"; col = "#888"
        try:
            if (val is not None) and (base_val not in (None, 0)) and (not (pd.isna(val) or pd.isna(base_val))):
                pct = (float(val) / float(base_val)) * 100.0
                pct_txt = f"{pct:.0f}%"; col = _pct_color(val, base_val)
        except Exception: pass
        return (
            "<div class='kpi-subwrap'>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ å…§</span> "
            f"<span class='kpi-substrong'>{rank_label}</span><br/>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ í‰ê· æ¯”</span> "
            f"<span class='kpi-subpct' style='color:{col};'>{pct_txt}</span>"
            "</div>"
        )

    def sublines_dummy():
        return (
         "<div class='kpi-subwrap' style='visibility:hidden;'>"
         "<span class='kpi-sublabel'>_</span> <span class='kpi-substrong'>_</span><br/>"
         "<span class='kpi-sublabel'>_</span> <span class='kpi-subpct'>_</span>"
          "</div>"
        )

    def kpi_with_rank(col, title, value, base_val, rank_tuple, prog_label, intlike=False, digits=3, value_suffix=""):
        with col:
            main_val = fmt(value, digits=digits, intlike=intlike)
            st.markdown(
                f"<div class='kpi-card'><div class='kpi-title'>{title}</div>"
                f"<div class='kpi-value'>{main_val}{value_suffix}</div>"
                f"{sublines_html(prog_label, rank_tuple, value, base_val)}</div>",
                unsafe_allow_html=True
            )

    # === KPI ë°°ì¹˜ (Row 1) ===
    c1, c2, c3, c4, c5 = st.columns(5)
    kpi_with_rank(c1, "ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ",    val_T, base_T, rk_T, prog_label, digits=3)
    kpi_with_rank(c2, "ğŸ  ê°€êµ¬ì‹œì²­ë¥ ",    val_H, base_H, rk_H, prog_label, digits=3)
    kpi_with_rank(c3, "ğŸ“º TVING LIVE",     val_live, base_live, rk_live, prog_label, intlike=True)
    kpi_with_rank(c4, "âš¡ TVING ë‹¹ì¼ VOD",  val_quick, base_quick, rk_quick, prog_label, intlike=True)
    kpi_with_rank(c5, "â–¶ï¸ TVING ì£¼ê°„ VOD", val_vod, base_vod, rk_vod, prog_label, intlike=True)

    # === KPI ë°°ì¹˜ (Row 2) ===
    # [ìˆ˜ì •] 5ì—´ë¡œ í™•ì¥í•˜ê³  ë§ˆì§€ë§‰ì— ë”ë¯¸ ì¹´ë“œ ì¶”ê°€
    c6, c7, c8, c9, c10 = st.columns(5)
    kpi_with_rank(c6, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", val_view, base_view, rk_view, prog_label, intlike=True)
    kpi_with_rank(c7, "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", val_buzz, base_buzz, rk_buzz, prog_label, intlike=True)
    with c8:
        v = val_topic_min
        main_val = "â€“" if (v is None or pd.isna(v)) else f"{int(round(v)):,d}ìœ„"
        st.markdown(
            f"<div class='kpi-card'><div class='kpi-title'>ğŸ† ìµœê³  í™”ì œì„± ìˆœìœ„</div>"
            f"<div class='kpi-value'>{main_val}</div>{sublines_dummy()}</div>",
            unsafe_allow_html=True
        )
    kpi_with_rank(c9, "ğŸ”¥ í™”ì œì„± ì ìˆ˜", val_topic_avg, base_topic_avg, rk_fscr, prog_label, intlike=True)
    with c10:
        # ë”ë¯¸ ì¹´ë“œ (ë ˆì´ì•„ì›ƒ ë§ì¶¤ìš©, íˆ¬ëª… ì²˜ë¦¬)
        st.markdown(
            f"<div class='kpi-card' style='opacity:0; pointer-events:none;'><div class='kpi-title'>-</div>"
            f"<div class='kpi-value'>-</div>{sublines_dummy()}</div>",
            unsafe_allow_html=True
        )

    st.divider()

    # --- Charts ---
    chart_h = 320
    common_cfg = {"scrollZoom": False, "staticPlot": False, "displayModeBar": False}

    # === [Row1] ì‹œì²­ë¥  | í‹°ë¹™ ===
    cA, cB = st.columns(2)
    with cA:
        st.markdown("<div class='sec-title'>ğŸ“ˆ ì‹œì²­ë¥ </div>", unsafe_allow_html=True)
        rsub = f[f["metric"].isin(["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "])].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        rsub = rsub.sort_values("íšŒì°¨_num")
        if not rsub.empty:
            ep_order = rsub[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            t_series = rsub[rsub["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            h_series = rsub[rsub["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            ymax = pd.concat([t_series["value"], h_series["value"]]).max()
            y_upper = float(ymax) * 1.4 if pd.notna(ymax) else None

            fig_rate = go.Figure()
            fig_rate.add_trace(go.Scatter(
                x=h_series["íšŒì°¨"], y=h_series["value"], mode="lines+markers+text", name="ê°€êµ¬ì‹œì²­ë¥ ",
                line=dict(color='#90a4ae', width=2), text=[f"{v:.2f}" for v in h_series["value"]], textposition="top center"
            ))
            fig_rate.add_trace(go.Scatter(
                x=t_series["íšŒì°¨"], y=t_series["value"], mode="lines+markers+text", name="íƒ€ê¹ƒì‹œì²­ë¥ ",
                line=dict(color='#3949ab', width=3), text=[f"{v:.2f}" for v in t_series["value"]], textposition="top center"
            ))
            fig_rate.update_xaxes(categoryorder="array", categoryarray=ep_order, title=None, fixedrange=True)
            fig_rate.update_yaxes(title=None, fixedrange=True, range=[0, y_upper] if (y_upper and y_upper > 0) else None)
            fig_rate.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8), legend=dict(orientation='h', yanchor='bottom', y=1.02))
            st.plotly_chart(fig_rate, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì‹œì²­ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cB:
        # [ìˆ˜ì •] ì œëª© ëˆ„ì  í…ìŠ¤íŠ¸ ì œê±°
        st.markdown("<div class='sec-title'>ğŸ“± TVING ì‹œì²­ììˆ˜</div>", unsafe_allow_html=True)
        t_keep = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        tsub = f[(f["metric"] == "ì‹œì²­ì¸êµ¬") & (f["ë§¤ì²´"].isin(t_keep))].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        tsub = tsub.sort_values("íšŒì°¨_num")
        
        if not tsub.empty:
            media_map = {"TVING LIVE": "LIVE", "TVING QUICK": "ë‹¹ì¼ VOD", "TVING VOD": "ì£¼ê°„ VOD"}
            tsub["ë§¤ì²´_í‘œê¸°"] = tsub["ë§¤ì²´"].map(media_map)
            
            pvt = tsub.pivot_table(index="íšŒì°¨", columns="ë§¤ì²´_í‘œê¸°", values="value", aggfunc="sum").fillna(0)
            ep_order = tsub[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            pvt = pvt.reindex(ep_order)
            
            stack_order = ["LIVE", "ë‹¹ì¼ VOD", "ì£¼ê°„ VOD"]
            colors = {"LIVE": "#90caf9", "ë‹¹ì¼ VOD": "#64b5f6", "ì£¼ê°„ VOD": "#1565c0"}
            
            fig_tving = go.Figure()
            for m in stack_order:
                if m in pvt.columns:
                    # [ìˆ˜ì •] ê³„ì—´ë³„ ë ˆì´ë¸”(text) ì œê±°
                    fig_tving.add_trace(go.Bar(
                        name=m, x=pvt.index, y=pvt[m],
                        marker_color=colors[m],
                        text=None, # ë ˆì´ë¸” ì œê±°
                        hovertemplate=f"<b>%{{x}}</b><br>{m}: %{{y:,.0f}}<extra></extra>"
                    ))
            
            total_vals = pvt[list(set(pvt.columns) & set(stack_order))].sum(axis=1)
            max_val = total_vals.max()
            total_txt = [fmt_live_kor(v) for v in total_vals]
            
            # ì´í•© ë ˆì´ë¸”ë§Œ ìœ ì§€
            fig_tving.add_trace(go.Scatter(
                x=pvt.index, y=total_vals, mode='text',
                text=total_txt, textposition='top center',
                textfont=dict(size=11, color='#333'),
                showlegend=False, hoverinfo='skip'
            ))

            fig_tving.update_layout(
                barmode='stack', height=chart_h, margin=dict(l=8, r=8, t=10, b=8),
                legend=dict(orientation='h', yanchor='bottom', y=1.02),
                yaxis=dict(showgrid=False, visible=False, range=[0, max_val * 1.2]),
                xaxis=dict(categoryorder="array", categoryarray=ep_order, fixedrange=True)
            )
            st.plotly_chart(fig_tving, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  TVING ì‹œì²­ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Row2] ë°ëª¨ ë¶„í¬ ===
    cG, cH, cI = st.columns(3)

    def _render_pyramid_local(container, title, df_src, height=260):
        if df_src.empty:
            container.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

        COLOR_MALE_NEW = "#5B85D9"; COLOR_FEMALE_NEW = "#E66C6C"

        df_demo = df_src.copy()
        df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
        df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
        df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & df_demo["ì—°ë ¹ëŒ€_ëŒ€"].notna()]

        if df_demo.empty: container.info("ë°ì´í„° ì—†ìŒ"); return

        order = ["60ëŒ€", "50ëŒ€", "40ëŒ€", "30ëŒ€", "20ëŒ€", "10ëŒ€"]

        pvt = df_demo.groupby(["ì—°ë ¹ëŒ€_ëŒ€","ì„±ë³„"])["value"].sum().unstack("ì„±ë³„").reindex(order).fillna(0)
        male = -pvt.get("ë‚¨", pd.Series(0, index=pvt.index))
        female = pvt.get("ì—¬", pd.Series(0, index=pvt.index))

        total_pop = male.abs().sum() + female.sum()
        if total_pop == 0: total_pop = 1
        
        male_share = (male.abs() / total_pop * 100)
        female_share = (female / total_pop * 100)
        max_abs = float(max(male.abs().max(), female.max()) or 1)

        male_text = [f"{v:.1f}%" if v > 0 else "" for v in male_share]
        female_text = [f"{v:.1f}%" if v > 0 else "" for v in female_share]

        fig = go.Figure()
        fig.add_trace(go.Bar(
            y=pvt.index, x=male, name="ë‚¨", orientation="h", marker_color=COLOR_MALE_NEW,
            text=male_text, textposition="inside", insidetextanchor="end",
            textfont=dict(color="#ffffff", size=11),
            hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ë‚¨ì„±=%{customdata[0]:,.0f}ëª…<br>ì „ì²´ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
            customdata=np.column_stack([male.abs(), male_share])
        ))
        fig.add_trace(go.Bar(
            y=pvt.index, x=female, name="ì—¬", orientation="h", marker_color=COLOR_FEMALE_NEW,
            text=female_text, textposition="inside", insidetextanchor="start",
            textfont=dict(color="#ffffff", size=11),
            hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ì—¬ì„±=%{customdata[0]:,.0f}ëª…<br>ì „ì²´ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
            customdata=np.column_stack([female, female_share])
        ))

        fig.update_layout(
            barmode="overlay", height=height, margin=dict(l=8, r=8, t=48, b=8),
            legend_title=None, bargap=0.15,
            title=dict(text=title, x=0.0, y=0.98, font=dict(size=14))
        )
        fig.update_yaxes(categoryorder="array", categoryarray=order, fixedrange=True)
        fig.update_xaxes(range=[-max_abs*1.1, max_abs*1.1], showticklabels=False, showgrid=False, zeroline=True, fixedrange=True)
        container.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    with cG:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TV</div>", unsafe_allow_html=True)
        tv_demo = f[(f["ë§¤ì²´"] == "TV") & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cG, "", tv_demo, height=260)

    with cH:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TVING LIVE</div>", unsafe_allow_html=True)
        live_demo = f[(f["ë§¤ì²´"] == "TVING LIVE") & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cH, "", live_demo, height=260)

    with cI:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TVING VOD</div>", unsafe_allow_html=True)
        vod_demo = f[(f["ë§¤ì²´"].isin(["TVING VOD", "TVING QUICK"])) & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cI, "", vod_demo, height=260)

    # === [Row3] ë””ì§€í„¸ ===
    cC, cD = st.columns(2)
    digital_colors = ['#5c6bc0', '#7e57c2', '#26a69a', '#66bb6a', '#ffa726', '#ef5350']
    
    with cC:
        st.markdown("<div class='sec-title'>ğŸ’» ë””ì§€í„¸ ì¡°íšŒìˆ˜</div>", unsafe_allow_html=True)
        dview = _get_view_data(f) 
        if not dview.empty:
            if has_week_col and dview["ì£¼ì°¨"].notna().any():
                order = (dview[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dview.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dview.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum").sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            total_view = pvt.sum(axis=1)
            max_view = total_view.max()
            view_ticks_val, view_ticks_txt = get_axis_ticks(max_view, formatter=fmt_kor)
            total_text = [fmt_kor(v) for v in total_view]

            fig_view = go.Figure()
            for i, col in enumerate(pvt.columns):
                h_texts = [fmt_kor(v) for v in pvt[col]]
                fig_view.add_trace(go.Bar(
                    name=col, x=x_vals, y=pvt[col], marker_color=digital_colors[i % len(digital_colors)],
                    hovertemplate="<b>%{x}</b><br>" + f"{col}: " + "%{text}<extra></extra>",
                    text=h_texts, textposition='none'
                ))
            
            fig_view.add_trace(go.Scatter(
                x=x_vals, y=total_view, mode='text', text=total_text, textposition='top center',
                textfont=dict(size=11, color='#333'), showlegend=False, hoverinfo='skip'
            ))
            fig_view.update_layout(
                barmode="stack", legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8),
                yaxis=dict(tickvals=view_ticks_val, ticktext=view_ticks_txt, fixedrange=True, range=[0, max_view * 1.15])
            )
            if use_category: fig_view.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
            st.plotly_chart(fig_view, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì¡°íšŒìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cD:
        st.markdown("<div class='sec-title'>ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰</div>", unsafe_allow_html=True)
        dbuzz = f[f["metric"] == "ì–¸ê¸‰ëŸ‰"].copy()
        if not dbuzz.empty:
            if has_week_col and dbuzz["ì£¼ì°¨"].notna().any():
                order = (dbuzz[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dbuzz.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dbuzz.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum").sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            total_buzz = pvt.sum(axis=1)
            max_buzz = total_buzz.max()
            total_text = [f"{v:,.0f}" for v in total_buzz]

            fig_buzz = go.Figure()
            for i, col in enumerate(pvt.columns):
                h_texts = [f"{v:,.0f}" for v in pvt[col]]
                fig_buzz.add_trace(go.Bar(
                    name=col, x=x_vals, y=pvt[col], marker_color=digital_colors[(i+2) % len(digital_colors)],
                    hovertemplate="<b>%{x}</b><br>" + f"{col}: " + "%{text}<extra></extra>",
                    text=h_texts, textposition='none'
                ))
            
            fig_buzz.add_trace(go.Scatter(
                x=x_vals, y=total_buzz, mode='text', text=total_text, textposition='top center',
                textfont=dict(size=11, color='#333'), showlegend=False, hoverinfo='skip'
            ))
            fig_buzz.update_layout(
                barmode="stack", legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8),
                yaxis=dict(fixedrange=True, range=[0, max_buzz * 1.15])
            )
            if use_category: fig_buzz.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
            st.plotly_chart(fig_buzz, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì–¸ê¸‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Row4] í™”ì œì„± ===
    cE, cF = st.columns(2)
    with cE:
        st.markdown("<div class='sec-title'>ğŸ”¥ í™”ì œì„± ì ìˆ˜ & ìˆœìœ„</div>", unsafe_allow_html=True)
        fdx = _metric_filter(f, "F_Total").copy(); fs = _metric_filter(f, "F_score").copy()
        if has_week_col and f["ì£¼ì°¨"].notna().any():
            order = (f[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
            key_col = "ì£¼ì°¨"; use_category = True
        else:
            key_col = "ì£¼ì°¨ì‹œì‘ì¼"; order = sorted(f[key_col].dropna().unique()); use_category = False
            
        if not fs.empty:
            fs["val"] = pd.to_numeric(fs["value"], errors="coerce")
            fs_agg = fs.dropna(subset=[key_col]).groupby(key_col, as_index=False)["val"].mean()
        else: fs_agg = pd.DataFrame(columns=[key_col, "val"])
            
        if not fdx.empty:
            fdx["rank"] = pd.to_numeric(fdx["value"], errors="coerce")
            fdx_agg = fdx.dropna(subset=[key_col]).groupby(key_col, as_index=False)["rank"].min()
        else: fdx_agg = pd.DataFrame(columns=[key_col, "rank"])
            
        if not fs_agg.empty:
            merged = pd.merge(fs_agg, fdx_agg, on=key_col, how="left")
            if use_category: merged = merged.set_index(key_col).reindex(order).dropna(subset=["val"]).reset_index()
            else: merged = merged.sort_values(key_col)
            
            if not merged.empty:
                x_vals = merged[key_col].tolist(); y_vals = merged["val"].tolist()
                labels = [f"{int(r['rank'])}ìœ„<br>/{int(r['val']):,}ì " if pd.notna(r['rank']) else f"{int(r['val']):,}ì " for _, r in merged.iterrows()]
                
                fig_comb = go.Figure()
                fig_comb.add_trace(go.Scatter(
                    x=x_vals, y=y_vals, mode="lines+markers+text", name="í™”ì œì„± ì ìˆ˜",
                    text=labels, textposition="top center", textfont=dict(size=11, color="#333"),
                    line=dict(color='#ec407a', width=3), marker=dict(size=7, color='#ec407a')
                ))
                if y_vals: fig_comb.update_yaxes(range=[0, max(y_vals) * 1.25], title=None, fixedrange=True)
                if use_category: fig_comb.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
                fig_comb.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=20, b=8))
                st.plotly_chart(fig_comb, use_container_width=True, config=common_cfg)
            else: st.info("ë°ì´í„° ì—†ìŒ")
        else: st.info("ë°ì´í„° ì—†ìŒ")

    with cF:
        st.markdown("<div style='height:320px;display:flex;align-items:center;justify-content:center;color:#ccc;'></div>", unsafe_allow_html=True)

    st.divider()

    # === [Row5] ë°ëª¨ë¶„ì„ ìƒì„¸ í‘œ (AgGrid) ===
    st.markdown("#### ğŸ‘¥ íšŒì°¨ë³„ ì‹œì²­ììˆ˜ ë¶„í¬")

    def _build_demo_table_numeric(df_src, medias):
        sub = df_src[(df_src["metric"]=="ì‹œì²­ì¸êµ¬") & (df_src["ë°ëª¨"].notna()) & (df_src["ë§¤ì²´"].isin(medias))].copy()
        if sub.empty: return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)
        sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(_gender_from_demo)
        sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)
        sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()
        if "íšŒì°¨_num" not in sub.columns:
            sub["íšŒì°¨_num"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        sub = sub.dropna(subset=["íšŒì°¨_num"])
        sub["íšŒì°¨_num"] = sub["íšŒì°¨_num"].astype(int)
        sub["ë¼ë²¨"] = sub.apply(lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)
        pvt = sub.pivot_table(index="íšŒì°¨_num", columns="ë¼ë²¨", values="value", aggfunc="sum").fillna(0)
        for c in DEMO_COLS_ORDER:
            if c not in pvt.columns: pvt[c] = 0
        pvt = pvt[DEMO_COLS_ORDER].sort_index()
        pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))
        return pvt.reset_index(drop=True)

    diff_renderer = JsCode("""
    function(params){
      const api = params.api;
      const colId = params.column.getColId();
      const rowIndex = params.node.rowIndex;
      const val = Number(params.value || 0);
      if (colId === "íšŒì°¨") return params.value;
      let arrow = "";
      if (rowIndex > 0) {
        const prev = api.getDisplayedRowAtIndex(rowIndex - 1);
        if (prev && prev.data && prev.data[colId] != null) {
          const pv = Number(prev.data[colId] || 0);
          if (val > pv) arrow = "ğŸ”º"; else if (val < pv) arrow = "â–¾";
        }
      }
      return arrow + Math.round(val).toLocaleString();
    }""")

    _js_demo_cols = "[" + ",".join([f'"{c}"' for c in DEMO_COLS_ORDER]) + "]"
    cell_style_renderer = JsCode(f"""
    function(params){{
      const field = params.colDef.field;
      if (field === "íšŒì°¨") return {{'text-align':'left','font-weight':'600','background-color':'#fff'}};
      const COLS = {_js_demo_cols};
      let rowVals = [];
      for (let k of COLS) {{
        const v = Number((params.data && params.data[k] != null) ? params.data[k] : NaN);
        if (!isNaN(v)) rowVals.push(v);
      }}
      let bg = '#ffffff';
      if (rowVals.length > 0) {{
        const v = Number(params.value || 0);
        const mn = Math.min.apply(null, rowVals);
        const mx = Math.max.apply(null, rowVals);
        let norm = 0.5;
        if (mx > mn) norm = (v - mn) / (mx - mn);
        const alpha = 0.12 + 0.45 * Math.max(0, Math.min(1, norm));
        bg = 'rgba(30,90,255,' + alpha.toFixed(3) + ')';
      }}
      return {{'background-color': bg, 'text-align': 'right', 'padding': '2px 4px', 'font-weight': '500'}};
    }}""")

    # [ìˆ˜ì •] ë†’ì´ ìë™(autoHeight) ë° height=None ì ìš©í•˜ì—¬ ì˜ë¦¼ í•´ê²°
    def _render_aggrid_table(df_numeric, title):
        st.markdown(f"###### {title}")
        if df_numeric.empty: st.info("ë°ì´í„° ì—†ìŒ"); return
        gb = GridOptionsBuilder.from_dataframe(df_numeric)
        # [ìˆ˜ì •] domLayout='autoHeight' ì ìš©
        gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='autoHeight')
        gb.configure_default_column(sortable=False, resizable=True, filter=False, cellStyle={'textAlign': 'right'}, headerClass='centered-header bold-header')
        gb.configure_column("íšŒì°¨", header_name="íšŒì°¨", cellStyle={'textAlign': 'left'})
        for c in [col for col in df_numeric.columns if col != "íšŒì°¨"]:
            gb.configure_column(c, header_name=c, cellRenderer=diff_renderer, cellStyle=cell_style_renderer)
        # [ìˆ˜ì •] height=Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìë™ ë†’ì´ ì‚¬ìš©
        AgGrid(df_numeric, gridOptions=gb.build(), theme="streamlit", height=None, update_mode=GridUpdateMode.NO_UPDATE, allow_unsafe_jscode=True)

    tv_numeric = _build_demo_table_numeric(f, ["TV"])
    _render_aggrid_table(tv_numeric, "ğŸ“º TV (ì‹œì²­ììˆ˜)")

    tving_numeric = _build_demo_table_numeric(f, ["TVING LIVE", "TVING QUICK", "TVING VOD"])
    _render_aggrid_table(tving_numeric, "â–¶ï¸ TVING í•©ì‚° ì‹œì²­ììˆ˜")
#endregion


#region [ 9. í˜ì´ì§€ 3: IPê°„ ë°ëª¨ë¶„ì„ ]
# =====================================================
# [ìˆ˜ì •] ê¸°ì¡´ Region 10

# ===== 9.1. [í˜ì´ì§€ 3] AgGrid ë Œë”ëŸ¬ (0-based % Diff) =====
# (ì´ JS ì½”ë“œëŠ” ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤)
index_value_formatter = JsCode("""
function(params) {
    const indexValue = params.value;
    if (indexValue == null || (typeof indexValue !== 'number')) return 'N/A';
    if (indexValue === 999) return 'INF';
    const roundedIndex = Math.round(indexValue);
    let arrow = '';
    if (roundedIndex > 5) { arrow = ' â–²'; }
    else if (roundedIndex < -5) { arrow = ' â–¼'; }
    let sign = roundedIndex > 0 ? '+' : '';
    if (roundedIndex === 0) sign = '';
    return sign + roundedIndex + '%' + arrow;
}""")

index_cell_style = JsCode("""
function(params) {
    const indexValue = params.value;
    let color = '#333';
    let fontWeight = '500';
    if (indexValue == null || (typeof indexValue !== 'number')) {
        color = '#888';
    } else if (indexValue === 999) {
        color = '#888';
    } else {
        if (indexValue > 5) { color = '#d93636'; }
        else if (indexValue < -5) { color = '#2a61cc'; }
    }
    return { 'color': color, 'font-weight': fontWeight };
}""")


# ===== 9.2. [í˜ì´ì§€ 3] AgGrid í…Œì´ë¸” ë Œë”ë§ í•¨ìˆ˜ (Legacy) =====
# [ì°¸ê³ ] í˜„ì¬ render_heatmap í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ í•¨ìˆ˜ëŠ” í˜¸ì¶œë˜ì§€ ì•ŠìŒ (ë¯¸ì‚¬ìš©)
def render_index_table(df_index: pd.DataFrame, title: str, height: int = 400):
    st.markdown(f"###### {title}")

    if df_index.empty: st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    gb = GridOptionsBuilder.from_dataframe(df_index)
    gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
    gb.configure_default_column(sortable=False, resizable=True, filter=False,
                                cellStyle={'textAlign': 'center'}, headerClass='centered-header bold-header')
    gb.configure_column("íšŒì°¨", header_name="íšŒì°¨", cellStyle={'textAlign': 'left'}, pinned='left', width=70)

    for c in [col for col in df_index.columns if col != "íšŒì°¨" and not col.endswith(('_base', '_comp'))]:
        gb.configure_column(
            c, 
            header_name=c.replace("ë‚¨ì„±","M").replace("ì—¬ì„±","F"), 
            valueFormatter=index_value_formatter, 
            cellStyle=index_cell_style,         
            width=80
        )
    for c in [col for col in df_index.columns if col.endswith(('_base', '_comp'))]:
        gb.configure_column(c, hide=True)

    grid_options = gb.build()
    AgGrid(df_index, gridOptions=grid_options, theme="streamlit", height=height,
           update_mode=GridUpdateMode.NO_UPDATE, allow_unsafe_jscode=True,
           enable_enterprise_modules=False
    )

# ===== 9.3. [í˜ì´ì§€ 3] íˆíŠ¸ë§µ ë Œë”ë§ í•¨ìˆ˜ =====
def render_heatmap(df_plot: pd.DataFrame, title: str):
    """
    ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ Plotly íˆíŠ¸ë§µì„ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    st.markdown(f"###### {title}")

    if df_plot.empty:
        st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_heatmap = df_plot.set_index("íšŒì°¨")
    
    cols_to_drop = [c for c in df_heatmap.columns if c.endswith(('_base', '_comp'))]
    df_heatmap = df_heatmap.drop(columns=cols_to_drop)
    
    valid_values = df_heatmap.replace(999, np.nan).values
    if pd.isna(valid_values).all():
         v_min, v_max = -10.0, 10.0
    else:
         v_min = np.nanmin(valid_values)
         v_max = np.nanmax(valid_values)
         if pd.isna(v_min): v_min = 0.0
         if pd.isna(v_max): v_max = 0.0
    
    abs_max = max(abs(v_min), abs(v_max), 10.0)
    
    fig = px.imshow(
        df_heatmap,
        text_auto=False, 
        aspect="auto",
        color_continuous_scale='RdBu_r', 
        range_color=[-abs_max, abs_max], 
        color_continuous_midpoint=0
    )

    text_template_df = df_heatmap.applymap(
        lambda x: "INF" if x == 999 else (f"{x:+.0f}%" if pd.notna(x) else "")
    )

    fig.update_traces(
        text=text_template_df.values,
        texttemplate="%{text}",
        hovertemplate="íšŒì°¨: %{y}<br>ë°ëª¨: %{x}<br>ì¦ê°: %{text}<extra></extra>", # [ìˆ˜ì •] extra ì¶”ê°€
        textfont=dict(size=10, color="black")
    )

    fig.update_layout(
        height=max(520, len(df_heatmap.index) * 46), 
        xaxis_title=None,
        yaxis_title=None,
        xaxis=dict(side="top"),
    )
    
    # [ìˆ˜ì •] st.columns(1)ë¡œ ê°ì‹¸ì„œ ë…ë¦½ëœ ì¹´ë“œë¡œ ë§Œë“­ë‹ˆë‹¤.
    c_heatmap, = st.columns(1)
    with c_heatmap:
        st.plotly_chart(fig, use_container_width=True)


# ===== 9.4. [í˜ì´ì§€ 3] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_demographic():
    df_all = load_data() # [3. ê³µí†µ í•¨ìˆ˜]

    ip_options = sorted(df_all["IP"].dropna().unique().tolist())
    selected_ip1 = None; selected_ip2 = None; selected_group_criteria = None

    filter_cols = st.columns([3, 2, 2, 3, 3]) 

    with filter_cols[0]:
        st.markdown("### ğŸ‘¥ IP ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ")
    with st.expander("â„¹ï¸ ì‚¬ìš© ì„¤ëª… ë° ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
**ì‚¬ìš©ë²•**
- **ìƒë‹¨ í•„í„°ì—ì„œ ë¹„êµê¸°ì¤€, í”Œë«í¼ê³¼ ê¸°ì¤€ IPë¥¼ ì„ íƒ**
- **ë¹„êµ ê¸°ì¤€** : `IPê°„ ë¹„êµ` , `ê·¸ë£¹ê³¼ ë¹„êµ`
        
**ì§€í‘œí•´ì„**
- **ê¸°ì¤€IPì™€ ë¹„êµëŒ€ìƒê°„ í•´ë‹¹ ì—°ë ¹ëŒ€ì˜ 'ì‹œì²­ììˆ˜'ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤**
- **ì˜ˆì‹œ** : 01í™” 20ëŒ€ ë‚¨ì„±ì´ +51%ì¸ ê²½ìš° â†’ `ê¸°ì¤€IPê°€ ë¹„êµëŒ€ìƒë³´ë‹¤ 20ëŒ€ ë‚¨ì„± ì‹œì²­ììˆ˜ê°€ 51% ë§ë‹¤`
""").strip())
        st.markdown("</div>", unsafe_allow_html=True)

    with filter_cols[1]:
        comparison_mode = st.selectbox(
            "ë¹„êµ ëª¨ë“œ", 
            ["IP vs IP", "IP vs ê·¸ë£¹"], 
            index=0,
            key="demo_compare_mode",
            label_visibility="collapsed"
        )
        
    with filter_cols[2]:
        selected_media_type = st.selectbox(
            "ë¶„ì„ ë§¤ì²´", 
            ["TV", "TVING"],
            index=0,
            key="demo_media_type",
            label_visibility="collapsed"
        )
            
    with filter_cols[3]:
        selected_ip1 = st.selectbox(
            "ê¸°ì¤€ IP", ip_options, 
            index=0 if ip_options else None, 
            label_visibility="collapsed", 
            key="demo_ip1_unified"
        )

    with filter_cols[4]:
        if comparison_mode == "IP vs IP":
            ip_options_2 = [ip for ip in ip_options if ip != selected_ip1] # [ìˆ˜ì •] ì˜µì…˜ í•„í„°ë§
            selected_ip2 = st.selectbox(
                "ë¹„êµ IP", ip_options_2, # [ìˆ˜ì •] í•„í„°ëœ ì˜µì…˜ ì‚¬ìš©
                index=0 if ip_options_2 else None, # [ìˆ˜ì •] ì¸ë±ìŠ¤ ë°©ì–´
                label_visibility="collapsed", 
                key="demo_ip2"
            )
        else: # "IP vs ê·¸ë£¹ í‰ê· "
            selected_group_criteria = st.multiselect(
                "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€", 
                ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"], 
                default=["ë™ì¼ í¸ì„±"],
                label_visibility="collapsed", 
                key="demo_group_criteria"
            )
            
    media_list_label = "TV" if selected_media_type == "TV" else "TVING (L+Q+V í•©ì‚°)"

    st.divider()

    if not selected_ip1: st.warning("ê¸°ì¤€ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return
    if comparison_mode == "IP vs IP" and (not selected_ip2): st.warning("ë¹„êµ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return

    df_base = pd.DataFrame(); df_comp = pd.DataFrame(); comp_name = ""
    media_list = ["TV"] if selected_media_type == "TV" else ["TVING LIVE", "TVING QUICK", "TVING VOD"]

    df_ip1_data = df_all[df_all["IP"] == selected_ip1].copy()
    if not df_ip1_data.empty:
        df_base = get_avg_demo_pop_by_episode(df_ip1_data, media_list) # [6. ê³µí†µ í•¨ìˆ˜]

    if comparison_mode == "IP vs IP":
        if selected_ip2:
            df_ip2_data = df_all[df_all["IP"] == selected_ip2].copy()
            if not df_ip2_data.empty:
                 df_comp = get_avg_demo_pop_by_episode(df_ip2_data, media_list) # [6. ê³µí†µ í•¨ìˆ˜]
            comp_name = selected_ip2
        else:
             st.warning("ë¹„êµ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return
             
    else: # "IP vs ê·¸ë£¹ í‰ê· "
        df_group_filtered = df_all.copy(); group_name_parts = []
        base_ip_info_rows = df_all[df_all["IP"] == selected_ip1];
        if not base_ip_info_rows.empty:
            base_ip_prog = base_ip_info_rows["í¸ì„±"].dropna().mode().iloc[0] if not base_ip_info_rows["í¸ì„±"].dropna().empty else None
            date_col = "ë°©ì˜ì‹œì‘ì¼" if "ë°©ì˜ì‹œì‘ì¼" in df_all.columns and df_all["ë°©ì˜ì‹œì‘ì¼"].notna().any() else "ì£¼ì°¨ì‹œì‘ì¼"
            base_ip_year = base_ip_info_rows[date_col].dropna().dt.year.mode().iloc[0] if not base_ip_info_rows[date_col].dropna().empty else None
            
            if not selected_group_criteria:
                st.info("ë¹„êµ ê·¸ë£¹ ê¸°ì¤€ì´ ì„ íƒë˜ì§€ ì•Šì•„ 'ì „ì²´'ì™€ ë¹„êµí•©ë‹ˆë‹¤.")
                group_name_parts.append("ì „ì²´")
            else:
                if "ë™ì¼ í¸ì„±" in selected_group_criteria:
                    if base_ip_prog: 
                        df_group_filtered = df_group_filtered[df_group_filtered["í¸ì„±"] == base_ip_prog]
                        group_name_parts.append(f"'{base_ip_prog}'")
                    else: st.warning("ê¸°ì¤€ IP í¸ì„± ì •ë³´ ì—†ìŒ (ë™ì¼ í¸ì„± ì œì™¸)", icon="âš ï¸")
                if "ë°©ì˜ ì—°ë„" in selected_group_criteria:
                    if base_ip_year: 
                        df_group_filtered = df_group_filtered[df_group_filtered[date_col].dt.year == int(base_ip_year)]
                        group_name_parts.append(f"{int(base_ip_year)}ë…„")
                    else: st.warning("ê¸°ì¤€ IP ì—°ë„ ì •ë³´ ì—†ìŒ (ë°©ì˜ ì—°ë„ ì œì™¸)", icon="âš ï¸")
                
                if not group_name_parts:
                    st.error("ë¹„êµ ê·¸ë£¹ì„ ì •ì˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê¸°ì¤€ IP ì •ë³´ ë¶€ì¡±)"); return

            if not df_group_filtered.empty:
                df_comp = get_avg_demo_pop_by_episode(df_group_filtered, media_list) # [6. ê³µí†µ í•¨ìˆ˜]
                comp_name = " & ".join(group_name_parts) + " í‰ê· "
            else:
                 st.warning("ì„ íƒí•˜ì‹  ê·¸ë£¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                 comp_name = " & ".join(group_name_parts) + " í‰ê· "
        else: 
            st.error("ê¸°ì¤€ IP ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    if df_base.empty:
        st.warning(f"ê¸°ì¤€ IP({selected_ip1})ì˜ ë°ëª¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        render_heatmap(pd.DataFrame(), f"{media_list_label} ë°ëª¨XíšŒì°¨ ì‹œì²­ììˆ˜ ë¹„êµ ({selected_ip1} vs {comp_name})")
        return
    if df_comp.empty:
         st.warning(f"ë¹„êµ ëŒ€ìƒ({comp_name})ì˜ ë°ëª¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Index ê³„ì‚° ì‹œ ë¹„êµê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
         df_comp = pd.DataFrame({'íšŒì°¨': df_base['íšŒì°¨']})
         for col in DEMO_COLS_ORDER: df_comp[col] = 0.0 # [2.1. ê³µí†µ ìƒìˆ˜]

    df_merged = pd.merge(df_base, df_comp, on="íšŒì°¨", suffixes=('_base', '_comp'), how='left')
    df_index = df_merged[["íšŒì°¨"]].copy()

    for col in DEMO_COLS_ORDER: # [2.1. ê³µí†µ ìƒìˆ˜]
        base_col = col + '_base'
        comp_col = col + '_comp'

        df_merged[base_col] = pd.to_numeric(df_merged.get(base_col), errors='coerce').fillna(0.0)
        df_merged[comp_col] = pd.to_numeric(df_merged.get(comp_col), errors='coerce').fillna(0.0)

        base_values = df_merged[base_col].values
        comp_values = df_merged[comp_col].values

        index_values = np.where(
            comp_values != 0,
            ((base_values - comp_values) / comp_values) * 100,
            np.where(base_values == 0, 0.0, 999)
        )
        df_index[col] = index_values
        df_index[base_col] = base_values 
        df_index[comp_col] = comp_values 

    table_title = f"{media_list_label} ì—°ë ¹ëŒ€ë³„ ì‹œì²­ììˆ˜ ì°¨ì´ ({selected_ip1} vs {comp_name})"
    render_heatmap(df_index, table_title) # [9.3. íˆíŠ¸ë§µ í•¨ìˆ˜]
#endregion


#region [ 10. í˜ì´ì§€ 4: IPê°„ ë¹„êµë¶„ì„ ]
# =====================================================
# [ìˆ˜ì •] ë„ë„›ì°¨íŠ¸ ìƒ‰ìƒê³ ì • / VOD+QUICK í†µí•© / ë ˆì´ë” ë¼ë²¨ í•œê¸€í™” / ì¡°íšŒìˆ˜ ì–µë‹¨ìœ„ í‘œê¸° (2025-11-12)

# ===== 10.0. í¬ë§·íŒ… í—¬í¼ (í˜ì´ì§€ 4 ì „ìš©) =====
def _fmt_kor_large(v):
    """Nì–µ NNNNë§Œ ë‹¨ìœ„ í¬ë§·íŒ…"""
    if v is None or pd.isna(v): return "â€“"
    val = float(v)
    if val == 0: return "0"
    
    uk = int(val // 100000000)
    man = int((val % 100000000) // 10000)
    
    if uk > 0:
        return f"{uk}ì–µ{man:04d}ë§Œ"
    elif man > 0:
        return f"{man}ë§Œ"
    else:
        return f"{int(val)}"

# ===== 10.1. [í˜ì´ì§€ 4] KPI ë°±ë¶„ìœ„ ê³„ì‚° (ìºì‹±) =====
@st.cache_data(ttl=600)
def get_kpi_data_for_all_ips(df_all: pd.DataFrame) -> pd.DataFrame:
    """
    ëª¨ë“  IPì— ëŒ€í•´ KPI ì§‘ê³„ í›„ ë°±ë¶„ìœ„(0~100) ë³€í™˜
    [ìˆ˜ì •] TVING VOD = VOD + QUICK í•©ì‚° ë°˜ì˜
    """
    df = df_all.copy()
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df.loc[df["value"] == 0, "value"] = np.nan
    df = df.dropna(subset=["value"])
    
    if "íšŒì°¨_numeric" in df.columns:
        df = df.dropna(subset=["íšŒì°¨_numeric"])
    else:
        df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        df = df.dropna(subset=["íšŒì°¨_numeric"])

    def _ip_mean_of_ep_mean(metric_name: str) -> pd.Series:
        sub = df[df["metric"] == metric_name]
        if sub.empty: return pd.Series(dtype=float, name=metric_name)
        ep_mean = sub.groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
        return ep_mean.groupby("IP")["value"].mean().rename(metric_name)

    kpi_t_rating = _ip_mean_of_ep_mean("Tì‹œì²­ë¥ ")
    kpi_h_rating = _ip_mean_of_ep_mean("Hì‹œì²­ë¥ ")

    # [ìˆ˜ì •] TVING VOD + QUICK í•©ì‚° -> "TVING VOD"ë¡œ í‘œê¸°
    sub_vod_all = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"].isin(["TVING VOD", "TVING QUICK"]))]
    if not sub_vod_all.empty:
        vod_ep_sum = sub_vod_all.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_vod = vod_ep_sum.groupby("IP")["value"].mean().rename("TVING VOD")
    else:
        kpi_vod = pd.Series(dtype=float, name="TVING VOD")

    # [ìˆ˜ì •] TVING LIVE ë‹¨ë…
    sub_live = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"] == "TVING LIVE")]
    if not sub_live.empty:
        live_ep_sum = sub_live.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_live = live_ep_sum.groupby("IP")["value"].mean().rename("TVING LIVE")
    else:
        kpi_live = pd.Series(dtype=float, name="TVING LIVE")

    kpi_view = _get_view_data(df).groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì¡°íšŒìˆ˜") # [3. ê³µí†µ í•¨ìˆ˜]
    kpi_buzz = df[df["metric"] == "ì–¸ê¸‰ëŸ‰"].groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰")
    kpi_f_score = _ip_mean_of_ep_mean("F_Score").rename("í™”ì œì„± ì ìˆ˜")

    kpi_df = pd.concat([kpi_t_rating, kpi_h_rating, kpi_vod, kpi_live, kpi_view, kpi_buzz, kpi_f_score], axis=1)
    kpi_percentiles = kpi_df.rank(pct=True) * 100
    return kpi_percentiles.fillna(0)


# ===== 10.2. [í˜ì´ì§€ 4] ë‹¨ì¼ IP/ê·¸ë£¹ KPI ê³„ì‚° =====
def get_agg_kpis_for_ip_page4(df_ip: pd.DataFrame) -> Dict[str, float | None]:
    """
    ë‹¨ì¼ IP ë˜ëŠ” IP ê·¸ë£¹ì— ëŒ€í•œ ì£¼ìš” KPI ì ˆëŒ€ê°’ ê³„ì‚°
    [ìˆ˜ì •] TVING VOD = VOD + QUICK í•©ì‚° ë°˜ì˜
    """
    kpis = {}
    kpis["Tì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Tì‹œì²­ë¥ ")
    kpis["Hì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Hì‹œì²­ë¥ ")
    
    # [ìˆ˜ì •] VOD + QUICK
    kpis["TVING VOD"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING VOD", "TVING QUICK"])
    # [ìˆ˜ì •] LIVE ë‹¨ë…
    kpis["TVING LIVE"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    
    kpis["ë””ì§€í„¸ ì¡°íšŒìˆ˜"] = mean_of_ip_sums(df_ip, "ì¡°íšŒìˆ˜")
    kpis["ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"] = mean_of_ip_sums(df_ip, "ì–¸ê¸‰ëŸ‰")
    kpis["í™”ì œì„± ì ìˆ˜"] = mean_of_ip_episode_mean(df_ip, "F_Score")

    return kpis


# ===== 10.3. [í˜ì´ì§€ 4] KPI ì¹´ë“œ ë Œë”ë§ (ìƒë‹¨) =====
def _render_kpi_row_ip_vs_group(kpis_ip, kpis_group, group_name):
    def calc_delta(ip_val, group_val): 
        ip_val = ip_val or 0
        group_val = group_val or 0
        if group_val is None or group_val == 0: return None
        return (ip_val - group_val) / group_val
        
    delta_t = calc_delta(kpis_ip.get('Tì‹œì²­ë¥ '), kpis_group.get('Tì‹œì²­ë¥ '))
    delta_h = calc_delta(kpis_ip.get('Hì‹œì²­ë¥ '), kpis_group.get('Hì‹œì²­ë¥ '))
    delta_live = calc_delta(kpis_ip.get('TVING LIVE'), kpis_group.get('TVING LIVE'))
    delta_vod = calc_delta(kpis_ip.get('TVING VOD'), kpis_group.get('TVING VOD'))
    delta_view = calc_delta(kpis_ip.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜'), kpis_group.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜'))
    delta_buzz = calc_delta(kpis_ip.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰'), kpis_group.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰'))
    delta_fscore = calc_delta(kpis_ip.get('í™”ì œì„± ì ìˆ˜'), kpis_group.get('í™”ì œì„± ì ìˆ˜'))

    # [ìˆ˜ì •] ì¡°íšŒìˆ˜ í¬ë§·íŒ… (Nì–µ NNNNë§Œ)
    view_val_str = _fmt_kor_large(kpis_ip.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜'))

    st.markdown(f"#### 1. ì£¼ìš” ì„±ê³¼ ({group_name} ëŒ€ë¹„)")
    kpi_cols = st.columns(7) 
    with kpi_cols[0]: st.metric("ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", f"{kpis_ip.get('Tì‹œì²­ë¥ ', 0):.2f}%", f"{delta_t * 100:.1f}%" if delta_t is not None else "N/A")
    with kpi_cols[1]: st.metric("ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", f"{kpis_ip.get('Hì‹œì²­ë¥ ', 0):.2f}%", f"{delta_h * 100:.1f}%" if delta_h is not None else "N/A")
    with kpi_cols[2]: st.metric("âš¡ í‹°ë¹™ LIVE", f"{kpis_ip.get('TVING LIVE', 0):,.0f}", f"{delta_live * 100:.1f}%" if delta_live is not None else "N/A")
    with kpi_cols[3]: st.metric("â–¶ï¸ í‹°ë¹™ VOD", f"{kpis_ip.get('TVING VOD', 0):,.0f}", f"{delta_vod * 100:.1f}%" if delta_vod is not None else "N/A")
    # [ìˆ˜ì •] ì¡°íšŒìˆ˜ í¬ë§·íŒ… ì ìš©
    with kpi_cols[4]: st.metric("ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", view_val_str, f"{delta_view * 100:.1f}%" if delta_view is not None else "N/A")
    with kpi_cols[5]: st.metric("ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰", f"{kpis_ip.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰', 0):,.0f}", f"{delta_buzz * 100:.1f}%" if delta_buzz is not None else "N/A")
    with kpi_cols[6]: st.metric("ğŸ”¥ í™”ì œì„± ì ìˆ˜", f"{kpis_ip.get('í™”ì œì„± ì ìˆ˜', 0):,.0f}", f"{delta_fscore * 100:.1f}%" if delta_fscore is not None else "N/A")

def _render_kpi_row_ip_vs_ip(kpis1, kpis2, ip1, ip2):
    def _card(title, v1, v2, fmt, higher_good=True):
        v1_disp = fmt.format(v1) if v1 is not None else "â€“"
        v2_disp = fmt.format(v2) if v2 is not None else "â€“"
        win = 0
        if v1 is not None and v2 is not None:
            if higher_good: win = 1 if v1 > v2 else (2 if v2 > v1 else 0)
            else: win = 1 if v1 < v2 else (2 if v2 < v1 else 0)
        
        s1 = "color:#d93636;font-weight:700" if win==1 else "color:#333"
        s2 = "color:#aaaaaa;font-weight:700" if win==2 else "color:#888"

        st.markdown(f"""
        <div class="kpi-card" style="padding:10px 10px;">
            <div class="kpi-title" style="margin-bottom:4px;">{title}</div>
            <div style="font-size:14px; line-height:1.4;">
                <span style="{s1}"><span style="font-size:11px;color:#d93636">{ip1}:</span> {v1_disp}</span><br>
                <span style="{s2}"><span style="font-size:11px;color:#aaaaaa">{ip2}:</span> {v2_disp}</span>
            </div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("#### 1. ì£¼ìš” ì„±ê³¼ ìš”ì•½")
    c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
    with c1: _card("ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", kpis1.get("Tì‹œì²­ë¥ "), kpis2.get("Tì‹œì²­ë¥ "), "{:.2f}%")
    with c2: _card("ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", kpis1.get("Hì‹œì²­ë¥ "), kpis2.get("Hì‹œì²­ë¥ "), "{:.2f}%")
    with c3: _card("âš¡ í‹°ë¹™ LIVE", kpis1.get("TVING LIVE"), kpis2.get("TVING LIVE"), "{:,.0f}")
    with c4: _card("â–¶ï¸ í‹°ë¹™ VOD", kpis1.get("TVING VOD"), kpis2.get("TVING VOD"), "{:,.0f}")
    with c5: _card("ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", kpis1.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), kpis2.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), "{:,.0f}")
    with c6: _card("ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰", kpis1.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), kpis2.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), "{:,.0f}")
    with c7: _card("ğŸ”¥ í™”ì œì„± ì ìˆ˜", kpis1.get("í™”ì œì„± ì ìˆ˜"), kpis2.get("í™”ì œì„± ì ìˆ˜"), "{:,.0f}")


# ===== 10.4. [í˜ì´ì§€ 4] í†µí•© ê·¸ë˜í”„ ì„¹ì…˜ =====
def _render_unified_charts(
    df_target: pd.DataFrame, 
    df_comp: pd.DataFrame, 
    target_name: str, 
    comp_name: str,
    kpi_percentiles: pd.DataFrame,
    comp_color: str = "#aaaaaa"
):
    st.divider()

    # --- 2. ì„±ê³¼ í¬ì§€ì…”ë‹ (Radar) & ì‹œì²­ë¥  ë¹„êµ (Line) ---
    st.markdown("#### 2. ì„±ê³¼ í¬ì§€ì…”ë‹ & ì‹œì²­ë¥ ")
    col_radar, col_rating = st.columns([1, 1])

    # [ì¢Œì¸¡] ì„±ê³¼ í¬ì§€ì…”ë‹
    with col_radar:
        st.markdown("###### ì„±ê³¼ ë°±ë¶„ìœ„ (Positioning)")
        
        # [ìˆ˜ì •] ë ˆì´ë” ì°¨íŠ¸ ì¶• ë¼ë²¨ ì‚¬ìš©ì ê´€ì ìœ¼ë¡œ ë³€ê²½
        # ë‚´ë¶€ Metric Key -> Label Mapping
        radar_map = {
            "Tì‹œì²­ë¥ ": "íƒ€ê¹ƒì‹œì²­ë¥ ", 
            "Hì‹œì²­ë¥ ": "ê°€êµ¬ì‹œì²­ë¥ ", 
            "TVING LIVE": "í‹°ë¹™ LIVE", 
            "TVING VOD": "í‹°ë¹™ VOD", # (VOD+QUICK)
            "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ì¡°íšŒìˆ˜", 
            "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ì–¸ê¸‰ëŸ‰", 
            "í™”ì œì„± ì ìˆ˜": "í™”ì œì„±"
        }
        radar_metrics = list(radar_map.keys())
        radar_labels = list(radar_map.values())

        # Target Score
        if target_name in kpi_percentiles.index:
            score_t = kpi_percentiles.loc[target_name][radar_metrics]
        else:
            score_t = pd.Series(0, index=radar_metrics)
            
        # Comp Score
        if comp_name in kpi_percentiles.index: # IP vs IP
            score_c = kpi_percentiles.loc[comp_name][radar_metrics]
        else: # IP vs Group
            group_ips = df_comp["IP"].unique()
            score_c = kpi_percentiles.loc[kpi_percentiles.index.isin(group_ips)].mean()[radar_metrics]

        fig_radar = go.Figure()
        fig_radar.add_trace(go.Scatterpolar(
            r=score_t.values, theta=radar_labels,
            fill='toself', name=target_name, line=dict(color="#d93636")
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=score_c.values, theta=radar_labels,
            fill='toself', name=comp_name, line=dict(color=comp_color)
        ))
        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True, height=350,
            margin=dict(l=50, r=50, t=30, b=30),
            legend=dict(orientation="h", yanchor="bottom", y=1.05)
        )
        st.plotly_chart(fig_radar, use_container_width=True)

    # [ìš°ì¸¡] ì‹œì²­ë¥  ë¹„êµ
    with col_rating:
        st.markdown(f"###### ì‹œì²­ë¥ ")
        
        # íšŒì°¨ ì œí•œ ë¡œì§
        df_target_rating = df_target[df_target["metric"].isin(["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "])].copy()
        if "íšŒì°¨_numeric" not in df_target_rating.columns:
            df_target_rating["íšŒì°¨_numeric"] = df_target_rating["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
            
        max_ep = df_target_rating["íšŒì°¨_numeric"].max()
        if pd.isna(max_ep): max_ep = 999
        
        def _get_trend(df, metric):
            if "íšŒì°¨_numeric" not in df.columns:
                df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
            mask = (df["metric"] == metric)
            if pd.notna(max_ep):
                mask = mask & (df["íšŒì°¨_numeric"] <= max_ep)
            sub = df[mask].copy()
            return sub.groupby("íšŒì°¨_numeric")["value"].mean().sort_index()

        t_target = _get_trend(df_target, "Tì‹œì²­ë¥ ")
        h_target = _get_trend(df_target, "Hì‹œì²­ë¥ ")
        t_comp   = _get_trend(df_comp,   "Tì‹œì²­ë¥ ")
        h_comp   = _get_trend(df_comp,   "Hì‹œì²­ë¥ ")
        
        fig_line = go.Figure()
        fig_line.add_trace(go.Scatter(x=h_target.index, y=h_target.values, name=f"{target_name}(ê°€êµ¬)",
                                      mode='lines+markers', line=dict(color="#90a4ae", width=2)))
        fig_line.add_trace(go.Scatter(x=t_target.index, y=t_target.values, name=f"{target_name}(íƒ€ê¹ƒ)",
                                      mode='lines+markers', line=dict(color="#3949ab", width=2)))
        
        fig_line.add_trace(go.Scatter(x=h_comp.index, y=h_comp.values, name=f"{comp_name}(ê°€êµ¬)",
                                      mode='lines+markers', line=dict(color="#90a4ae", width=2, dash='dot')))
        fig_line.add_trace(go.Scatter(x=t_comp.index, y=t_comp.values, name=f"{comp_name}(íƒ€ê¹ƒ)",
                                      mode='lines+markers', line=dict(color="#3949ab", width=2, dash='dot')))
        
        fig_line.update_layout(height=350, margin=dict(t=30, b=10), 
                               legend=dict(orientation="h", yanchor="bottom", y=1.02),
                               yaxis_title="ì‹œì²­ë¥ (%)", xaxis_title="íšŒì°¨")
        st.plotly_chart(fig_line, use_container_width=True)

    st.divider()

    # --- 3. ì‹œì²­ì¸êµ¬ ë¹„êµ ---
    st.markdown("#### 3. ë§¤ì²´ë³„ í‰ê·  ì‹œì²­ì¸êµ¬")
    col_pop_tv, col_pop_tving = st.columns(2)

    def _get_demo_pop(df_src, medias):
        sub = df_src[(df_src["metric"]=="ì‹œì²­ì¸êµ¬") & (df_src["ë§¤ì²´"].isin(medias)) & df_src["ë°ëª¨"].notna()].copy()
        sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(_gender_from_demo)
        sub["ì—°ë ¹"] = sub["ë°ëª¨"].apply(_to_decade_label)
        sub = sub[sub["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & (sub["ì—°ë ¹"]!="ê¸°íƒ€")]
        sub["label"] = sub.apply(lambda r: f"{r['ì—°ë ¹']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)
        
        if "íšŒì°¨_numeric" not in sub.columns:
             sub["íšŒì°¨_numeric"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        
        agg = sub.groupby(["IP","íšŒì°¨_numeric","label"])["value"].sum().reset_index()
        return agg.groupby("label")["value"].mean()

    with col_pop_tv:
        st.markdown("###### ğŸ“º TV (í‰ê·  ì‹œì²­ì¸êµ¬)")
        pop_t = _get_demo_pop(df_target, ["TV"])
        pop_c = _get_demo_pop(df_comp,   ["TV"])
        df_bar = pd.DataFrame({target_name: pop_t, comp_name: pop_c}).fillna(0).reset_index()
        df_melt = df_bar.melt(id_vars="label", var_name="êµ¬ë¶„", value_name="ì¸êµ¬ìˆ˜")
        
        sort_map = {col: i for i, col in enumerate(DEMO_COLS_ORDER)}
        df_melt["s"] = df_melt["label"].map(sort_map).fillna(999)
        df_melt = df_melt.sort_values("s")
        
        if not df_melt.empty:
            fig_tv = px.bar(df_melt, x="label", y="ì¸êµ¬ìˆ˜", color="êµ¬ë¶„", barmode="group",
                            color_discrete_map={target_name: "#d93636", comp_name: comp_color},
                            text="ì¸êµ¬ìˆ˜")
            fig_tv.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_tv.update_layout(height=300, margin=dict(t=30), legend=dict(title=None, orientation="h", y=1.02),
                                 xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_tv, use_container_width=True)
        else:
            st.info("ë°ì´í„° ì—†ìŒ")

    with col_pop_tving:
        # [ìˆ˜ì •] TVING LIVE, TVING VOD, TVING QUICK ëª¨ë‘ í¬í•¨í•˜ë˜ í‘œê¸°ëŠ” "í‹°ë¹™"
        st.markdown("###### â–¶ï¸ TVING (í‰ê·  ì‹œì²­ì¸êµ¬)")
        tving_ms = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        pop_t = _get_demo_pop(df_target, tving_ms)
        pop_c = _get_demo_pop(df_comp,   tving_ms)
        df_bar = pd.DataFrame({target_name: pop_t, comp_name: pop_c}).fillna(0).reset_index()
        df_melt = df_bar.melt(id_vars="label", var_name="êµ¬ë¶„", value_name="ì¸êµ¬ìˆ˜")
        
        sort_map = {col: i for i, col in enumerate(DEMO_COLS_ORDER)}
        df_melt["s"] = df_melt["label"].map(sort_map).fillna(999)
        df_melt = df_melt.sort_values("s")
        
        if not df_melt.empty:
            fig_tv = px.bar(df_melt, x="label", y="ì¸êµ¬ìˆ˜", color="êµ¬ë¶„", barmode="group",
                            color_discrete_map={target_name: "#d93636", comp_name: comp_color},
                            text="ì¸êµ¬ìˆ˜")
            fig_tv.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_tv.update_layout(height=300, margin=dict(t=30), legend=dict(title=None, orientation="h", y=1.02),
                                 xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_tv, use_container_width=True)
        else:
            st.info("ë°ì´í„° ì—†ìŒ")

    st.divider()

    # --- 4. ë””ì§€í„¸ ë¹„êµ (ë„ë„›ì°¨íŠ¸) ---
    st.markdown("#### 4. ë””ì§€í„¸ ë°˜ì‘")
    col_dig_view, col_dig_buzz = st.columns(2)

    def _get_pie_data(df_src, metric):
        if metric == "ì¡°íšŒìˆ˜":
            sub = _get_view_data(df_src) # [3. ê³µí†µ í•¨ìˆ˜]
        else:
            sub = df_src[df_src["metric"] == metric].copy()
        
        if sub.empty: return pd.DataFrame(columns=["ë§¤ì²´", "val"])
        # IP vs Group ìƒí™©ì—ì„œë„ 'ë§¤ì²´ë³„ í‰ê· 'ì´ ì•„ë‹ˆë¼ 'ë§¤ì²´ë³„ ì´ëŸ‰ì˜ ë¹„ì¤‘'ì„ ë´ì•¼í•˜ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì´í•©ì„ êµ¬í•˜ê³  ê·¸ ì•ˆì—ì„œ ë¹„ì¤‘ì„ ë‚˜ëˆ•ë‹ˆë‹¤.
        # ë‹¤ë§Œ, ë„ë„›ì˜ ìŠ¤ì¼€ì¼(í¬ê¸°) ë¹„êµë¥¼ ìœ„í•´ì„  Groupì˜ ê²½ìš° 'í‰ê· ì ì¸ 1ê°œ IPì˜ í¬ê¸°'ë¡œ í™˜ì‚°í•´ì•¼ ê³µì •í•œ ë¹„êµê°€ ë©ë‹ˆë‹¤.
        
        # Step 1: IPë³„, ë§¤ì²´ë³„ í•©ê³„
        per_ip_media = sub.groupby(["IP", "ë§¤ì²´"])["value"].sum().reset_index()
        
        # Step 2: ë§¤ì²´ë³„ë¡œ "IPë“¤ì˜ í‰ê· ê°’" ê³„ì‚° (ì´ê²ƒì´ ê³§ ê·¸ë£¹ì˜ í‰ê· ì ì¸ ëª¨ìŠµ)
        avg_per_media = per_ip_media.groupby("ë§¤ì²´")["value"].mean().reset_index().rename(columns={"value":"val"})
        
        return avg_per_media

    def _draw_scaled_donuts_fixed_color(df_t, df_c, title, t_name, c_name):
        from plotly.subplots import make_subplots
        
        # [ìˆ˜ì •] ìƒ‰ìƒ ê³ ì • ë¡œì§: ëª¨ë“  ë“±ì¥ ë§¤ì²´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì •ë ¬ í›„ ìƒ‰ìƒ í• ë‹¹
        all_media = set(df_t["ë§¤ì²´"].unique()) | set(df_c["ë§¤ì²´"].unique())
        sorted_media = sorted(list(all_media))
        
        # íŒŒìŠ¤í…”í†¤ ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ (ìˆœí™˜)
        base_colors = ['#5c6bc0', '#7e57c2', '#26a69a', '#66bb6a', '#ffa726', '#ef5350', '#8d6e63', '#78909c']
        color_map = {m: base_colors[i % len(base_colors)] for i, m in enumerate(sorted_media)}
        
        # ê° ë°ì´í„°í”„ë ˆì„ì— ìƒ‰ìƒ ì»¬ëŸ¼ ì¶”ê°€
        df_t["color"] = df_t["ë§¤ì²´"].map(color_map)
        df_c["color"] = df_c["ë§¤ì²´"].map(color_map)

        fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]],
                            subplot_titles=[f"{t_name}", f"{c_name}"])
        
        sum_t = df_t["val"].sum() if not df_t.empty else 0
        sum_c = df_c["val"].sum() if not df_c.empty else 0
        
        if not df_t.empty:
            fig.add_trace(go.Pie(
                labels=df_t["ë§¤ì²´"], values=df_t["val"], 
                name=t_name, scalegroup='one', hole=0.4,
                title=f"Total<br>{_fmt_kor_large(sum_t)}", title_font=dict(size=14),
                marker=dict(colors=df_t["color"]), # ê³ ì •ëœ ìƒ‰ìƒ ì ìš©
                domain=dict(column=0),
                sort=False # ë§¤ì²´ ì •ë ¬ ìˆœì„œ ìœ ì§€ (ë˜ëŠ” colors ë¦¬ìŠ¤íŠ¸ ìˆœì„œì™€ ë°ì´í„° ìˆœì„œ ì¼ì¹˜ í•„ìš”)
            ), 1, 1)
        
        if not df_c.empty:
            fig.add_trace(go.Pie(
                labels=df_c["ë§¤ì²´"], values=df_c["val"], 
                name=c_name, scalegroup='one', hole=0.4,
                title=f"Total<br>{_fmt_kor_large(sum_c)}", title_font=dict(size=14),
                marker=dict(colors=df_c["color"]), # ê³ ì •ëœ ìƒ‰ìƒ ì ìš©
                domain=dict(column=1),
                sort=False
            ), 1, 2)
        
        # [ìˆ˜ì •] ë²”ë¡€ ê°€ìš´ë° ì •ë ¬
        fig.update_layout(height=320, margin=dict(t=30, b=10, l=10, r=10),
                          legend=dict(orientation="h", y=-0.15, x=0.5, xanchor="center"))
        return fig

    with col_dig_view:
        st.markdown("###### ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜ ë¹„êµ")
        pie_t = _get_pie_data(df_target, "ì¡°íšŒìˆ˜")
        pie_c = _get_pie_data(df_comp,   "ì¡°íšŒìˆ˜")
        
        if pie_t.empty and pie_c.empty:
            st.info("ë°ì´í„° ì—†ìŒ")
        else:
            fig_pie = _draw_scaled_donuts_fixed_color(pie_t, pie_c, "ì¡°íšŒìˆ˜", target_name, comp_name)
            st.plotly_chart(fig_pie, use_container_width=True)

    with col_dig_buzz:
        st.markdown("###### ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰ ë¹„êµ")
        pie_t = _get_pie_data(df_target, "ì–¸ê¸‰ëŸ‰")
        pie_c = _get_pie_data(df_comp,   "ì–¸ê¸‰ëŸ‰")
        
        if pie_t.empty and pie_c.empty:
            st.info("ë°ì´í„° ì—†ìŒ")
        else:
            fig_pie = _draw_scaled_donuts_fixed_color(pie_t, pie_c, "ì–¸ê¸‰ëŸ‰", target_name, comp_name)
            st.plotly_chart(fig_pie, use_container_width=True)


# ===== 10.5. [í˜ì´ì§€ 4] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_comparison():
    df_all = load_data() # [3. ê³µí†µ í•¨ìˆ˜]
    try: 
        kpi_percentiles = get_kpi_data_for_all_ips(df_all) # [10.1. í•¨ìˆ˜]
    except Exception as e: 
        st.error(f"KPI ë°±ë¶„ìœ„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        kpi_percentiles = pd.DataFrame() 

    filter_cols = st.columns([3, 2, 3, 3])
    ip_options = sorted(df_all["IP"].dropna().unique().tolist())
    selected_ip1 = None
    selected_ip2 = None
    selected_group_criteria = None

    with filter_cols[0]:
        st.markdown("## âš–ï¸ IPê°„ ë¹„êµë¶„ì„")
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ / íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì—…ë°ì´íŠ¸ ì˜ˆì •
        - **í‹°ë¹™ VOD** `íšŒì°¨í‰ê· `: í‹°ë¹™ VOD + QUICK í•©ì‚°
        - **ë””ì§€í„¸ ì¡°íšŒ/ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•©
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ í‰ê· 
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)

    with filter_cols[1]:
        comparison_mode = st.radio(
            "ë¹„êµ ëª¨ë“œ", 
            ["IP vs IP", "IP vs ê·¸ë£¹ í‰ê· "], 
            index=1, horizontal=True, label_visibility="collapsed"
        ) 
    
    with filter_cols[2]:
        selected_ip1 = st.selectbox(
            "ê¸°ì¤€ IP", 
            ip_options, index=0 if ip_options else None, 
            label_visibility="collapsed"
        )

    with filter_cols[3]:
        if comparison_mode == "IP vs IP":
            ip_options_2 = [ip for ip in ip_options if ip != selected_ip1]
            selected_ip2 = st.selectbox(
                "ë¹„êµ IP", 
                ip_options_2, 
                index=1 if len(ip_options_2) > 1 else (0 if len(ip_options_2) > 0 else None), 
                label_visibility="collapsed"
            )
        else:
            selected_group_criteria = st.multiselect(
                "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€", 
                ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"], 
                default=["ë™ì¼ í¸ì„±"], label_visibility="collapsed"
            )

    st.divider()

    # --- ë°ì´í„° ì¤€ë¹„ ë° ë Œë”ë§ ---
    if not selected_ip1:
        st.info("ê¸°ì¤€ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    df_target = df_all[df_all["IP"] == selected_ip1].copy()
    kpis_target = get_agg_kpis_for_ip_page4(df_target)

    if comparison_mode == "IP vs ê·¸ë£¹ í‰ê· ":
        if not selected_group_criteria:
            st.warning("ë¹„êµ ê·¸ë£¹ ê¸°ì¤€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ê·¸ë£¹ ë°ì´í„° í•„í„°ë§
        group_name_parts = []
        df_comp = df_all.copy()
        
        ip_prog = df_target["í¸ì„±"].dropna().mode().iloc[0] if not df_target["í¸ì„±"].dropna().empty else None
        date_col = "ë°©ì˜ì‹œì‘ì¼" if "ë°©ì˜ì‹œì‘ì¼" in df_target.columns else "ì£¼ì°¨ì‹œì‘ì¼"
        ip_year = df_target[date_col].dropna().dt.year.mode().iloc[0] if not df_target[date_col].dropna().empty else None

        if "ë™ì¼ í¸ì„±" in selected_group_criteria:
            if ip_prog:
                df_comp = df_comp[df_comp["í¸ì„±"] == ip_prog]
                group_name_parts.append(f"'{ip_prog}'")
            else: st.warning("í¸ì„± ì •ë³´ ì—†ìŒ (ì œì™¸)")
        
        if "ë°©ì˜ ì—°ë„" in selected_group_criteria:
            if ip_year:
                df_comp = df_comp[df_comp[date_col].dt.year == ip_year]
                group_name_parts.append(f"{int(ip_year)}ë…„")
            else: st.warning("ì—°ë„ ì •ë³´ ì—†ìŒ (ì œì™¸)")
            
        if not group_name_parts:
            st.error("ë¹„êµ ê·¸ë£¹ì„ ì •ì˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
            
        comp_name = " & ".join(group_name_parts) + " í‰ê· "
        kpis_comp = get_agg_kpis_for_ip_page4(df_comp)
        
        # KPI Row
        _render_kpi_row_ip_vs_group(kpis_target, kpis_comp, comp_name)
        
        # Unified Charts (Comp Group = Grey)
        _render_unified_charts(df_target, df_comp, selected_ip1, comp_name, kpi_percentiles, comp_color="#aaaaaa")

    else: # IP vs IP
        if not selected_ip2:
            st.warning("ë¹„êµí•  IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
            
        df_comp = df_all[df_all["IP"] == selected_ip2].copy()
        kpis_comp = get_agg_kpis_for_ip_page4(df_comp)
        comp_name = selected_ip2
        
        # KPI Row
        _render_kpi_row_ip_vs_ip(kpis_target, kpis_comp, selected_ip1, selected_ip2)
        
        # Unified Charts (Comp IP = Grey)
        _render_unified_charts(df_target, df_comp, selected_ip1, comp_name, kpi_percentiles, comp_color="#aaaaaa")
#endregion


#region [ 11. í˜ì´ì§€ 5: íšŒì°¨ë³„ ë¹„êµ ]
# =====================================================
# [ìˆ˜ì •] ê¸°ì¡´ Region 12

# ===== 11.1. [í˜ì´ì§€ 5] íŠ¹ì • íšŒì°¨ ë°ì´í„° ì²˜ë¦¬ =====
def filter_data_for_episode_comparison(
    df_all_filtered: pd.DataFrame,
    selected_episode: str,
    selected_metric: str
) -> pd.DataFrame:
    """íŠ¹ì • íšŒì°¨ ë¹„êµë¥¼ ìœ„í•œ ë°ì´í„° í•„í„°ë§ ë° ì§‘ê³„ (í•„í„°ë§ëœ IP ëŒ€ìƒ)"""
    episode_num_str = str(selected_episode).strip().split()[0]
    target_episode_num_str = ''.join(ch for ch in episode_num_str if ch.isdigit() or ch == '.')
    try:
        target_episode_num = float(target_episode_num_str)
    except ValueError:
        return pd.DataFrame({'IP': df_all_filtered["IP"].unique(), 'value': 0})

    if "íšŒì°¨_numeric" in df_all_filtered.columns:
        base_filtered = df_all_filtered[df_all_filtered["íšŒì°¨_numeric"] == target_episode_num].copy()
    else:
        base_filtered = pd.DataFrame()
    if base_filtered.empty and "íšŒì°¨" in df_all_filtered.columns:
        possible_strs = [f"{int(target_episode_num)}í™”", f"{int(target_episode_num)}ì°¨"]
        mask = df_all_filtered["íšŒì°¨"].isin(possible_strs)
        base_filtered = df_all_filtered[mask].copy()

    result_df = pd.DataFrame(columns=["IP", "value"])

    if not base_filtered.empty:
        if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].mean().reset_index()

        elif selected_metric == "TVING ë¼ì´ë¸Œ+QUICK":
            df_lq = base_filtered[
                (base_filtered["metric"] == "ì‹œì²­ì¸êµ¬") &
                (base_filtered["ë§¤ì²´"].isin(["TVING LIVE", "TVING QUICK"]))]
            if not df_lq.empty:
                result_df = df_lq.groupby("IP")["value"].sum().reset_index()

        elif selected_metric == "TVING VOD":
            df_vod = base_filtered[
                (base_filtered["metric"] == "ì‹œì²­ì¸êµ¬") &
                (base_filtered["ë§¤ì²´"] == "TVING VOD")]
            if not df_vod.empty:
                result_df = df_vod.groupby("IP")["value"].sum().reset_index()
        
        # [ìˆ˜ì •] í”¼ë“œë°± 3ë²ˆ ë°˜ì˜: _get_view_data í•¨ìˆ˜ ì‚¬ìš©
        elif selected_metric == "ì¡°íšŒìˆ˜":
            filtered = _get_view_data(base_filtered) # [3. ê³µí†µ í•¨ìˆ˜]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].sum().reset_index()

        elif selected_metric == "ì–¸ê¸‰ëŸ‰":
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].sum().reset_index()

        else:  # ê¸°íƒ€ ì§€í‘œ (F_Score, F_Total ë“±)
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].mean().reset_index()

    all_ips_in_filter = df_all_filtered["IP"].unique()
    if result_df.empty:
        result_df = pd.DataFrame({'IP': all_ips_in_filter, 'value': 0})
    else:
        result_df = result_df.set_index("IP").reindex(all_ips_in_filter, fill_value=0).reset_index()
    result_df['value'] = pd.to_numeric(result_df['value'], errors='coerce').fillna(0)
    return result_df.sort_values("value", ascending=False)


# ===== 11.2. [í˜ì´ì§€ 5] íŠ¹ì • íšŒì°¨ ë¹„êµ ì‹œê°í™” =====
def plot_episode_comparison(
    df_result: pd.DataFrame,
    selected_metric: str,
    selected_episode: str,
    base_ip: str
):
    """íŠ¹ì • íšŒì°¨ ë¹„êµ ê²°ê³¼ ì‹œê°í™” (Bar Chart with Highlight)"""
    colors = ['#d93636' if ip == base_ip else '#666666' for ip in df_result['IP']]
    metric_label = selected_metric.replace("Tì‹œì²­ë¥ ", "íƒ€ê¹ƒ").replace("Hì‹œì²­ë¥ ", "ê°€êµ¬")

    fig = px.bar(
        df_result,
        x="IP",
        y="value",
        text="value",
        title=f"{selected_episode} - '{metric_label}' (ê¸°ì¤€: {base_ip})"
    )

    if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
        hover_template = "<b>%{x}</b><br>" + metric_label + ": %{y:.2f}%<extra></extra>"
    else:
        hover_template = "<b>%{x}</b><br>" + metric_label + ": %{y:,}<extra></extra>"

    fig.update_traces(
        marker_color=colors,
        textposition='outside',
        hovertemplate=hover_template
    )

    if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
        fig.update_traces(texttemplate='%{text:.2f}%')
        fig.update_layout(yaxis_title=metric_label + " (%)")
    else:
        fig.update_traces(texttemplate='%{text:,.0f}')
        fig.update_layout(yaxis_title=metric_label)

    fig.update_layout(
        xaxis_title=None,
        xaxis=dict(tickfont=dict(size=11)),
        height=350,
        margin=dict(t=40, b=0, l=0, r=0)
    )
    st.plotly_chart(fig, use_container_width=True)


# ===== 11.3. [í˜ì´ì§€ 5] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_episode():
    df_all = load_data() # [3. ê³µí†µ í•¨ìˆ˜]

    filter_cols = st.columns([3, 3, 2, 3])
    ip_options_main = sorted(df_all["IP"].dropna().unique().tolist())
    episode_options_main = get_episode_options(df_all)  # [3. ê³µí†µ í•¨ìˆ˜]

    with filter_cols[0]:
        st.markdown("## ğŸ¬ íšŒì°¨ë³„ ë¹„êµ")

    with filter_cols[1]:
        selected_base_ip = st.selectbox(
            "ê¸°ì¤€ IP (í•˜ì´ë¼ì´íŠ¸)",
            ip_options_main,
            index=0 if ip_options_main else None,
            label_visibility="collapsed",
            key="ep_base_ip_main"
        )

    with filter_cols[2]:
        selected_episode = st.selectbox(
            "íšŒì°¨",
            episode_options_main,
            index=0 if episode_options_main else None,
            label_visibility="collapsed",
            key="ep_selected_episode_main"
        )

    with filter_cols[3]:
        selected_group_criteria = st.multiselect(
            "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"],
            default=["ë™ì¼ í¸ì„±"],
            label_visibility="collapsed",
            key="ep_group_criteria"
        )

    st.divider()

    if not selected_base_ip or not selected_episode:
        st.warning("í•„í„°ì—ì„œ ê¸°ì¤€ IPì™€ íšŒì°¨ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    df_filtered_main = df_all.copy()
    group_filter_applied = []

    if selected_group_criteria:
        base_rows = df_all[df_all["IP"] == selected_base_ip]
        if not base_rows.empty:
            base_prog = base_rows["í¸ì„±"].dropna().mode().iloc[0] if not base_rows["í¸ì„±"].dropna().empty else None
            date_col = "ë°©ì˜ì‹œì‘ì¼" if ("ë°©ì˜ì‹œì‘ì¼" in df_all.columns and df_all["ë°©ì˜ì‹œì‘ì¼"].notna().any()) else "ì£¼ì°¨ì‹œì‘ì¼"
            base_year = base_rows[date_col].dropna().dt.year.mode().iloc[0] if not base_rows[date_col].dropna().empty else None

            if "ë™ì¼ í¸ì„±" in selected_group_criteria and base_prog:
                df_filtered_main = df_filtered_main[df_filtered_main["í¸ì„±"] == base_prog]
                group_filter_applied.append(f"í¸ì„±='{base_prog}'")
            elif "ë™ì¼ í¸ì„±" in selected_group_criteria and not base_prog:
                st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}'ì˜ í¸ì„± ì •ë³´ ì—†ìŒ")

            if "ë°©ì˜ ì—°ë„" in selected_group_criteria and base_year:
                df_filtered_main = df_filtered_main[df_filtered_main[date_col].dt.year == int(base_year)]
                group_filter_applied.append(f"ì—°ë„={int(base_year)}")
            elif "ë°©ì˜ ì—°ë„" in selected_group_criteria and not base_year:
                st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}'ì˜ ì—°ë„ ì •ë³´ ì—†ìŒ")
        else:
            st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            df_filtered_main = pd.DataFrame()

    if df_filtered_main.empty:
        st.warning("ì„ íƒí•˜ì‹  í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if selected_base_ip not in df_filtered_main["IP"].unique():
        st.warning("ì„ íƒí•˜ì‹  ê·¸ë£¹ ì¡°ê±´ì— ê¸°ì¤€ IPê°€ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    key_metrics = ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "TVING ë¼ì´ë¸Œ+QUICK", "TVING VOD", "ì¡°íšŒìˆ˜", "ì–¸ê¸‰ëŸ‰"]
    filter_desc = " (" + ", ".join(group_filter_applied) + ")" if group_filter_applied else " (ì „ì²´ IP)"
    st.markdown(f"#### {selected_episode} ì„±ê³¼ ë¹„êµ{filter_desc} (ê¸°ì¤€ IP: {selected_base_ip})")
    st.caption("ì„ íƒëœ IP ê·¸ë£¹ì˜ ì„±ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°ì¤€ IPëŠ” ë¶‰ì€ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
    st.markdown("---")

    chart_cols = st.columns(2)
    for i, metric in enumerate(key_metrics):
        with chart_cols[i % 2]:
            # [ìˆ˜ì •] ê° ì°¨íŠ¸ í•­ëª©ì„ ë³„ë„ì˜ 1-column ë ˆì´ì•„ì›ƒìœ¼ë¡œ ê°ì‹¸ (stVerticalBlockBorderWrapperë¥¼ ê°•ì œë¡œ ìƒì„±)
            inner_col, = st.columns(1)
            with inner_col:
                try:
                    df_result = filter_data_for_episode_comparison(df_filtered_main, selected_episode, metric) # [11.1. í•¨ìˆ˜]
                    if df_result.empty or df_result['value'].isnull().all() or (df_result['value'] == 0).all():
                        metric_label = metric.replace("Tì‹œì²­ë¥ ", "íƒ€ê¹ƒ").replace("Hì‹œì²­ë¥ ", "ê°€êµ¬")
                        st.markdown(f"###### {selected_episode} - '{metric_label}'")
                        st.info("ë°ì´í„° ì—†ìŒ")
                        st.markdown("---")
                    else:
                        plot_episode_comparison(df_result, metric, selected_episode, selected_base_ip) # [11.2. í•¨ìˆ˜]
                        st.markdown("---")
                except Exception as e:
                    st.error(f"ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜({metric}): {e}")

#endregion


#region [ 12. í˜ì´ì§€ 6: ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì„±ê³¼ ]
# =====================================================
# [ìˆ˜ì •] 2025-11-13: íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ ê³„ì‚° ë¡œì§ ìµœì í™” (ëˆ„ë½ëœ ì¢…í•©ë“±ê¸‰ ì»¬ëŸ¼ ìƒì„± ì¶”ê°€)
def render_growth_score():
    """
    [í˜ì´ì§€ 6] ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ ë Œë”ë§ í•¨ìˆ˜
    """
    df_all = load_data().copy() # [3. ê³µí†µ í•¨ìˆ˜]

    # ---------- ì„¤ì • ----------
    EP_CHOICES = [2, 4, 6, 8, 10, 12, 14, 16]
    ROW_LABELS = ["S","A","B","C","D"]
    COL_LABELS = ["+2","+1","0","-1","-2"]
    ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
    SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}
    SLOPE_LABELS = ["+2", "+1", "0", "-1", "-2"]
    NETFLIX_VOD_FACTOR = 1.4
    ABS_NUM = {"S":5, "A":4, "B":3, "C":2, "D":1} # íšŒì°¨ë³„ ì¶”ì´ìš©

    METRICS = [
        ("ê°€êµ¬ì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", None),
        ("íƒ€ê¹ƒì‹œì²­ë¥ ", "Tì‹œì²­ë¥ ", None),
        ("TVING LIVE", "ì‹œì²­ì¸êµ¬", "LIVE"),
        ("TVING VOD",  "ì‹œì²­ì¸êµ¬", "VOD"),
    ]

    ips = sorted(df_all["IP"].dropna().unique().tolist())
    if not ips:
        st.warning("IP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    st.markdown("""
    <style>
      div[data-testid="stVerticalBlockBorderWrapper"]:has(.growth-kpi) .kpi-card {
          border-radius:16px;border:1px solid #e7ebf3;background:#fff;padding:12px 14px;
          box-shadow:0 1px 2px rgba(0,0,0,0.04);
      }
      .growth-kpi .kpi-title{font-size:13px;color:#5b6b83;margin-bottom:4px;font-weight:600}
      .growth-kpi .kpi-value{font-weight:800;letter-spacing:-0.2px}
    </style>
    """, unsafe_allow_html=True)

    # ---------- í—¤ë”(íƒ€ì´í‹€/ì„ íƒ) ----------
    _ep_display = st.session_state.get("growth_ep_cutoff", 4)

    head = st.columns([5, 3, 2])
    with head[0]:
        st.markdown(
            f"## ğŸš€ ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ <span style='font-size:20px;color:#6b7b93'>(~{_ep_display}íšŒ ê¸°ì¤€)</span>",
            unsafe_allow_html=True
        )
    with head[1]:
        selected_ip = st.selectbox(
            "IP ì„ íƒ", ips, index=0,
            key="growth_ip_select", label_visibility="collapsed"
        )
    with head[2]:
        ep_cutoff = st.selectbox(
            "íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1,
            key="growth_ep_cutoff", label_visibility="collapsed"
        )

    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("""
    **ë“±ê¸‰ ì²´ê³„**
    - **ì ˆëŒ€ê°’ ë“±ê¸‰**: ê° ì§€í‘œì˜ ì ˆëŒ€ ìˆ˜ì¤€ì„ IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ë¡œ êµ¬ë¶„ â†’ `S / A / B / C / D`
    - **ìƒìŠ¹ë¥  ë“±ê¸‰**: ë™ì¼ ê¸°ê°„(ì„ íƒ íšŒì°¨ ë²”ìœ„) ë‚´ íšŒì°¨-ê°’ ì„ í˜•íšŒê·€ ê¸°ìš¸ê¸°(slope)ë¥¼ IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ë¡œ êµ¬ë¶„ â†’ `+2 / +1 / 0 / -1 / -2`
    - **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€ê°’ê³¼ ìƒìŠ¹ë¥  ë“±ê¸‰ì„ ê²°í•©í•´ í‘œê¸° (ì˜ˆ: `A+2`).

    **ë³´ì •ê¸°ì¤€**
    - ë„·í”Œë¦­ìŠ¤ í¸ì„±ì‘í’ˆì€ ë„·í”Œë¦­ìŠ¤ ë¹„ í¸ì„±ì‘ ëŒ€ë¹„ í‰ê· ì ìœ¼ë¡œ ì•½ 40%ì •ë„ì˜ TVING VODìˆ˜ì¹˜ì˜ ì†ì‹¤ì´ ìˆìœ¼ë©°, ê·¸ì— ë”°ë¼ ë“±ê¸‰ì‚°ì¶œì‹œ 40%ë³´ì •
            """)

    st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>",
            unsafe_allow_html=True
        )

    # ---------- [ìµœì í™”] ë°ì´í„° ì „ì²˜ë¦¬ ë° ê³„ì‚° ë¡œì§ ë¶„ë¦¬ ----------
    
    # 1. ì „ì²´ IPì— ëŒ€í•´ íšŒì°¨ë³„ ìˆ«ìí˜• ì»¬ëŸ¼ ìƒì„± (Loop ë°–ì—ì„œ ì²˜ë¦¬)
    if "íšŒì°¨_numeric" not in df_all.columns:
        df_all["íšŒì°¨_numeric"] = df_all["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False).astype(float)
    
    # 2. IPë³„ ë°ì´í„°í”„ë ˆì„ ë”•ì…”ë„ˆë¦¬ ìƒì„± (í•„í„°ë§ ë¹„ìš© ì ˆê°)
    ip_dfs = {ip: df_all[df_all["IP"] == ip].copy() for ip in ips}

    # 3. [Helper] ì „ì²´ ë°ì´í„°ë¥¼ Numpy Arrayë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    def _get_full_series(ip_df, metric, media):
        """íŠ¹ì • IP, Metricì˜ ì „ì²´ íšŒì°¨ ë°ì´í„°ë¥¼ (x, y) Numpy Arrayë¡œ ë°˜í™˜"""
        sub = ip_df[ip_df["metric"] == metric].copy()
        
        if media == "LIVE":
            sub = sub[sub["ë§¤ì²´"] == "TVING LIVE"]
        elif media == "VOD":
            sub = sub[sub["ë§¤ì²´"] == "TVING VOD"]
            # ë„·í”Œë¦­ìŠ¤ ë³´ì •
            if "ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘" in sub.columns:
                is_netflix = (sub["ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘"] == 1)
                if is_netflix.any():
                    sub.loc[is_netflix, "value"] = pd.to_numeric(sub.loc[is_netflix, "value"], errors="coerce") * NETFLIX_VOD_FACTOR

        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        
        if sub.empty: return None
        
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            s = sub.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        else:
            s = sub.groupby("íšŒì°¨_numeric")["value"].sum().reset_index()
            
        s = s.sort_values("íšŒì°¨_numeric")
        return s["íšŒì°¨_numeric"].values.astype(float), s["value"].values.astype(float)

    # 4. [Pre-Calculation] ëª¨ë“  IPì˜ Metricë³„ ì „ì²´ (x, y) ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì¶”ì¶œ
    ip_metric_cache = {}
    for ip in ips:
        ip_metric_cache[ip] = {}
        curr_df = ip_dfs[ip]
        for disp, metric, media in METRICS:
            ip_metric_cache[ip][disp] = _get_full_series(curr_df, metric, media)

    # 5. [Calculation] Numpy Slicingì„ ì´ìš©í•œ í†µê³„ ê³„ì‚°
    def _calc_stats_from_cache(xy_tuple, n_cutoff, metric_type):
        if xy_tuple is None: return np.nan, np.nan
        
        x, y = xy_tuple
        mask = x <= float(n_cutoff)
        x_sub, y_sub = x[mask], y[mask]
        
        if len(x_sub) == 0: return np.nan, np.nan
        
        # Abs Value
        if metric_type in ["ê°€êµ¬ì‹œì²­ë¥ ", "íƒ€ê¹ƒì‹œì²­ë¥ "]:
            abs_val = np.mean(y_sub)
        else:
            abs_val = np.mean(y_sub)
            
        # Slope
        if len(x_sub) < 2:
            slope = np.nan
        else:
            try:
                slope = np.polyfit(x_sub, y_sub, 1)[0]
            except:
                slope = np.nan
        return abs_val, slope

    def _quintile_grade(series, labels):
        s = pd.Series(series).astype(float)
        valid = s.dropna()
        if valid.empty: return pd.Series(index=s.index, data=np.nan)
        ranks = valid.rank(method="average", ascending=False, pct=True)
        bins = [0, .2, .4, .6, .8, 1.0000001]
        idx = np.digitize(ranks.values, bins, right=True) - 1
        idx = np.clip(idx, 0, 4)
        out = pd.Series([labels[i] for i in idx], index=valid.index)
        return out.reindex(s.index)

    def _to_percentile(s):
        s = pd.Series(s).astype(float)
        return s.rank(pct=True) * 100

    # ---------- [ë©”ì¸ ë¡œì§] íšŒì°¨ë³„ ë“±ê¸‰ ì‚°ì¶œ (Loop Optimized) ----------
    
    sel_ip_df = ip_dfs[selected_ip]
    if "íšŒì°¨_numeric" in sel_ip_df.columns:
        _max_ep_val = pd.to_numeric(sel_ip_df["íšŒì°¨_numeric"], errors="coerce").max()
    else:
        _max_ep_val = 0
    
    if pd.isna(_max_ep_val) or _max_ep_val == 0:
        _Ns = [min(EP_CHOICES)]
    else:
        _Ns = [n for n in EP_CHOICES if n <= _max_ep_val]
    
    needed_cutoffs = set(_Ns)
    needed_cutoffs.add(ep_cutoff)
    sorted_cutoffs = sorted(list(needed_cutoffs))

    evo_rows = []
    base_for_current_cutoff = None 

    # í†µí•© Loop
    for n in sorted_cutoffs:
        tmp_rows = []
        for ip in ips:
            row = {"IP": ip}
            for disp, _, _ in METRICS:
                xy = ip_metric_cache[ip][disp]
                abs_v, slope_v = _calc_stats_from_cache(xy, n, disp)
                row[f"{disp}_ì ˆëŒ€"] = abs_v
                row[f"{disp}_ê¸°ìš¸ê¸°"] = slope_v
            tmp_rows.append(row)
        
        tmp_df = pd.DataFrame(tmp_rows)
        
        # ë“±ê¸‰ ì‚°ì • (ì—¬ê¸°ì— [disp]_ì¢…í•© ìƒì„± ë¡œì§ ì¶”ê°€ë¨)
        for disp, _, _ in METRICS:
            tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ì ˆëŒ€"], ["S","A","B","C","D"])
            tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
            # [ì¤‘ìš”] ëˆ„ë½ë˜ì—ˆë˜ ì¢…í•© ë“±ê¸‰ ì»¬ëŸ¼ ìƒì„± ì½”ë“œ ë³µêµ¬
            tmp_df[f"{disp}_ì¢…í•©"] = tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")
        
        tmp_df["_ABS_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ì ˆëŒ€"]) for d,_,_ in METRICS], axis=1).mean(axis=1)
        tmp_df["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_ in METRICS], axis=1).mean(axis=1)
        tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df["_ABS_PCT_MEAN"], ["S","A","B","C","D"])
        tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df["_SLOPE_PCT_MEAN"], SLOPE_LABELS)
        tmp_df["ì¢…í•©ë“±ê¸‰"] = tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")

        # í˜„ì¬ Cutoff(ìƒë‹¨ ì¹´ë“œìš©) ë°ì´í„° ì €ì¥
        if n == ep_cutoff:
            base = tmp_df.copy() 

        # ê·¸ë˜í”„ìš© ë°ì´í„° ìˆ˜ì§‘
        if n in _Ns:
            row = tmp_df[tmp_df["IP"] == selected_ip]
            if not row.empty and pd.notna(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]):
                ag = str(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"])
                sg = str(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
                evo_rows.append({
                    "N": n,
                    "íšŒì°¨ë¼ë²¨": f"{n}íšŒì°¨",
                    "ABS_GRADE": ag,
                    "SLOPE_GRADE": sg,
                    "ABS_NUM": ABS_NUM.get(ag, np.nan)
                })

    if 'base' not in locals(): base = tmp_df.copy()

    # ---------- [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ] ----------
    focus = base[base["IP"] == selected_ip].iloc[0]

    st.markdown("<div class='growth-kpi'>", unsafe_allow_html=True)
    card_cols = st.columns([2, 1, 1, 1, 1])
    with card_cols[0]:
        st.markdown(
            f"""
            <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
              <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
              <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
            </div>
            """,
            unsafe_allow_html=True
        )
    def _grade_card(col, title, val):
        with col:
            st.markdown(
                f"""
                <div class="kpi-card" style="height:110px;">
                  <div class="kpi-title">{title}</div>
                  <div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div>
                </div>
                """,
                unsafe_allow_html=True
            )
    _grade_card(card_cols[1], "ê°€êµ¬ì‹œì²­ë¥  ë“±ê¸‰", focus["ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©"])
    _grade_card(card_cols[2], "íƒ€ê¹ƒì‹œì²­ë¥  ë“±ê¸‰", focus["íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©"])
    _grade_card(card_cols[3], "TVING LIVE ë“±ê¸‰", focus["TVING LIVE_ì¢…í•©"])
    _grade_card(card_cols[4], "TVING VOD ë“±ê¸‰",  focus["TVING VOD_ì¢…í•©"])
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)
    
    # ===== [íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´: ì„ íƒ IP] =====
    evo = pd.DataFrame(evo_rows)
    if evo.empty:
        st.info("íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        fig_e = go.Figure()
        fig_e.add_vrect(
            x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5,
            fillcolor="rgba(0,90,200,0.12)", line_width=0
        )
        fig_e.add_trace(go.Scatter(
            x=evo["N"], y=evo["ABS_NUM"],
            mode="lines+markers",
            line=dict(shape="spline", width=3),
            marker=dict(size=8),
            name=selected_ip,
            hoverinfo="skip"
        ))
        for xi, yi, ag, sg in zip(evo["N"], evo["ABS_NUM"], evo["ABS_GRADE"], evo["SLOPE_GRADE"]):
            label = f"{ag}{sg}" if isinstance(ag, str) and sg else ag
            fig_e.add_annotation(
                x=xi, y=yi, text=label, showarrow=False,
                font=dict(size=12, color="#333", family="sans-serif"), yshift=14
            )
        fig_e.update_xaxes(
            tickmode="array",
            tickvals=evo["N"].tolist(),
            ticktext=[f"{int(n)}íšŒì°¨" for n in evo["N"].tolist()],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_yaxes(
            tickmode="array",
            tickvals=[5,4,3,2,1],
            ticktext=["S","A","B","C","D"],
            range=[0.7, 5.3],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_layout(
            height=200,
            margin=dict(l=8, r=8, t=8, b=8),
            showlegend=False
        )
        
        c_evo, = st.columns(1)
        with c_evo:
            st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})

    st.divider()

    # ---------- [í¬ì§€ì…”ë‹ë§µ] ----------
    st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")

    pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
    for _, r in base.iterrows():
        ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
        rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
        if ra in ROW_LABELS and rs in COL_LABELS:
            pos_map[(ra, rs)].append(r["IP"])

    z = []
    for rr in ROW_LABELS:
        row_z = []
        for cc in COL_LABELS:
            row_z.append((ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0)
        z.append(row_z)

    fig = px.imshow(
        z,
        x=COL_LABELS, y=ROW_LABELS,
        origin="upper",
        color_continuous_scale="Blues",
        range_color=[1, 5],
        text_auto=False,
        aspect="auto"
    ).update_traces(xgap=0.0, ygap=0.0)

    fig.update_xaxes(showticklabels=False, title=None, ticks="")
    fig.update_yaxes(showticklabels=False, title=None, ticks="")
    fig.update_layout(
        height=760,
        margin=dict(l=2, r=2, t=2, b=2),
        coloraxis_showscale=False
    )
    fig.update_traces(hovertemplate="<extra></extra>")

    def _font_color(val: float) -> str:
        return "#FFFFFF" if val >= 3.3 else "#111111"

    for r_idx, rr in enumerate(ROW_LABELS):
        for c_idx, cc in enumerate(COL_LABELS):
            cell_val = z[r_idx][c_idx]
            names = pos_map[(rr, cc)]
            color = _font_color(cell_val)

            fig.add_annotation(
                x=cc, y=rr, xref="x", yref="y",
                text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>",
                showarrow=False,
                font=dict(size=22, color=color, family="sans-serif"),
                xanchor="center", yanchor="top",
                xshift=0, yshift=80, align="left"
            )

            if names:
                fig.add_annotation(
                    x=cc, y=rr, xref="x", yref="y",
                    text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>",
                    showarrow=False,
                    font=dict(size=12, color=color, family="sans-serif"),
                    xanchor="center", yanchor="middle",
                    yshift=6
                )
    
    c_posmap, = st.columns(1)
    with c_posmap:
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # ---------- [ì „ì²´í‘œ] ----------
    table = base[[
        "IP","ì¢…í•©_ì ˆëŒ€ë“±ê¸‰","ì¢…í•©_ìƒìŠ¹ë“±ê¸‰","ì¢…í•©ë“±ê¸‰",
        "ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©","TVING LIVE_ì¢…í•©","TVING VOD_ì¢…í•©"
    ]].copy()

    table["_abs_key"]   = table["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].map(ABS_SCORE).fillna(0)
    table["_slope_key"] = table["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].map(SLO_SCORE).fillna(0)
    table = table.sort_values(["_abs_key","_slope_key","IP"], ascending=[False, False, True])

    table_view = table[[
        "IP","ì¢…í•©ë“±ê¸‰","ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©","TVING LIVE_ì¢…í•©","TVING VOD_ì¢…í•©"
    ]].rename(columns={
        "ì¢…í•©ë“±ê¸‰":"ì¢…í•©",
        "ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©":"ê°€êµ¬ì‹œì²­ë¥ ",
        "íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©":"íƒ€ê¹ƒì‹œì²­ë¥ ",
        "TVING LIVE_ì¢…í•©":"TVING LIVE",
        "TVING VOD_ì¢…í•©":"TVING VOD"
    })

    grade_cell = JsCode("""
    function(params){
      try{
        const raw = params.value;
        if (raw === null || raw === undefined) {
          return {'text-align':'center'};
        }
        const v = String(raw);
        let bg=null, color=null, fw='700';
        if (/^[SABCD]/.test(v)) {
          if (v.startsWith('S')) { bg='rgba(0,91,187,0.14)'; color='#003d80'; }
          else if (v.startsWith('A')) { bg='rgba(0,91,187,0.08)'; color='#004a99'; }
          else if (v.startsWith('B')) { bg='rgba(0,0,0,0.03)'; color='#333'; fw='600'; }
          else if (v.startsWith('C')) { bg='rgba(42,97,204,0.08)'; color='#2a61cc'; }
          else if (v.startsWith('D')) { bg='rgba(42,97,204,0.14)'; color='#1a44a3'; }
          return {'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'};
        }
        return {'text-align':'center'};
      } catch (e) {
        return {'text-align':'center'};
      }
    }""")

    gb = GridOptionsBuilder.from_dataframe(table_view.fillna("â€“"))
    gb.configure_default_column(resizable=True, sortable=True, filter=False,
                                headerClass='centered-header bold-header',
                                cellStyle={'textAlign':'center'})
    gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
    for colname in ["ì¢…í•©","ê°€êµ¬ì‹œì²­ë¥ ","íƒ€ê¹ƒì‹œì²­ë¥ ","TVING LIVE","TVING VOD"]:
        gb.configure_column(colname, cellStyle=grade_cell, width=120)
    grid_options = gb.build()

    st.markdown("#### ğŸ“‹ IPì „ì²´")
    AgGrid(
        table_view.fillna("â€“"),
        gridOptions=grid_options,
        theme="streamlit",
        height=420,
        fit_columns_on_grid_load=True,
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )
#endregion


#region [ 13. í˜ì´ì§€ 7: ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸ ]
# =====================================================
# [ìˆ˜ì •] 2025-11-13: íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ ê³„ì‚° ë¡œì§ ìµœì í™” (Pre-fetch + Numpy Slicing)
def render_growth_score_digital():
    """
    [í˜ì´ì§€ 7] ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸ ë Œë”ë§ í•¨ìˆ˜
    """
    df_all = load_data().copy() # [3. ê³µí†µ í•¨ìˆ˜]

    # ---------- ì„¤ì • ----------
    EP_CHOICES = [2, 4, 6, 8, 10, 12, 14, 16]
    ROW_LABELS = ["S","A","B","C","D"]
    COL_LABELS = ["+2","+1","0","-1","-2"]
    ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
    SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}
    ABS_NUM    = {"S":5, "A":4, "B":3, "C":2, "D":1}
    SLOPE_LABELS = ["+2", "+1", "0", "-1", "-2"]

    METRICS = [
        ("ì¡°íšŒìˆ˜", "ì¡°íšŒìˆ˜", "sum", True),
        ("í™”ì œì„±", "F_Score", "mean", True),
    ]

    ips = sorted(df_all["IP"].dropna().unique().tolist())
    if not ips:
        st.warning("IP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    # ---------- í—¤ë”(íƒ€ì´í‹€/ì„ íƒ) ----------
    _ep_display = st.session_state.get("growth_d_ep_cutoff", 4)
    head = st.columns([5, 3, 2])
    with head[0]:
        st.markdown(
            f"## ğŸ›°ï¸ ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸ <span style='font-size:20px;color:#6b7b93'>(~{_ep_display}íšŒ ê¸°ì¤€)</span>",
            unsafe_allow_html=True
        )
    with head[1]:
        selected_ip = st.selectbox("IP ì„ íƒ", ips, index=0,
                                   key="growth_d_ip_select", label_visibility="collapsed")
    with head[2]:
        ep_cutoff = st.selectbox("íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1,
                                 key="growth_d_ep_cutoff", label_visibility="collapsed")

    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("""
**ë””ì§€í„¸ ì§€í‘œ ì •ì˜(ê³ ì •)**
- **ì¡°íšŒìˆ˜, í™”ì œì„±**: íšŒì°¨ë³„ í•©(ì—í”¼ì†Œë“œ ë‹¨ìœ„)ì„ ì‚¬ìš© â†’ 1~NíšŒ ì§‘ê³„ ì‹œê³„ì—´ì˜ í‰ê· /íšŒê·€

**ë“±ê¸‰ ì²´ê³„(ê³µí†µ)**
- **ì ˆëŒ€ê°’ ë“±ê¸‰**: IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ `S/A/B/C/D`
- **ìƒìŠ¹ë¥  ë“±ê¸‰**: íšŒê·€ê¸°ìš¸ê¸° slopeì˜ IP ê°„ ë°±ë¶„ìœ„ 20% `+2/+1/0/-1/-2`
- **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€+ìƒìŠ¹ ê²°í•©(ì˜ˆ: `A+2`)  

**íšŒì°¨ ê¸°ì¤€(~NíšŒ)**
- ê° IPì˜ **1~NíšŒ** ë°ì´í„°ë§Œ ì‚¬ìš©(ì—†ëŠ” íšŒì°¨ ìë™ ì œì™¸)
- 0/ë¹„ì •ìƒê°’ì€ NaN ì²˜ë¦¬í•´ ì™œê³¡ ë°©ì§€
        """)

    st.markdown(
        f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>",
        unsafe_allow_html=True
    )

    # ---------- [ìµœì í™”] ë°ì´í„° ì „ì²˜ë¦¬ ë° ê³„ì‚° ë¡œì§ ë¶„ë¦¬ ----------

    # 1. ì „ì²´ IPì— ëŒ€í•´ íšŒì°¨ë³„ ìˆ«ìí˜• ì»¬ëŸ¼ ìƒì„± (Loop ë°–ì—ì„œ ì²˜ë¦¬)
    if "íšŒì°¨_numeric" not in df_all.columns:
        df_all["íšŒì°¨_numeric"] = df_all["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False).astype(float)
    
    # 2. IPë³„ ë°ì´í„°í”„ë ˆì„ ë”•ì…”ë„ˆë¦¬ ìƒì„± (í•„í„°ë§ ë¹„ìš© ì ˆê°)
    ip_dfs = {ip: df_all[df_all["IP"] == ip].copy() for ip in ips}
    
    # 3. [Helper] ì „ì²´ ë°ì´í„°ë¥¼ Numpy Arrayë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    def _get_full_series_digital(ip_df, metric_name, mtype):
        """íŠ¹ì • IP, Metricì˜ ì „ì²´ íšŒì°¨ ë°ì´í„°ë¥¼ (x, y) Numpy Arrayë¡œ ë°˜í™˜"""
        if metric_name == "ì¡°íšŒìˆ˜":
            sub = _get_view_data(ip_df) # [3. ê³µí†µ í•¨ìˆ˜]
        else:
            sub = ip_df[ip_df["metric"] == metric_name].copy()
            
        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        
        if sub.empty: return None
        
        if mtype == "sum":
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].sum()
        elif mtype == "rank_inv": # ì°¸ê³ ìš© (í˜„ì¬ ë¯¸ì‚¬ìš©)
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].mean()
            s["value"] = -1 * s["value"]
        else:
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].mean()
            
        s = s.sort_values("íšŒì°¨_numeric")
        return s["íšŒì°¨_numeric"].values.astype(float), s["value"].values.astype(float)
    
    # 4. [Pre-Calculation] ëª¨ë“  IPì˜ Metricë³„ ì „ì²´ (x, y) ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì¶”ì¶œ
    ip_metric_cache = {}
    for ip in ips:
        ip_metric_cache[ip] = {}
        curr_df = ip_dfs[ip]
        for disp, metric_name, mtype, _ in METRICS:
            ip_metric_cache[ip][disp] = _get_full_series_digital(curr_df, metric_name, mtype)

    # 5. [Calculation] Numpy Slicingì„ ì´ìš©í•œ í†µê³„ ê³„ì‚°
    def _calc_stats_from_cache_digital(xy_tuple, n_cutoff, use_slope):
        if xy_tuple is None: return np.nan, np.nan
        
        x, y = xy_tuple
        mask = (x >= 1) & (x <= float(n_cutoff))
        x_sub, y_sub = x[mask], y[mask]
        
        if len(x_sub) == 0: return np.nan, np.nan
        
        # Abs Value (Mean of the time series)
        abs_val = float(np.nanmean(y_sub))
        
        # Slope
        if not use_slope or len(x_sub) < 2:
            slope = np.nan
        else:
            try:
                slope = float(np.polyfit(x_sub, y_sub, 1)[0])
            except:
                slope = np.nan
                
        return abs_val, slope

    def _quintile_grade(series, labels):
        s = pd.Series(series).astype(float)
        valid = s.dropna()
        if valid.empty: return pd.Series(index=s.index, data=np.nan)
        ranks = valid.rank(method="average", ascending=False, pct=True)
        bins = [0, .2, .4, .6, .8, 1.0000001]
        idx = np.digitize(ranks.values, bins, right=True) - 1
        idx = np.clip(idx, 0, 4)
        out = pd.Series([labels[i] for i in idx], index=valid.index)
        return out.reindex(s.index)

    def _to_percentile(s):
        s = pd.Series(s).astype(float)
        return s.rank(pct=True) * 100

    # ---------- [ë©”ì¸ ë¡œì§] íšŒì°¨ë³„ ë“±ê¸‰ ì‚°ì¶œ (Loop Optimized) ----------
    
    sel_ip_df = ip_dfs[selected_ip]
    if "íšŒì°¨_numeric" in sel_ip_df.columns:
        _max_ep_val = pd.to_numeric(sel_ip_df["íšŒì°¨_numeric"], errors="coerce").max()
    else:
        _max_ep_val = 0

    if pd.isna(_max_ep_val) or _max_ep_val == 0:
        _Ns = [min(EP_CHOICES)]
    else:
        _Ns = [n for n in EP_CHOICES if n <= _max_ep_val]
    
    needed_cutoffs = set(_Ns)
    needed_cutoffs.add(ep_cutoff)
    sorted_cutoffs = sorted(list(needed_cutoffs))

    evo_rows = []
    base_for_current_cutoff = None

    for n in sorted_cutoffs:
        tmp_rows = []
        for ip in ips:
            row = {"IP": ip}
            for disp, _, _, use_slope in METRICS:
                xy = ip_metric_cache[ip][disp]
                abs_v, slope_v = _calc_stats_from_cache_digital(xy, n, use_slope)
                row[f"{disp}_ì ˆëŒ€"] = abs_v
                row[f"{disp}_ê¸°ìš¸ê¸°"] = slope_v
            tmp_rows.append(row)
        
        tmp_df = pd.DataFrame(tmp_rows)
        
        for disp, _, _, _ in METRICS:
            tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ì ˆëŒ€"], ["S","A","B","C","D"])
            tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
            tmp_df[f"{disp}_ì¢…í•©"] = tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")

        tmp_df["_ABS_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ì ˆëŒ€"]) for d,_,_,_ in METRICS], axis=1).mean(axis=1)
        tmp_df["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_,_ in METRICS], axis=1).mean(axis=1)
        tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df["_ABS_PCT_MEAN"], ["S","A","B","C","D"])
        tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df["_SLOPE_PCT_MEAN"], SLOPE_LABELS)
        tmp_df["ì¢…í•©ë“±ê¸‰"] = tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")

        if n == ep_cutoff:
            base = tmp_df.copy()

        if n in _Ns:
            row = tmp_df[tmp_df["IP"] == selected_ip]
            if not row.empty and pd.notna(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]):
                ag = str(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"])
                sg = str(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
                evo_rows.append({
                    "N": n,
                    "ABS_GRADE": ag,
                    "SLOPE_GRADE": sg,
                    "ABS_NUM": ABS_NUM.get(ag, np.nan)
                })
                
    if 'base' not in locals(): base = tmp_df.copy()

    # ---------- [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ] ----------
    focus = base[base["IP"] == selected_ip].iloc[0]

    st.markdown("<div class='growth-kpi'>", unsafe_allow_html=True) # [ìˆ˜ì •] kpi-card ë˜í¼
    card_cols = st.columns([2, 1, 1, 1, 1])
    with card_cols[0]:
        st.markdown(
            f"""
            <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
              <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
              <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
            </div>
            """, unsafe_allow_html=True
        )
    def _grade_card(col, title, val):
        with col:
            st.markdown(
                f"""
                <div class="kpi-card" style="height:110px;">
                  <div class="kpi-title">{title}</div>
                  <div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div>
                </div>
                """,
                unsafe_allow_html=True
            )
    _grade_card(card_cols[1], "ì¡°íšŒìˆ˜ ë“±ê¸‰", focus["ì¡°íšŒìˆ˜_ì¢…í•©"])
    _grade_card(card_cols[2], "í™”ì œì„± ë“±ê¸‰", focus["í™”ì œì„±_ì¢…í•©"])
    _grade_card(card_cols[3], " ",  " ") # ë¹ˆì¹¸
    _grade_card(card_cols[4], " ",  " ")
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)

    # ===== [íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´: ì„ íƒ IP] =====
    # ì„ íƒëœ IPì˜ ìœ íš¨ íšŒì°¨ í™•ì¸ (ê·¸ë˜í”„ ëŠê¹€ ë°©ì§€ ë“±)
    _v_view = _get_view_data(df_all[df_all["IP"] == selected_ip]) # [3. ê³µí†µ í•¨ìˆ˜]
    _v_view["ep"] = pd.to_numeric(
        _v_view["íšŒì°¨_numeric"] if "íšŒì°¨_numeric" in _v_view.columns
        else _v_view["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False),
        errors="coerce"
    )
    _v_view["val"] = pd.to_numeric(_v_view["value"], errors="coerce").replace(0, np.nan)
    has_ep1 = bool(_v_view.loc[_v_view["ep"] == 1, "val"].notna().any())
    has_ep2 = bool(_v_view.loc[_v_view["ep"] == 2, "val"].notna().any())

    evo = pd.DataFrame(evo_rows)
    if evo.empty:
        st.info("íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        fig_e = go.Figure()
        fig_e.add_vrect(x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5,
                        fillcolor="rgba(0,90,200,0.12)", line_width=0)

        fig_e.add_trace(go.Scatter(
            x=evo["N"], y=evo["ABS_NUM"],
            mode="lines+markers",
            line=dict(shape="spline", width=3),
            marker=dict(size=8),
            name=selected_ip,
            hoverinfo="skip"
        ))
        for xi, yi, ag, sg in zip(evo["N"], evo["ABS_NUM"], evo["ABS_GRADE"], evo["SLOPE_GRADE"]):
            label = f"{ag}{sg}" if isinstance(ag, str) and sg else ag
            if int(xi) == 2 and (not has_ep1 or not has_ep2):
                label = "-"
            fig_e.add_annotation(
                x=xi, y=yi, text=label,
                showarrow=False, font=dict(size=12, color="#333", family="sans-serif"),
                yshift=14
            )
        fig_e.update_xaxes(
            tickmode="array",
            tickvals=evo["N"].tolist(),
            ticktext=[f"{int(n)}íšŒì°¨" for n in evo["N"].tolist()],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_yaxes(
            tickmode="array",
            tickvals=[5,4,3,2,1],
            ticktext=["S","A","B","C","D"],
            range=[0.7, 5.3],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_layout(height=200, margin=dict(l=8, r=8, t=8, b=8), showlegend=False)
        
        c_evo_d, = st.columns(1)
        with c_evo_d:
            st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})

    st.divider()

    # ---------- [í¬ì§€ì…”ë‹ë§µ] ----------
    st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")

    pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
    for _, r in base.iterrows():
        ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
        rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
        if ra in ROW_LABELS and rs in COL_LABELS:
            pos_map[(ra, rs)].append(r["IP"])

    z = []
    for rr in ROW_LABELS:
        row_z = []
        for cc in COL_LABELS:
            row_z.append((ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0)
        z.append(row_z)

    fig = px.imshow(
        z, x=COL_LABELS, y=ROW_LABELS, origin="upper",
        color_continuous_scale="Blues", range_color=[1, 5],
        text_auto=False, aspect="auto"
    ).update_traces(xgap=0.0, ygap=0.0)

    fig.update_xaxes(showticklabels=False, title=None, ticks="")
    fig.update_yaxes(showticklabels=False, title=None, ticks="")
    fig.update_layout(height=760, margin=dict(l=2, r=2, t=2, b=2), coloraxis_showscale=False)
    fig.update_traces(hovertemplate="<extra></extra>")

    def _font_color(val: float) -> str:
        return "#FFFFFF" if val >= 3.3 else "#111111"

    for r_idx, rr in enumerate(ROW_LABELS):
        for c_idx, cc in enumerate(COL_LABELS):
            cell_val = z[r_idx][c_idx]
            names = pos_map[(rr, cc)]
            color = _font_color(cell_val)

            fig.add_annotation(
                x=cc, y=rr, xref="x", yref="y",
                text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>",
                showarrow=False, font=dict(size=22, color=color, family="sans-serif"),
                xanchor="center", yanchor="top",
                xshift=0, yshift=80, align="left"
            )
            if names:
                fig.add_annotation(
                    x=cc, y=rr, xref="x", yref="y",
                    text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>",
                    showarrow=False, font=dict(size=12, color=color, family="sans-serif"),
                    xanchor="center", yanchor="middle",
                    yshift=6
                )

    c_posmap_d, = st.columns(1)
    with c_posmap_d:
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # ---------- [ì „ì²´í‘œ] ----------
    table = base[[
        "IP","ì¢…í•©_ì ˆëŒ€ë“±ê¸‰","ì¢…í•©_ìƒìŠ¹ë“±ê¸‰","ì¢…í•©ë“±ê¸‰",
        "ì¡°íšŒìˆ˜_ì¢…í•©","í™”ì œì„±_ì¢…í•©"
    ]].copy()

    table["_abs_key"]   = table["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].map(ABS_SCORE).fillna(0)
    table["_slope_key"] = table["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].map(SLO_SCORE).fillna(0)
    table = table.sort_values(["_abs_key","_slope_key","IP"], ascending=[False, False, True])

    table_view = table[[
        "IP","ì¢…í•©ë“±ê¸‰","ì¡°íšŒìˆ˜_ì¢…í•©","í™”ì œì„±_ì¢…í•©"
    ]].rename(columns={
        "ì¢…í•©ë“±ê¸‰":"ì¢…í•©",
        "ì¡°íšŒìˆ˜_ì¢…í•©":"ì¡°íšŒìˆ˜",
        "í™”ì œì„±_ì¢…í•©":"í™”ì œì„±",
    })

    grade_cell = JsCode("""
    function(params){
      try{
        const raw = params.value;
        if (raw === null || raw === undefined) {
          return {'text-align':'center'};
        }
        const v = String(raw);
        let bg=null, color=null, fw='700';
        if (/^[SABCD]/.test(v)) {
          if (v.startsWith('S')) { bg='rgba(0,91,187,0.14)'; color='#003d80'; }
          else if (v.startsWith('A')) { bg='rgba(0,91,187,0.08)'; color='#004a99'; }
          else if (v.startsWith('B')) { bg='rgba(0,0,0,0.03)'; color='#333'; fw='600'; }
          else if (v.startsWith('C')) { bg='rgba(42,97,204,0.08)'; color:'#2a61cc'; }
          else if (v.startsWith('D')) { bg='rgba(42,97,204,0.14)'; color:'#1a44a3'; }
          return {'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'};
        }
        return {'text-align':'center'};
      } catch (e) {
        return {'text-align':'center'};
      }
    }""")

    gb = GridOptionsBuilder.from_dataframe(table_view.fillna("â€“"))
    gb.configure_default_column(resizable=True, sortable=True, filter=False,
                                headerClass='centered-header bold-header',
                                cellStyle={'textAlign':'center'})
    gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
    for colname in ["ì¢…í•©","ì¡°íšŒìˆ˜","í™”ì œì„±"]:
        gb.configure_column(colname, cellStyle=grade_cell, width=120)
    grid_options = gb.build()

    st.markdown("#### ğŸ“‹ IPì „ì²´-ë””ì§€í„¸")
    AgGrid(
        table_view.fillna("â€“"),
        gridOptions=grid_options,
        theme="streamlit",
        height=420,
        fit_columns_on_grid_load=True,
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )
#endregion


#region [ 14. ë©”ì¸ ë¼ìš°í„° ]
# =====================================================
# [ìˆ˜ì •] ê¸°ì¡´ Region 15
if st.session_state["page"] == "Overview":
    render_overview() # [ 7. í˜ì´ì§€ 1 ]
elif st.session_state["page"] == "IP ì„±ê³¼":
    render_ip_detail() # [ 8. í˜ì´ì§€ 2 ]
elif st.session_state["page"] == "ë°ëª¨ê·¸ë˜í”½":
    render_demographic() # [ 9. í˜ì´ì§€ 3 ]
elif st.session_state["page"] == "ë¹„êµë¶„ì„":
    render_comparison() # [ 10. í˜ì´ì§€ 4 ]
elif st.session_state["page"] == "íšŒì°¨ë³„":
    render_episode() # [ 11. í˜ì´ì§€ 5 ]
elif st.session_state["page"] == "ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ":
    render_growth_score() # [ 12. í˜ì´ì§€ 6 ]
elif st.session_state["page"] == "ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸":
    render_growth_score_digital() # [ 13. í˜ì´ì§€ 7 ]
else:
    render_overview() # ê¸°ë³¸ê°’ìœ¼ë¡œ Overview ë Œë”ë§
    
#endregion
