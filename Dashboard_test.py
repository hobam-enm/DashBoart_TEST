# ğŸ“Š Overview / IP ì„±ê³¼ ëŒ€ì‹œë³´ë“œ â€” v2.0 


#region [ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ]
# =====================================================
import os
import datetime
import re
from typing import List, Dict, Any, Optional 
import time, uuid
import textwrap

import numpy as np
import pandas as pd
import plotly.express as px
from plotly import graph_objects as go
import plotly.io as pio
import streamlit as st
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode
import gspread
from google.oauth2.service_account import Credentials
#endregion



#region [ 3-1. AgGrid Wrapper (ìë™ ì˜µì…˜ ìƒì„±) ]
try:
    from st_aggrid import AgGrid as __AgGrid_raw
except Exception:
    __AgGrid_raw = None

def __AgGrid_wrapped(df, gridOptions=None, *, format_map=None, cell_renderer_map=None, center=True, default_sortable=True, **kwargs):
    """
    drop-in ëŒ€ì²´:
    - ê¸°ì¡´ AgGrid(df, gridOptions=...)ì€ ê·¸ëŒ€ë¡œ ë™ì‘
    - gridOptions ë¯¸ì§€ì • ì‹œ, build_aggrid_options()ë¡œ ìë™ ìƒì„±
    """
    try:
        from st_aggrid import GridUpdateMode  # just to ensure import path exists
        pass
    except Exception:
        pass

    if gridOptions is None:
        try:
            gridOptions = build_aggrid_options(
                df,
                center=center,
                default_sortable=default_sortable,
                format_map=(format_map or {}),
                cell_renderer_map=(cell_renderer_map or {}),
            )
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ìµœì†Œ ì˜µì…˜ìœ¼ë¡œ í´ë°±
            gridOptions = None
    if __AgGrid_raw is None:
        raise RuntimeError("st_aggrid.AgGrid ê°€ìš©í•˜ì§€ ì•ŠìŒ")
    return __AgGrid_raw(df, gridOptions=gridOptions, **kwargs)

# ê¸°ì¡´ ì´ë¦„ìœ¼ë¡œ ë°”ì¸ë”© (ê¸°ì¡´ í˜¸ì¶œë¶€ ìˆ˜ì • ì—†ì´ë„ ë™ì‘)
AgGrid = __AgGrid_wrapped
#endregion

#region [ 1-0. í˜ì´ì§€ ì„¤ì • â€” ë°˜ë“œì‹œ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ ]
# =====================================================
st.set_page_config(
    page_title="Drama Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)
#endregion


#region [ 1-1. ì…ì¥ê²Œì´íŠ¸ - URL í† í° ì§€ì† ì¸ì¦ ]
# =====================================================
# ìƒˆë¡œê³ ì¹¨/ì¬ì‹¤í–‰ì—ë„ URL ?auth=í† í° ìœ¼ë¡œ ë¡œê·¸ì¸ ìœ ì§€
AUTH_TTL = 12*3600              # 12ì‹œê°„ ìœ ì§€
AUTH_QUERY_KEY = "auth"         # URL ì¿¼ë¦¬ í‚¤

# Streamlit ë²„ì „ í˜¸í™˜ rerun
def _rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()

@st.cache_resource
def _auth_store():
    """ì„œë²„ ë©”ëª¨ë¦¬ ì˜ì† ìºì‹œ: token -> {'ts': issued_at}"""
    return {}

def _now() -> int:
    return int(time.time())

def _issue_token() -> str:
    return uuid.uuid4().hex

def _set_auth_query(token: str):
    """ë¦¬ë¡œë“œ ì—†ì´ URL ì¿¼ë¦¬ì— auth í† í°ì„ ì£¼ì…"""
    try:
        qp = st.query_params
        qp[AUTH_QUERY_KEY] = token
        st.query_params = qp
    except Exception:
        st.experimental_set_query_params(**{AUTH_QUERY_KEY: token})

def _get_auth_query() -> Optional[str]:
    qp = st.query_params
    return qp.get(AUTH_QUERY_KEY)

def _validate_token(token: str) -> bool:
    store = _auth_store()
    ent = store.get(token)
    if not ent:
        return False
    if _now() - ent["ts"] > AUTH_TTL:
        # ë§Œë£Œ â†’ ì œê±°
        del store[token]
        return False
    return True

def _persist_auth(token: str):
    store = _auth_store()
    store[token] = {"ts": _now()}

def _logout():
    """URLì—ì„œ í† í° ì œê±° + ì„œë²„ ì €ì¥ì†Œì—ì„œ ì‚­ì œ + ì„¸ì…˜ ì´ˆê¸°í™”"""
    token = _get_auth_query()
    if token:
        store = _auth_store()
        store.pop(token, None)
    # URLì—ì„œ auth ì œê±°
    try:
        qp = st.query_params
        if AUTH_QUERY_KEY in qp:
            del qp[AUTH_QUERY_KEY]
            st.query_params = qp
    except Exception:
        st.experimental_set_query_params()
    # ì„¸ì…˜ë„ ì´ˆê¸°í™”
    st.session_state.clear()
    _rerun()

def check_password_with_token() -> bool:
    """1) URL í† í°ì´ ìœ íš¨í•˜ë©´ í†µê³¼, 2) ì•„ë‹ˆë©´ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥"""
    # 1) í† í° ê²€ì¦
    token = _get_auth_query()
    if token and _validate_token(token):
        return True

    # 2) ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ UI (ì‚¬ì´ë“œë°”)
    with st.sidebar:
        st.markdown("## ğŸ” ë¡œê·¸ì¸")
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="__pwd__")
        login = st.button("ë¡œê·¸ì¸")

    if login:
        secret_pwd = st.secrets.get("DASHBOARD_PASSWORD")
        if secret_pwd and isinstance(pwd, str) and pwd.strip() == str(secret_pwd).strip():
            new_token = _issue_token()
            _persist_auth(new_token)
            _set_auth_query(new_token)  # URLì— í† í° ë¶€ì—¬ â†’ ìƒˆë¡œê³ ì¹¨ í›„ì—ë„ ìœ ì§€
            _rerun()
        else:
            st.sidebar.warning("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return False

# âœ… ê²Œì´íŠ¸ ì‹¤í–‰(ì•± ë³¸ë¬¸ ì•ì—ì„œ ì°¨ë‹¨)
if not check_password_with_token():
    st.stop()

#endregion



#region [ 2. ê¸°ë³¸ ì„¤ì • ë° ê³µí†µ ìƒìˆ˜ ]
# =====================================================



# ===== ë„¤ë¹„ê²Œì´ì…˜ ì•„ì´í…œ ì •ì˜ (v2.0) =====
NAV_ITEMS = {
    "Overview": "ğŸ“Š Overview",
    "IP ì„±ê³¼": "ğŸ“ˆ IP ì„±ê³¼ ìì„¸íˆë³´ê¸°",
    "ë°ëª¨ê·¸ë˜í”½": "ğŸ‘¥ ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ",
    "ë¹„êµë¶„ì„": "âš–ï¸ ë¹„êµë¶„ì„",
    "ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ": "ğŸš€ ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ",
    "ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸": "ğŸ›°ï¸ ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸",
    "íšŒì°¨ë³„": "ğŸ¬ íšŒì°¨ ë¹„êµ",
}

# ===== ë°ëª¨ ì»¬ëŸ¼ ìˆœì„œ (í˜ì´ì§€ 2, 3ì—ì„œ ê³µí†µ ì‚¬ìš©) =====
DECADES = ["10ëŒ€","20ëŒ€","30ëŒ€","40ëŒ€","50ëŒ€","60ëŒ€"]
DEMO_COLS_ORDER = [f"{d}ë‚¨ì„±" for d in DECADES] + [f"{d}ì—¬ì„±" for d in DECADES]

# ===== â—€â—€â—€ [ì‹ ê·œ] Plotly ê³µí†µ í…Œë§ˆ =====
dashboard_theme = go.Layout(
    paper_bgcolor='rgba(0,0,0,0)',  # ì¹´ë“œ ë°°ê²½ê³¼ ë™ì¼í•˜ê²Œ íˆ¬ëª…
    plot_bgcolor='rgba(0,0,0,0)',   # ì°¨íŠ¸ ë‚´ë¶€ ë°°ê²½ íˆ¬ëª…
    font=dict(family='sans-serif', size=12, color='#333333'),
    title=dict(font=dict(size=16, color="#111"), x=0.05),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='right',
        x=1,
        bgcolor='rgba(0,0,0,0)'
    ),
    margin=dict(l=20, r=20, t=50, b=20), # ê¸°ë³¸ ë§ˆì§„
    xaxis=dict(
        showgrid=False, 
        zeroline=True, 
        zerolinecolor='#e0e0e0', 
        zerolinewidth=1
    ),
    yaxis=dict(
        showgrid=True, 
        gridcolor='#f0f0f0', # ë§¤ìš° ì—°í•œ ê·¸ë¦¬ë“œ
        zeroline=True, 
        zerolinecolor='#e0e0e0'
    ),
    # í…Œë§ˆ ìƒ‰ìƒ (Plotly ê¸°ë³¸ê°’ ì‚¬ìš©. í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
    # colorway=px.colors.qualitative.Plotly 
)
# â—€â—€â—€ [ìˆ˜ì •] go.Layout ê°ì²´ë¥¼ go.layout.Templateìœ¼ë¡œ ê°ì‹¸ì„œ ë“±ë¡
pio.templates['dashboard_theme'] = go.layout.Template(layout=dashboard_theme)
pio.templates.default = 'dashboard_theme'
# =====================================================
#endregion

#region [ 3. ê³µí†µ í•¨ìˆ˜: ë°ì´í„° ë¡œë“œ / ìœ í‹¸ë¦¬í‹° ]
# =====================================================

# ===== â—€â—€â—€ [ìˆ˜ì •] ë°ì´í„° ë¡œë“œ (Streamlit Secrets ì‚¬ìš©) =====
@st.cache_data(ttl=600)
def load_data() -> pd.DataFrame: # url ì¸ìˆ˜ ì œê±°
    """
    Streamlit Secretsë¥¼ ì‚¬ìš©í•˜ì—¬ Google Sheetsì—ì„œ ë°ì´í„°ë¥¼ ì¸ì¦í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤.
    st.secretsì— 'gcp_service_account', 'SHEET_ID', 'GID' (ì›Œí¬ì‹œíŠ¸ ì´ë¦„)ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    # ===== 1. Google Sheets ì¸ì¦ =====
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    
    # st.secretsì—ì„œ gcp_service_account ì •ë³´ ë¡œë“œ
    creds_info = st.secrets["gcp_service_account"]
    creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
    client = gspread.authorize(creds)

    # ===== 2. ë°ì´í„° ë¡œë“œ =====
    try:
        # st.secretsì—ì„œ ì‹œíŠ¸ IDì™€ ì›Œí¬ì‹œíŠ¸ ì´ë¦„(GID í‚¤) ë¡œë“œ
        sheet_id = st.secrets["SHEET_ID"]
        # TOMLì—ì„œ GID = "RAW"ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ, "RAW"ë¼ëŠ” ì´ë¦„ì˜ ì›Œí¬ì‹œíŠ¸ë¥¼ ì—½ë‹ˆë‹¤.
        worksheet_name = st.secrets["GID"] 
        
        spreadsheet = client.open_by_key(sheet_id)
        worksheet = spreadsheet.worksheet(worksheet_name)
        
        # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        data = worksheet.get_all_records() # ì‹œíŠ¸ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´
        df = pd.DataFrame(data)

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"Streamlit Secretsì˜ GID ê°’ ('{worksheet_name}')ì— í•´ë‹¹í•˜ëŠ” ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    except KeyError as e:
        st.error(f"Streamlit Secretsì— í•„ìš”í•œ í‚¤({e})ê°€ ì—†ìŠµë‹ˆë‹¤. TOML ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

    # --- 3. (ì´í•˜ ì›ë³¸ ì½”ë“œì˜ ì „ì²˜ë¦¬ ë¡œì§ ë™ì¼) ---
    
    # --- ë‚ ì§œ íŒŒì‹± ---
    if "ì£¼ì°¨ì‹œì‘ì¼" in df.columns:
        df["ì£¼ì°¨ì‹œì‘ì¼"] = pd.to_datetime(
            df["ì£¼ì°¨ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", # â—€â—€â—€ [ì°¸ê³ ] ì›ë³¸ í¬ë§· ìœ ì§€
            errors="coerce"
        )
    if "ë°©ì˜ì‹œì‘ì¼" in df.columns:
        df["ë°©ì˜ì‹œì‘ì¼"] = pd.to_datetime(
            df["ë°©ì˜ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", # â—€â—€â—€ [ì°¸ê³ ] ì›ë³¸ í¬ë§· ìœ ì§€
            errors="coerce"
        )

    # --- ìˆ«ìí˜• ë°ì´í„° ë³€í™˜ ---
    # gspread.get_all_records()ëŠ” ì´ë¯¸ 1,000ë‹¨ìœ„ ì½¤ë§ˆë‚˜ %ë¥¼ ì œê±°í•˜ê³  ìˆ«ì/ë¬¸ìì—´ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # í•˜ì§€ë§Œ ë§Œì•½ì„ ìœ„í•´ ì›ë³¸ ì½”ë“œì˜ ìˆ«ì ë³€í™˜ ë¡œì§ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    if "value" in df.columns:
        # .astype(str)ì„ ì¶”ê°€í•˜ì—¬ gspreadê°€ ìˆ«ìë¡œ ê°€ì ¸ì˜¨ ê²½ìš°ì—ë„ ì²˜ë¦¬ë˜ë„ë¡ ë³´ì¥
        v = df["value"].astype(str).str.replace(",", "", regex=False).str.replace("%", "", regex=False)
        df["value"] = pd.to_numeric(v, errors="coerce").fillna(0)

    # --- ë¬¸ìì—´ ë°ì´í„° ì •ì œ ---
    for c in ["IP", "í¸ì„±", "ì§€í‘œêµ¬ë¶„", "ë§¤ì²´", "ë°ëª¨", "metric", "íšŒì°¨", "ì£¼ì°¨"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()

    # --- íŒŒìƒ ì»¬ëŸ¼ ìƒì„± ---
    if "íšŒì°¨" in df.columns:
        df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    else:
        df["íšŒì°¨_numeric"] = pd.NA

    return df

# ===== ì¼ë°˜ í¬ë§·íŒ… ìœ í‹¸ =====
def fmt(v, digits=3, intlike=False):
    """
    ìˆ«ì í¬ë§·íŒ… í—¬í¼ (Noneì´ë‚˜ NaNì€ 'â€“'ë¡œ í‘œì‹œ)
    """
    if v is None or pd.isna(v):
        return "â€“"
    return f"{v:,.0f}" if intlike else f"{v:.{digits}f}"

# ===== KPI ì¹´ë“œ ë Œë”ë§ ìœ í‹¸ =====
def kpi(col, title, value):
    """
    Streamlit ì»¬ëŸ¼ ë‚´ì— KPI ì¹´ë“œë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    with col:
        st.markdown(
            f'<div class="kpi-card"><div class="kpi-title">{title}</div>'
            f'<div class="kpi-value">{value}</div></div>',
            unsafe_allow_html=True
        )

# ===== í˜ì´ì§€ ë¼ìš°íŒ… ìœ í‹¸ =====
def get_current_page_default(default="Overview"):
    """
    URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°(?page=...)ì—ì„œ í˜„ì¬ í˜ì´ì§€ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    ì—†ìœ¼ë©´ default ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        qp = st.query_params  # Streamlit ì‹ ë²„ì „
        p = qp.get("page", None)
        if p is None:
            return default
        return p if isinstance(p, str) else p[0]
    except Exception:
        qs = st.experimental_get_query_params()  # êµ¬ë²„ì „ í˜¸í™˜
        return (qs.get("page", [default])[0])

# ===== íšŒì°¨ ì˜µì…˜ ìƒì„± ìœ í‹¸ (í˜ì´ì§€ 5) =====
def get_episode_options(df: pd.DataFrame) -> List[str]:
    """ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì°¨ ëª©ë¡ (ë¬¸ìì—´, '00' ì œì™¸, 'ì°¨'/'í™”' ì œê±°)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    valid_options = []
    # ìˆ«ì íšŒì°¨ ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©
    if "íšŒì°¨_numeric" in df.columns:
        unique_episodes_num = sorted([
            int(ep) for ep in df["íšŒì°¨_numeric"].dropna().unique() if ep > 0 # 0ë³´ë‹¤ í° ê²½ìš°ë§Œ
        ])
        if unique_episodes_num:
            max_ep_num = unique_episodes_num[-1]
            for ep_num in unique_episodes_num: valid_options.append(str(ep_num))
            # ë§ˆì§€ë§‰ íšŒì°¨ ì²˜ë¦¬
            last_ep_str_num = str(max_ep_num)
            if last_ep_str_num in valid_options and valid_options[-1] != last_ep_str_num:
                 valid_options.remove(last_ep_str_num); valid_options.append(last_ep_str_num)
            if len(valid_options) > 0 and "(ë§ˆì§€ë§‰í™”)" not in valid_options[-1]:
                 valid_options[-1] = f"{valid_options[-1]} (ë§ˆì§€ë§‰í™”)"
            return valid_options
        else: return []
    # ìˆ«ì íšŒì°¨ ì»¬ëŸ¼ ì—†ì„ ê²½ìš°
    elif "íšŒì°¨" in df.columns:
        raw_options = sorted(df["íšŒì°¨"].dropna().unique())
        for opt in raw_options:
            # '00'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒ ì œì™¸
            if not opt.startswith("00"):
                cleaned_opt = re.sub(r"[í™”ì°¨]", "", opt) # 'í™”' ë˜ëŠ” 'ì°¨' ì œê±°
                if cleaned_opt.isdigit() and int(cleaned_opt) > 0: 
                    valid_options.append(cleaned_opt)
        # ìˆ«ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        return sorted(list(set(valid_options)), key=lambda x: int(x) if x.isdigit() else float('inf')) 
    else: return []
#endregion

#region [ 4. ê³µí†µ ìŠ¤íƒ€ì¼ ]
# =====================================================
# CSS ìˆ˜ì •: ì „ì²´ì ì¸ ìƒ‰ìƒ í†¤, í°íŠ¸, ì¹´ë“œ ë””ìì¸, ë„¤ë¹„ ë²„íŠ¼ ìŠ¤í‚¨


# [ 4. ê³µí†µ ìŠ¤íƒ€ì¼ ] ë§¨ ì•„ë˜ìª½ì— ì´ ë¸”ë¡ì„ ì¶”ê°€(ë˜ëŠ” ê¸°ì¡´ page-title ìŠ¤íƒ€ì¼ì„ êµì²´)

#endregion



#region [ 5. ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ ]
# =====================================================
# í˜„ì¬ í˜ì´ì§€ ì½ê¸°(ì—†ìœ¼ë©´ Overview)
current_page = get_current_page_default("Overview")
st.session_state["page"] = current_page  # ì„¸ì…˜ ë³´ì¡´

# URLë§Œ ì—…ë°ì´íŠ¸(ë¦¬ë¡œë“œ ì—†ìŒ)
def _set_page_query_param(page_key: str):
    try:
        qp = st.query_params
        qp["page"] = page_key
        st.query_params = qp
    except Exception:
        st.experimental_set_query_params(page=page_key)

# ê·¸ë¼ë””ì–¸íŠ¸ íƒ€ì´í‹€: ë©”ì¸ í…ìŠ¤íŠ¸ë§Œ(ì„œë¸Œíƒ€ì´í‹€ ì œê±°)
def render_gradient_title(main_text: str, emoji: str = "ğŸ¬"):
    st.markdown(
        f"""
        <div class="page-title-wrap">
          <span class="page-title-emoji">{emoji}</span>
          <span class="page-title-main">{main_text}</span>
        </div>
        """,
        unsafe_allow_html=True,
    )

with st.sidebar:
    st.markdown('<div class="sidebar-hr"></div>', unsafe_allow_html=True)

    # ì œëª©/ë¬¸ì˜ â€” ë¦¬ì ¼4 CSSë¡œ ì¤‘ì•™ì •ë ¬ë¨
    render_gradient_title("ë“œë¼ë§ˆ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", emoji="")
    st.markdown(
        "<p class='sidebar-contact' style='font-size:12px; color:gray;'>ë¬¸ì˜ : ë¯¸ë””ì–´)ë””ì§€í„¸ë§ˆì¼€íŒ…íŒ€ ë°ì´í„°íŒŒíŠ¸</p>",
        unsafe_allow_html=True
    )
    st.markdown("<hr style='border:1px solid #eee; margin:0px 0;'>", unsafe_allow_html=True)

    # ğŸ”¹ ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ (ë¦¬ë¡œë“œ ì—†ì´ ì „í™˜)
    # NAV_ITEMSëŠ” dict ê°€ì • (key=í˜ì´ì§€í‚¤, value=í‘œì‹œë¼ë²¨)
    for key, label in NAV_ITEMS.items():
        is_active = (current_page == key)

        # ì²´í¬/ì´ëª¨ì§€ ìë™ ë¶€ì°© ë¡œì§ì€ ì™„ì „ ì œê±° â€” label ê·¸ëŒ€ë¡œ ì‚¬ìš©
        wrapper_cls = "nav-active" if is_active else "nav-inactive"
        st.markdown(f'<div class="{wrapper_cls}">', unsafe_allow_html=True)

        # typeì€ secondaryë¡œ ê³ ì • â†’ ìƒ‰ìƒì€ CSSì—ì„œ .nav-active ë˜ëŠ” primary ì„ íƒìê°€ ê°•ì œ
        clicked = st.button(
            label,
            key=f"navbtn__{key}",
            use_container_width=True,
            type=("primary" if is_active else "secondary")
        )
        st.markdown('</div>', unsafe_allow_html=True)

        if clicked and not is_active:
            st.session_state["page"] = key
            _set_page_query_param(key)
            if hasattr(st, "rerun"): st.rerun()
            else: st.experimental_rerun()
#endregion


#region [ 6. ê³µí†µ ì§‘ê³„ ìœ í‹¸: KPI ê³„ì‚° ]
# =====================================================
def _episode_col(df: pd.DataFrame) -> str:
    """ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” íšŒì°¨ ìˆ«ì ì»¬ëŸ¼ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return "íšŒì°¨_numeric" if "íšŒì°¨_numeric" in df.columns else ("íšŒì°¨_num" if "íšŒì°¨_num" in df.columns else "íšŒì°¨")

def mean_of_ip_episode_sum(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    if sub.empty:
        return None
    ep_col = _episode_col(sub)
    sub = sub.dropna(subset=[ep_col]).copy()
    # â˜† í•µì‹¬: 0 íŒ¨ë”© ì œì™¸
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
    per_ip_mean = ep_sum.groupby("IP")["value"].mean()
    return float(per_ip_mean.mean()) if not per_ip_mean.empty else None


def mean_of_ip_episode_mean(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    if sub.empty:
        return None
    ep_col = _episode_col(sub)
    sub = sub.dropna(subset=[ep_col]).copy()
    # â˜† í•µì‹¬: 0 íŒ¨ë”© ì œì™¸
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
    per_ip_mean = ep_mean.groupby("IP")["value"].mean()
    return float(per_ip_mean.mean()) if not per_ip_mean.empty else None


def mean_of_ip_sums(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    # âœ… [ê·œì¹™ ì¶”ê°€] ì¡°íšŒìˆ˜ í•©ê³„: ë§¤ì²´ê°€ 'ìœ íŠœë¸Œ'ì¼ ë•ŒëŠ” ì„¸ë¶€ì†ì„±1ì´ PGC/UGCë§Œ í¬í•¨
    if metric_name == "ì¡°íšŒìˆ˜" and not sub.empty and "ë§¤ì²´" in sub.columns:
        if "ì„¸ë¶€ì†ì„±1" in sub.columns:
            yt_mask = (sub["ë§¤ì²´"] == "ìœ íŠœë¸Œ")
            attr_mask = sub["ì„¸ë¶€ì†ì„±1"].isin(["PGC", "UGC"])
            sub = sub[~yt_mask | (yt_mask & attr_mask)]
    if sub.empty:
        return None
    # â˜† í•µì‹¬: 0 íŒ¨ë”© ì œì™¸
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    per_ip_sum = sub.groupby("IP")["value"].sum()
    return float(per_ip_sum.mean()) if not per_ip_sum.empty else None


#endregion

#region [ 7. ê³µí†µ ì§‘ê³„ ìœ í‹¸: ë°ëª¨  ]
# =====================================================

# ===== ë°ëª¨ ë¬¸ìì—´ íŒŒì‹± ìœ í‹¸ =====
def _gender_from_demo(s: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„(ë‚¨/ì—¬/ê¸°íƒ€)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]): return "ë‚¨"
    return "ê¸°íƒ€"

def gender_from_demo(s: str):
    """ 'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„ (ë‚¨/ì—¬) ì¶”ì¶œ, ê·¸ ì™¸ None (í˜ì´ì§€ 3ìš©) """
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]):     return "ë‚¨"
    return None # ë‚¨/ì—¬ ì•„ë‹ˆë©´ None (e.g. ì „ì²´)

def _to_decade_label(x: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì—°ë ¹ëŒ€(10ëŒ€, 20ëŒ€...)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(x))
    if not m: return "ê¸°íƒ€"
    n = int(m.group(0))
    return f"{(n//10)*10}ëŒ€"

def _decade_label_clamped(x: str):
    """ 10ëŒ€~60ëŒ€ ë²”ìœ„ë¡œ ì—°ë ¹ëŒ€ ë¼ë²¨ ìƒì„±, ê·¸ ì™¸ëŠ” None (í˜ì´ì§€ 2, 3ìš©) """
    m = re.search(r"\d+", str(x))
    if not m: return None
    n = int(m.group(0))
    n = max(10, min(60, (n // 10) * 10)) # 10ëŒ€ ë¯¸ë§Œ -> 10ëŒ€, 60ëŒ€ ì´ˆê³¼ -> 60ëŒ€
    return f"{n}ëŒ€"

def _decade_key(s: str):
    """ì—°ë ¹ëŒ€ ì •ë ¬ì„ ìœ„í•œ ìˆ«ì í‚¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(s))
    return int(m.group(0)) if m else 999

def _fmt_ep(n):
    """ íšŒì°¨ ë²ˆí˜¸ë¥¼ '01í™”' í˜•íƒœë¡œ í¬ë§·íŒ… (í˜ì´ì§€ 2, 3ìš©) """
    try:
        return f"{int(n):02d}í™”"
    except Exception:
        return str(n)

# ===== í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ë Œë”ë§ (í˜ì´ì§€ 1, 2) =====
COLOR_MALE = "#2a61cc"
COLOR_FEMALE = "#d93636"

def render_gender_pyramid(container, title: str, df_src: pd.DataFrame, height: int = 260):

    if df_src.empty:
        container.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ë°ëª¨ ë°ì´í„° ì „ì²˜ë¦¬ ---
    df_demo = df_src.copy()
    df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
    df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
    df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & df_demo["ì—°ë ¹ëŒ€_ëŒ€"].notna()]

    if df_demo.empty:
        container.info("í‘œì‹œí•  ë°ëª¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    order = sorted(df_demo["ì—°ë ¹ëŒ€_ëŒ€"].unique().tolist(), key=_decade_key)

    # --- í”¼ë²— í…Œì´ë¸” ìƒì„± (ì—°ë ¹ëŒ€/ì„±ë³„ ê¸°ì¤€ value í•©ê³„) ---
    pvt = (
        df_demo.groupby(["ì—°ë ¹ëŒ€_ëŒ€","ì„±ë³„"])["value"]
               .sum()
               .unstack("ì„±ë³„")
               .reindex(order)
               .fillna(0)
    )

    male = -pvt.get("ë‚¨", pd.Series(0, index=pvt.index)) # ë‚¨ì„±ì€ ìŒìˆ˜ë¡œ
    female = pvt.get("ì—¬", pd.Series(0, index=pvt.index))

    max_abs = float(max(male.abs().max(), female.max()) or 1) # ì°¨íŠ¸ xì¶• ë²”ìœ„ ê³„ì‚°ìš©

    # --- ì„±ë³„ ë‚´ ë¹„ì¤‘ ê³„ì‚° ---
    male_share = (male.abs() / male.abs().sum() * 100) if male.abs().sum() else male.abs()
    female_share = (female / female.sum() * 100) if female.sum() else female

    male_text = [f"{v:.1f}%" for v in male_share]
    female_text = [f"{v:.1f}%" for v in female_share]

    # --- Plotly Figure ìƒì„± ---
    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=pvt.index, x=male, name="ë‚¨",
        orientation="h",
        marker_color=COLOR_MALE,
        text=male_text,
        textposition="inside",
        insidetextanchor="end",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ë‚¨ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([male.abs(), male_share])
    ))
    fig.add_trace(go.Bar(
        y=pvt.index, x=female, name="ì—¬",
        orientation="h",
        marker_color=COLOR_FEMALE,
        text=female_text,
        textposition="inside",
        insidetextanchor="start",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ì—¬ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([female, female_share])
    ))

    # --- ë ˆì´ì•„ì›ƒ ì„¤ì • ---
    fig.update_layout(
        barmode="overlay",
        height=height,
        margin=dict(l=8, r=8, t=10, b=8),
        legend_title=None,
        bargap=0.15,
        bargroupgap=0.05
    )
    fig.update_yaxes(
        categoryorder="array",
        categoryarray=order,
        title=None,
        tickfont=dict(size=12),
        fixedrange=True
    )
    fig.update_xaxes(
        range=[-max_abs*1.05, max_abs*1.05], # ì¢Œìš° ëŒ€ì¹­
        title=None,
        showticklabels=False,
        showgrid=False,
        zeroline=True,
        zerolinewidth=1,
        zerolinecolor="#888",
        fixedrange=True
    )

        # --- ì œëª© ë³µêµ¬ (ì—¬ê¸° ì¶”ê°€) ---
    fig.update_layout(
        title=dict(
            text=title,          # í˜¸ì¶œë¶€ì—ì„œ ë„˜ê¸´ "ğŸ¯ TV ë°ëª¨ ë¶„í¬" / "ğŸ“º TVING ë°ëª¨ ë¶„í¬"
            x=0.0, xanchor="left",
            y=0.98, yanchor="top",
            font=dict(size=14)
        )
    )
    # íƒ€ì´í‹€ ì˜ì—­ í™•ë³´ (të¥¼ ë„‰ë„‰íˆ)
    fig.update_layout(margin=dict(l=8, r=8, t=48, b=8))
    # í•„ìš” ì‹œ ì „ì—­ í…œí”Œë¦¿ íƒ€ì´í‹€ ì¶©ëŒ ë°©ì§€:
    # fig.layout.template = None

    container.plotly_chart(fig, use_container_width=True,
                           config={"scrollZoom": False, "staticPlot": False, "displayModeBar": False})

# ===== ê·¸ë£¹ ë°ëª¨ í‰ê·  ê³„ì‚° (í˜ì´ì§€ 3) =====
def get_avg_demo_pop_by_episode(df_src: pd.DataFrame, medias: List[str]) -> pd.DataFrame:
    """
    ì—¬ëŸ¬ IPê°€ í¬í•¨ëœ df_srcì—ì„œ, íšŒì°¨ë³„/ë°ëª¨ë³„ *í‰ê· * ì‹œì²­ììˆ˜(ì‹œì²­ì¸êµ¬)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    (IP vs ê·¸ë£¹ ë¹„êµìš©) â€” 0 íŒ¨ë”© ì œì™¸.
    """
    sub = df_src[
        (df_src["metric"] == "ì‹œì²­ì¸êµ¬") &
        (df_src["ë°ëª¨"].notna()) &
        (df_src["ë§¤ì²´"].isin(medias))
    ].copy()

    if sub.empty:
        return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

    # 0 íŒ¨ë”© ì œê±°
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    # ë¼ë²¨ íŒŒì‹±
    sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(gender_from_demo)  # ë‚¨/ì—¬, ê·¸ ì™¸ None
    sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)
    sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()

    # íšŒì°¨
    sub = sub.dropna(subset=["íšŒì°¨_numeric"])
    sub["íšŒì°¨_num"] = sub["íšŒì°¨_numeric"].astype(int)

    # ë°ëª¨ ë¼ë²¨
    sub["ë¼ë²¨"] = sub.apply(lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)

    # 1) IPë³„/íšŒì°¨ë³„/ë¼ë²¨ë³„ í•©ê³„
    ip_ep_demo_sum = sub.groupby(["IP", "íšŒì°¨_num", "ë¼ë²¨"])["value"].sum().reset_index()
    # 2) íšŒì°¨ë³„/ë¼ë²¨ë³„ í‰ê·  (IP í‰ê· )
    ep_demo_mean = ip_ep_demo_sum.groupby(["íšŒì°¨_num", "ë¼ë²¨"])["value"].mean().reset_index()

    # 3) í”¼ë²—
    pvt = ep_demo_mean.pivot_table(index="íšŒì°¨_num", columns="ë¼ë²¨", values="value").fillna(0)

    # 4) í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œ ì ìš©
    for c in DEMO_COLS_ORDER:
        if c not in pvt.columns:
            pvt[c] = 0
    pvt = pvt[DEMO_COLS_ORDER].sort_index()

    # 5) íšŒì°¨ í‘œê¸° ì¶”ê°€
    pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))
    return pvt.reset_index(drop=True)
#endregion

#region [ 8. í˜ì´ì§€ 1: Overview ]
# =====================================================
def render_overview():
    # â—€â—€â—€ [ìˆ˜ì •] load_data() í˜¸ì¶œ ë°©ì‹ ë³€ê²½
    df = load_data()
  
    # --- í˜ì´ì§€ ì „ìš© í•„í„° (ë©”ì¸ ì˜ì—­, ì œëª© ì˜†ì— ë°°ì¹˜) ---   
    filter_cols = st.columns(4) # [ì œëª© | í¸ì„±í•„í„° | ì—°ë„í•„í„° | ì›”í•„í„°]
    
    with filter_cols[0]:
        st.markdown("### ğŸ“Š Overview")
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)

        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ / íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì—…ë°ì´íŠ¸ ì˜ˆì •
        - **í‹°ë¹™ QUICK** `íšŒì°¨í‰ê· `: ë°©ì˜ë‹¹ì¼ VOD ì‹œì²­ UV
        - **í‹°ë¹™ VOD** `íšŒì°¨í‰ê· `: ë°©ì˜ì¼+1ë¶€í„° +6ê¹Œì§€ **6days** VOD UV
        - **ë””ì§€í„¸ ì¡°íšŒ/ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•©
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ í‰ê· 
        - **ì•µì»¤ë“œë¼ë§ˆ ê¸°ì¤€**: í† ì¼ 3%â†‘, ì›”í™” 2%â†‘
        """).strip())

        st.markdown("</div>", unsafe_allow_html=True)


    with filter_cols[1]:
        prog_sel = st.multiselect(
            "í¸ì„±", 
            sorted(df["í¸ì„±"].dropna().unique().tolist()),
            placeholder="í¸ì„± ì„ íƒ",
            label_visibility="collapsed"
        )

    # ë‚ ì§œ í•„í„° (ì—°ë„, ì›”)
    if "ë°©ì˜ì‹œì‘ì¼" in df.columns and df["ë°©ì˜ì‹œì‘ì¼"].notna().any():
        date_col_for_filter = "ë°©ì˜ì‹œì‘ì¼"
    else:
        date_col_for_filter = "ì£¼ì°¨ì‹œì‘ì¼"
        
    date_series = df[date_col_for_filter].dropna()
    if not date_series.empty:
        all_years = sorted(date_series.dt.year.unique().tolist(), reverse=True)
        all_months = sorted(date_series.dt.month.unique().tolist())
        
        with filter_cols[2]:
            year_sel = st.multiselect(
                "ì—°ë„", 
                all_years, 
                placeholder="ì—°ë„ ì„ íƒ",
                label_visibility="collapsed"
            )
        with filter_cols[3]:
            month_sel = st.multiselect(
                "ì›”", 
                all_months, 
                placeholder="ì›” ì„ íƒ",
                label_visibility="collapsed"
            )
    else:
        year_sel = None
        month_sel = None
            
    month_range = None 

    # --- í•„í„° ì ìš© ---
    f = df.copy()
    if prog_sel:
        f = f[f["í¸ì„±"].isin(prog_sel)]
    if year_sel and date_col_for_filter in f.columns:
        f = f[f[date_col_for_filter].dt.year.isin(year_sel)]
    if month_sel and date_col_for_filter in f.columns:
        f = f[f[date_col_for_filter].dt.month.isin(month_sel)]

    # --- ìš”ì•½ì¹´ë“œ ê³„ì‚° ì„œë¸Œí•¨ìˆ˜ ---
    def avg_of_ip_means(metric_name: str):
        return mean_of_ip_episode_mean(f, metric_name)

    def avg_of_ip_tving_epSum_mean(media_name: str):
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", [media_name])

    def avg_of_ip_sums(metric_name: str):
        return mean_of_ip_sums(f, metric_name)

    def count_ip_with_min1(metric_name: str):
        sub = f[f["metric"] == metric_name]
        if sub.empty: return 0
        ip_min = sub.groupby("IP")["value"].min()
        return (ip_min == 1).sum()

    def count_anchor_dramas():
        sub = f[f["metric"]=="Tì‹œì²­ë¥ "].groupby(["IP","í¸ì„±"])["value"].mean().reset_index()
        mon_tue = sub[(sub["í¸ì„±"]=="ì›”í™”") & (sub["value"]>2)].shape[0]
        sat_sun = sub[(sub["í¸ì„±"]=="í† ì¼") & (sub["value"]>3)].shape[0]
        return mon_tue + sat_sun

    # --- ìš”ì•½ ì¹´ë“œ ---
    st.caption('â–¶ IPë³„ í‰ê· ')

    c1, c2, c3, c4, c5 = st.columns(5)
    st.markdown("<div style='margin-top:20px'></div>", unsafe_allow_html=True)
    c6, c7, c8, c9, c10 = st.columns(5)

    t_rating   = avg_of_ip_means("Tì‹œì²­ë¥ ")
    h_rating   = avg_of_ip_means("Hì‹œì²­ë¥ ")
    tving_live = avg_of_ip_tving_epSum_mean("TVING LIVE")
    tving_quick= avg_of_ip_tving_epSum_mean("TVING QUICK")
    tving_vod  = avg_of_ip_tving_epSum_mean("TVING VOD")
    digital_view = avg_of_ip_sums("ì¡°íšŒìˆ˜")
    digital_buzz = avg_of_ip_sums("ì–¸ê¸‰ëŸ‰")
    f_score      = avg_of_ip_means("F_Score")
    fundex_top1 = count_ip_with_min1("F_Total")
    anchor_total = count_anchor_dramas()

    kpi(c1, "ğŸ¯ íƒ€ê¹ƒ ì‹œì²­ë¥ ", fmt(t_rating, digits=3))
    kpi(c2, "ğŸ  ê°€êµ¬ ì‹œì²­ë¥ ", fmt(h_rating, digits=3))
    kpi(c3, "ğŸ“º í‹°ë¹™ LIVE", fmt(tving_live, intlike=True))
    kpi(c4, "âš¡ í‹°ë¹™ QUICK", fmt(tving_quick, intlike=True))
    kpi(c5, "â–¶ï¸ í‹°ë¹™ VOD", fmt(tving_vod, intlike=True))
    kpi(c6, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", fmt(digital_view, intlike=True))
    kpi(c7, "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", fmt(digital_buzz, intlike=True))
    kpi(c8, "ğŸ”¥ í™”ì œì„± ì ìˆ˜",  fmt(f_score, intlike=True))
    kpi(c9, "ğŸ¥‡ í€ë±ìŠ¤ 1ìœ„", f"{fundex_top1}ì‘í’ˆ")
    kpi(c10, "âš“ ì•µì»¤ë“œë¼ë§ˆ", f"{anchor_total}ì‘í’ˆ")

    st.divider()

    # --- ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ (Stacked Bar) ---
    df_trend = f[f["metric"]=="ì‹œì²­ì¸êµ¬"].copy()

    tv_weekly = df_trend[df_trend["ë§¤ì²´"]=="TV"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
    tving_livequick_weekly = df_trend[df_trend["ë§¤ì²´"].isin(["TVING LIVE","TVING QUICK"])]\
        .groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
    tving_vod_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING VOD"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()

    df_bar = pd.DataFrame({
        "ì£¼ì°¨ì‹œì‘ì¼": sorted(set(tv_weekly.index) | set(tving_livequick_weekly.index) | set(tving_vod_weekly.index))
    })
    df_bar["TV ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tv_weekly).fillna(0)
    df_bar["í‹°ë¹™ ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_livequick_weekly).fillna(0)
    df_bar["í‹°ë¹™ VOD"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_vod_weekly).fillna(0)

    df_long = df_bar.melt(id_vars="ì£¼ì°¨ì‹œì‘ì¼",
                          value_vars=["TV ë³¸ë°©","í‹°ë¹™ ë³¸ë°©","í‹°ë¹™ VOD"],
                          var_name="êµ¬ë¶„", value_name="ì‹œì²­ììˆ˜")

    fig = px.bar(
        df_long, x="ì£¼ì°¨ì‹œì‘ì¼", y="ì‹œì²­ììˆ˜", color="êµ¬ë¶„", text="ì‹œì²­ììˆ˜",
        title="ğŸ“Š ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ (TV ë³¸ë°© / í‹°ë¹™ ë³¸ë°© / í‹°ë¹™ VOD, ëˆ„ì )",
        color_discrete_map={
            "TV ë³¸ë°©": "#1f77b4",
            "í‹°ë¹™ ë³¸ë°©": "#d62728",
            "í‹°ë¹™ VOD": "#ff7f7f"
        }
    )
    fig.update_layout(
        xaxis_title=None, yaxis_title=None,
        barmode="stack", legend_title="êµ¬ë¶„",
        title_font=dict(size=20)
    )
    fig.update_traces(texttemplate='%{text:,.0f}', textposition="inside")
    st.plotly_chart(fig, use_container_width=True)

    st.divider()

    # --- ì£¼ìš”ì‘í’ˆ í…Œì´ë¸” (AgGrid) ---
    st.markdown("#### ğŸ¬ ì „ì²´ ì‘í’ˆ RAW")

    df_perf = (
        f.groupby("IP")
        .agg(
            íƒ€ê¹ƒì‹œì²­ë¥ =("value", lambda x: x[f.loc[x.index, "metric"]=="Tì‹œì²­ë¥ "].mean()),
            ê°€êµ¬ì‹œì²­ë¥ =("value", lambda x: x[f.loc[x.index, "metric"]=="Hì‹œì²­ë¥ "].mean()),
            í‹°ë¹™LIVE=("value", lambda x: x[(f.loc[x.index, "ë§¤ì²´"]=="TVING LIVE") & (f.loc[x.index,"metric"]=="ì‹œì²­ì¸êµ¬")].sum()),
            í‹°ë¹™QUICK=("value", lambda x: x[(f.loc[x.index, "ë§¤ì²´"]=="TVING QUICK") & (f.loc[x.index,"metric"]=="ì‹œì²­ì¸êµ¬")].sum()),
            í‹°ë¹™VOD_6Days=("value", lambda x: x[(f.loc[x.index, "ë§¤ì²´"]=="TVING VOD") & (f.loc[x.index,"metric"]=="ì‹œì²­ì¸êµ¬")].sum()),
            ë””ì§€í„¸ì¡°íšŒìˆ˜=("value", lambda x: x[(f.loc[x.index,"metric"]=="ì¡°íšŒìˆ˜") & ((f.loc[x.index,"ë§¤ì²´"]!="ìœ íŠœë¸Œ") | (f.loc[x.index,"ì„¸ë¶€ì†ì„±1"].isin(["PGC","UGC"])) )].sum()),
            ë””ì§€í„¸ì–¸ê¸‰ëŸ‰=("value", lambda x: x[(f.loc[x.index,"metric"]=="ì–¸ê¸‰ëŸ‰")].sum()),
            í™”ì œì„±ìˆœìœ„=("value", lambda x: x[(f.loc[x.index,"metric"]=="F_Total")].min()),
            í™”ì œì„±ì ìˆ˜=("value", lambda x: x[(f.loc[x.index,"metric"]=="F_Score")].mean()) # ì¶”ê°€ëœ ë¶€ë¶„
        )
        .reset_index()
    ).sort_values("íƒ€ê¹ƒì‹œì²­ë¥ ", ascending=False)

    fmt_fixed3 = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      return Number(params.value).toFixed(3);
    }
    """)
    fmt_thousands = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      return Math.round(params.value).toLocaleString();
    }
    """)
    fmt_rank = JsCode("""
    function(params){
      if (params.value == null || isNaN(params.value)) return '';
      return Math.round(params.value) + 'ìœ„';
    }
    """)

    gb = GridOptionsBuilder.from_dataframe(df_perf)
    gb.configure_default_column(
        sortable=True, resizable=True, filter=False,
        cellStyle={'textAlign': 'center'},
        headerClass='centered-header'
    )
    gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
    gb.configure_column('IP', header_name='IP', cellStyle={'textAlign':'left'})
    gb.configure_column('íƒ€ê¹ƒì‹œì²­ë¥ ', valueFormatter=fmt_fixed3, sort='desc')
    gb.configure_column('ê°€êµ¬ì‹œì²­ë¥ ', valueFormatter=fmt_fixed3)
    gb.configure_column('í‹°ë¹™LIVE', valueFormatter=fmt_thousands)
    gb.configure_column('í‹°ë¹™QUICK', valueFormatter=fmt_thousands)
    gb.configure_column('í‹°ë¹™VOD_6Days', valueFormatter=fmt_thousands)
    gb.configure_column('ë””ì§€í„¸ì¡°íšŒìˆ˜', valueFormatter=fmt_thousands)
    gb.configure_column('ë””ì§€í„¸ì–¸ê¸‰ëŸ‰', valueFormatter=fmt_thousands)
    gb.configure_column('í™”ì œì„±ìˆœìœ„', valueFormatter=fmt_rank)
    gb.configure_column('í™”ì œì„±ì ìˆ˜', valueFormatter=fmt_thousands) # ì¶”ê°€ëœ ë¶€ë¶„

    grid_options = gb.build()

    AgGrid(
        df_perf,
        gridOptions=grid_options,
        theme="streamlit",
        height=300,
        fit_columns_on_grid_load=True,
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )
#endregion

#region [ 9. í˜ì´ì§€ 2: IP ì„±ê³¼ ìì„¸íˆë³´ê¸° ]
# =====================================================
def render_ip_detail():

    # â—€â—€â—€ [ë³€ê²½ ì—†ìŒ] ë°ì´í„° ë¡œë“œ
    df_full = load_data()

    filter_cols = st.columns([3, 2, 2])  # [ì œëª© | IPì„ íƒ | ê·¸ë£¹ê¸°ì¤€]

    # â–¼â–¼ ì œëª© í‘œê¸° ë°©ì‹ë§Œ í†µì¼ â–¼â–¼
    with filter_cols[0]:
        st.markdown("<div class='page-title'>ğŸ“ˆ IP ì„±ê³¼ ìì„¸íˆë³´ê¸°</div>", unsafe_allow_html=True)
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)

        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ / íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì—…ë°ì´íŠ¸ ì˜ˆì •
        - **í‹°ë¹™ QUICK** `íšŒì°¨í‰ê· `: ë°©ì˜ë‹¹ì¼ VOD ì‹œì²­ UV
        - **í‹°ë¹™ VOD** `íšŒì°¨í‰ê· `: ë°©ì˜ì¼+1ë¶€í„° +6ê¹Œì§€ **6days** VOD UV
        - **ë””ì§€í„¸ ì¡°íšŒ/ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•©
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ í‰ê· 
        """).strip())

        st.markdown("</div>", unsafe_allow_html=True)

    ip_options = sorted(df_full["IP"].dropna().unique().tolist())
    with filter_cols[1]:
        ip_selected = st.selectbox(
            "IP (ë‹¨ì¼ì„ íƒ)",
            ip_options,
            index=0 if ip_options else None,
            placeholder="IP ì„ íƒ",
            label_visibility="collapsed"
        )

    with filter_cols[2]:
        selected_group_criteria = st.multiselect(
            "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"],
            default=["ë™ì¼ í¸ì„±"],
            placeholder="ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            label_visibility="collapsed",
            key="ip_detail_group"
        )

    if "ë°©ì˜ì‹œì‘ì¼" in df_full.columns and df_full["ë°©ì˜ì‹œì‘ì¼"].notna().any():
        date_col_for_filter = "ë°©ì˜ì‹œì‘ì¼"
    else:
        date_col_for_filter = "ì£¼ì°¨ì‹œì‘ì¼"

    month_range = None

    # --- ì„ íƒ IP / ê¸°ê°„ í•„í„° ---
    f = df_full[df_full["IP"] == ip_selected].copy()

    if "íšŒì°¨_numeric" in f.columns:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨_numeric"], errors="coerce")
    else:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")

    def _week_to_num(x: str):
        m = re.search(r"-?\d+", str(x))
        return int(m.group(0)) if m else None

    has_week_col = "ì£¼ì°¨" in f.columns
    if has_week_col:
        f["ì£¼ì°¨_num"] = f["ì£¼ì°¨"].apply(_week_to_num)

    try:
        sel_prog = f["í¸ì„±"].dropna().mode().iloc[0]  # sel_progëŠ” ê·¸ë£¹í•‘ ë¡œì§ì— í•„ìš”
    except Exception:
        sel_prog = None

    try:
        sel_year = (
            f[date_col_for_filter].dropna().dt.year.mode().iloc[0]
            if date_col_for_filter in f.columns and not f[date_col_for_filter].dropna().empty
            else None
        )
    except Exception:
        sel_year = None

    # --- ë² ì´ìŠ¤(ë¹„êµ ê·¸ë£¹ ê¸°ì¤€) ---
    base = df_full.copy()
    group_name_parts = []

    if "ë™ì¼ í¸ì„±" in selected_group_criteria:
        if sel_prog:
            base = base[base["í¸ì„±"] == sel_prog]
            group_name_parts.append(f"'{sel_prog}'")
        else:
            st.warning(f"'{ip_selected}'ì˜ í¸ì„± ì •ë³´ê°€ ì—†ì–´ 'ë™ì¼ í¸ì„±' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")

    if "ë°©ì˜ ì—°ë„" in selected_group_criteria:
        if sel_year:
            base = base[base[date_col_for_filter].dt.year == sel_year]
            group_name_parts.append(f"{int(sel_year)}ë…„")
        else:
            st.warning(f"'{ip_selected}'ì˜ ì—°ë„ ì •ë³´ê°€ ì—†ì–´ 'ë°©ì˜ ì—°ë„' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")

    if not group_name_parts and selected_group_criteria:  # ê¸°ì¤€ì„ ì„ íƒí–ˆì§€ë§Œ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        st.warning("ê·¸ë£¹í•‘ ê¸°ì¤€ ì •ë³´ ë¶€ì¡±. ì „ì²´ ë°ì´í„°ì™€ ë¹„êµí•©ë‹ˆë‹¤.", icon="âš ï¸")
        group_name_parts.append("ì „ì²´")
        base = df_full.copy()
    elif not group_name_parts:  # ì•„ì˜ˆ ê¸°ì¤€ ì„ íƒì„ ì•ˆ í•œ ê²½ìš°
        group_name_parts.append("ì „ì²´")
        base = df_full.copy()

    prog_label = " & ".join(group_name_parts) + " í‰ê· "

    if "íšŒì°¨_numeric" in base.columns:
        base["íšŒì°¨_num"] = pd.to_numeric(base["íšŒì°¨_numeric"], errors="coerce")
    else:
        base["íšŒì°¨_num"] = pd.to_numeric(base["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")

    # --- ìƒë‹¨ íƒ€ì´í‹€ (í‘œê¸° ë°©ì‹ë§Œ êµì²´) ---
    st.markdown(
        f"<div class='sub-title'>ğŸ“º {ip_selected} ì„±ê³¼ ìƒì„¸ ë¦¬í¬íŠ¸</div>",
        unsafe_allow_html=True
    )
    st.markdown("---")

    # =========================
    # ğŸ”§ Metric Normalizer
    # =========================
    def _normalize_metric(s: str) -> str:
        """
        metric ë¬¸ìì—´ì„ ì†Œë¬¸ìí™”í•˜ê³ , ì˜ìˆ«ìë§Œ ë‚¨ê¹€.
        ì˜ˆ: 'F_score'/'F Score'/'FScore'/'f_score ' -> 'fscore'
        """
        if s is None:
            return ""
        s2 = re.sub(r"[^A-Za-z0-9ê°€-í£]+", "", str(s)).lower()
        return s2

    def _metric_filter(df: pd.DataFrame, name: str) -> pd.DataFrame:
        target = _normalize_metric(name)
        if "metric_norm" not in df.columns:
            df = df.copy()
            df["metric_norm"] = df["metric"].apply(_normalize_metric)
        return df[df["metric_norm"] == target]

    # --- KPI/í‰ê· ë¹„/ë­í‚¹ ê³„ì‚° ---
    val_T = mean_of_ip_episode_mean(f, "Tì‹œì²­ë¥ ")
    val_H = mean_of_ip_episode_mean(f, "Hì‹œì²­ë¥ ")
    val_live = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    val_quick = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
    val_vod = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
    val_buzz = mean_of_ip_sums(f, "ì–¸ê¸‰ëŸ‰")
    val_view = mean_of_ip_sums(f, "ì¡°íšŒìˆ˜")

    # â–¶ í™”ì œì„± ë©”íŠ¸ë¦­ (ëª…ì‹œ ê³ ì •: ìˆœìœ„=F_Total, ì ìˆ˜=F_score)
    def _min_of_ip_metric(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty:
            return None
        s = pd.to_numeric(sub["value"], errors="coerce").dropna()
        return float(s.min()) if not s.empty else None

    # âœ… F_score í‰ê· (ì‹œì²­ë¥ ê³¼ ê°™ì€ ë¡œì§) with í´ë°±:
    # 1) íšŒì°¨ê°€ ìˆìœ¼ë©´: íšŒì°¨ë³„ í‰ê·  â†’ ì „ì²´ í‰ê· 
    # 2) íšŒì°¨ê°€ ì—†ê³  ë‚ ì§œê°€ ìˆìœ¼ë©´: ë‚ ì§œë³„ í‰ê·  â†’ ì „ì²´ í‰ê· 
    # 3) ë‘˜ ë‹¤ ì—†ìœ¼ë©´: ë‹¨ìˆœ í‰ê· 
    def _mean_like_rating(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty:
            return None
        sub["val"] = pd.to_numeric(sub["value"], errors="coerce")
        sub = sub.dropna(subset=["val"])
        if sub.empty:
            return None

        # 1) íšŒì°¨ ê¸°ì¤€
        if "íšŒì°¨_num" in sub.columns and sub["íšŒì°¨_num"].notna().any():
            g = sub.dropna(subset=["íšŒì°¨_num"]).groupby("íšŒì°¨_num", as_index=False)["val"].mean()
            return float(g["val"].mean()) if not g.empty else None

        # 2) ë‚ ì§œ ê¸°ì¤€
        if date_col_for_filter in sub.columns and sub[date_col_for_filter].notna().any():
            g = sub.dropna(subset=[date_col_for_filter]).groupby(date_col_for_filter, as_index=False)["val"].mean()
            return float(g["val"].mean()) if not g.empty else None

        # 3) ë‹¨ìˆœ í‰ê· 
        return float(sub["val"].mean()) if not sub["val"].empty else None

    val_topic_min = _min_of_ip_metric(f, "F_Total")
    val_topic_avg = _mean_like_rating(f, "F_score")

    base_T = mean_of_ip_episode_mean(base, "Tì‹œì²­ë¥ ")
    base_H = mean_of_ip_episode_mean(base, "Hì‹œì²­ë¥ ")
    base_live = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    base_quick = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
    base_vod = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
    base_buzz = mean_of_ip_sums(base, "ì–¸ê¸‰ëŸ‰")
    base_view = mean_of_ip_sums(base, "ì¡°íšŒìˆ˜")

    # â–¶ í™”ì œì„± ë² ì´ìŠ¤ê°’
    def _series_ip_metric(base_df: pd.DataFrame, metric_name: str, mode: str = "mean", media: List[str] | None = None):
        sub = _metric_filter(base_df, metric_name).copy()
        if media is not None:
            sub = sub[sub["ë§¤ì²´"].isin(media)]
        if sub.empty:
            return pd.Series(dtype=float)

        if mode == "mean":
            ep_col = _episode_col(sub)
            sub = sub.dropna(subset=[ep_col])
            ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
            s = ep_mean.groupby("IP")["value"].mean()
        elif mode == "sum":
            s = sub.groupby("IP")["value"].sum()
        elif mode == "ep_sum_mean":
            ep_col = _episode_col(sub)
            sub = sub.dropna(subset=[ep_col])
            ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
            s = ep_sum.groupby("IP")["value"].mean()
        elif mode == "min":
            s = sub.groupby("IP")["value"].min()
        else:
            raise ValueError("unknown mode")
        return pd.to_numeric(s, errors="coerce").dropna()

    base_topic_min_series = _series_ip_metric(base, "F_Total", mode="min")
    base_topic_min = float(base_topic_min_series.mean()) if not base_topic_min_series.empty else None
    base_topic_avg = _mean_like_rating(base, "F_score")

    # --- ë­í‚¹ ê³„ì‚° ìœ í‹¸ ---
    def _rank_within_program(
        base_df: pd.DataFrame, metric_name: str, ip_name: str, value: float,
        mode: str = "mean", media: List[str] | None = None, low_is_good: bool = False
    ):
        s = _series_ip_metric(base_df, metric_name, mode=mode, media=media)
        if s.empty or value is None or pd.isna(value):
            return (None, 0)
        if ip_name not in s.index:
            if low_is_good:
                r = int((s < value).sum() + 1)
            else:
                r = int((s > value).sum() + 1)
            return (r, int(s.shape[0]))
        ranks = s.rank(method="min", ascending=low_is_good)
        r = int(ranks.loc[ip_name])
        return (r, int(s.shape[0]))

    rk_T     = _rank_within_program(base, "Tì‹œì²­ë¥ ", ip_selected, val_T,   mode="mean",        media=None)
    rk_H     = _rank_within_program(base, "Hì‹œì²­ë¥ ", ip_selected, val_H,   mode="mean",        media=None)
    rk_live  = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_live,  mode="ep_sum_mean", media=["TVING LIVE"])
    rk_quick = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_quick, mode="ep_sum_mean", media=["TVING QUICK"])
    rk_vod   = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_vod,   mode="ep_sum_mean", media=["TVING VOD"])
    rk_buzz  = _rank_within_program(base, "ì–¸ê¸‰ëŸ‰",   ip_selected, val_buzz,  mode="sum",        media=None)
    rk_view  = _rank_within_program(base, "ì¡°íšŒìˆ˜",   ip_selected, val_view,  mode="sum",        media=None)
    rk_fmin  = _rank_within_program(base, "F_Total",  ip_selected, val_topic_min, mode="min",   media=None, low_is_good=True)
    rk_fscr  = _rank_within_program(base, "F_score",  ip_selected, val_topic_avg, mode="mean",  media=None, low_is_good=False)

    # --- KPI ë Œë” ìœ í‹¸ ---
    def _pct_color(val, base_val):
        if val is None or pd.isna(val) or base_val in (None, 0) or pd.isna(base_val):
            return "#888"
        pct = (val / base_val) * 100
        return "#d93636" if pct > 100 else ("#2a61cc" if pct < 100 else "#444")

    def sublines_html(prog_label: str, rank_tuple: tuple, val, base_val):
        # ê¸°ë³¸í˜•(ë‹¤ë¥¸ KPI): ê·¸ë£¹ å…§ / í‰ê· æ¯” ë…¸ì¶œ
        rnk, total = rank_tuple if rank_tuple else (None, 0)
        rank_label = f"{rnk}ìœ„" if (rnk is not None and total > 0) else "â€“ìœ„"
        pct_txt = "â€“"; col = "#888"
        try:
            if (val is not None) and (base_val not in (None, 0)) and (not (pd.isna(val) or pd.isna(base_val))):
                pct = (float(val) / float(base_val)) * 100.0
                pct_txt = f"{pct:.0f}%"; col = _pct_color(val, base_val)
        except Exception:
            pct_txt = "â€“"; col = "#888"
        return (
            "<div class='kpi-subwrap'>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ å…§</span> "
            f"<span class='kpi-substrong'>{rank_label}</span><br/>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ í‰ê· æ¯”</span> "
            f"<span class='kpi-subpct' style='color:{col};'>{pct_txt}</span>"
            "</div>"
        )

    def sublines_dummy():
        # ë†’ì´ë§Œ ë§ì¶”ëŠ” ìˆ¨ê¹€ í…ìŠ¤íŠ¸
        return (
            "<div class='kpi-subwrap' style='visibility:hidden;'>"
            "<span class='kpi-sublabel'>_</span> <span class='kpi-substrong'>_</span><br/>"
            "<span class='kpi-sublabel'>_</span> <span class='kpi-subpct'>_</span>"
            "</div>"
        )

    def kpi_with_rank(col, title, value, base_val, rank_tuple, prog_label,
                      intlike=False, digits=3, value_suffix:str=""):
        with col:
            if intlike and value is not None and not pd.isna(value):
                main_val = f"{value:,.0f}"
            elif (value is not None and not pd.isna(value)):
                main_val = f"{value:.{digits}f}"
            else:
                main_val = "â€“"
            main = f"{main_val}{value_suffix}"
            st.markdown(
                f"<div class='kpi-card'>"
                f"<div class='kpi-title'>{title}</div>"
                f"<div class='kpi-value'>{main}</div>"
                f"{sublines_html(prog_label, rank_tuple, value, base_val)}"
                f"</div>",
                unsafe_allow_html=True
            )

    def kpi_dummy(col):
        with col:
            st.markdown(
                "<div class='kpi-card'>"
                "<div class='kpi-title' style='visibility:hidden;'>_</div>"
                "<div class='kpi-value' style='visibility:hidden;'>_</div>"
                f"{sublines_dummy()}"
                "</div>",
                unsafe_allow_html=True
            )

    # === KPI ë°°ì¹˜ ===
    r1c1, r1c2, r1c3, r1c4, r1c5 = st.columns(5)
    kpi_with_rank(r1c1, "ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ",    val_T,   base_T,   rk_T,     prog_label, intlike=False, digits=3)
    kpi_with_rank(r1c2, "ğŸ  ê°€êµ¬ì‹œì²­ë¥ ",    val_H,   base_H,   rk_H,     prog_label, intlike=False, digits=3)
    kpi_with_rank(r1c3, "ğŸ“º TVING LIVE",     val_live,  base_live,  rk_live,  prog_label, intlike=True)
    kpi_with_rank(r1c4, "âš¡ TVING QUICK",    val_quick, base_quick, rk_quick, prog_label, intlike=True)
    kpi_with_rank(r1c5, "â–¶ï¸ TVING VOD",      val_vod,   base_vod,   rk_vod,   prog_label, intlike=True)

    r2c1, r2c2, r2c3, r2c4, r2c5 = st.columns(5)
    kpi_with_rank(r2c1, "ğŸ’¬ ì´ ì–¸ê¸‰ëŸ‰",     val_buzz,  base_buzz,  rk_buzz,  prog_label, intlike=True)
    kpi_with_rank(r2c2, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", val_view,  base_view,  rk_view,  prog_label, intlike=True)

    # í™”ì œì„± ìˆœìœ„: ë³¸ë¬¸ì— 'ìœ„' ë¶™ì´ê³  í•˜ë‹¨ì€ ë”ë¯¸(ë¹„ë…¸ì¶œ)
    with r2c3:
        v = val_topic_min
        main_val = "â€“" if (v is None or pd.isna(v)) else f"{int(round(v)):,d}ìœ„"
        st.markdown(
            "<div class='kpi-card'>"
            "<div class='kpi-title'>ğŸ† ìµœê³  í™”ì œì„± ìˆœìœ„</div>"
            f"<div class='kpi-value'>{main_val}</div>"
            f"{sublines_dummy()}"
            "</div>",
            unsafe_allow_html=True
        )

    kpi_with_rank(r2c4, "ğŸ”¥ í™”ì œì„± ì ìˆ˜",     val_topic_avg, base_topic_avg, rk_fscr,
                  prog_label, intlike=True)

    kpi_dummy(r2c5)  # ë ë”ë¯¸

    st.divider()

    # --- ê³µí†µ ê·¸ë˜í”„ í¬ê¸°/ì„¤ì • ---
    chart_h = 260
    common_cfg = {"scrollZoom": False, "staticPlot": False, "displayModeBar": False}

    # === [Row1] ì‹œì²­ë¥  ì¶”ì´ | í‹°ë¹™ì¶”ì´ ===
    cA, cB = st.columns(2)
    with cA:
        st.markdown("<div class='sec-title'>ğŸ“ˆ ì‹œì²­ë¥  ì¶”ì´ (íšŒì°¨ë³„)</div>", unsafe_allow_html=True)
        rsub = f[f["metric"].isin(["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "])].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        rsub = rsub.sort_values("íšŒì°¨_num")
        if not rsub.empty:
            ep_order = rsub[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            t_series = rsub[rsub["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            h_series = rsub[rsub["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            ymax = pd.concat([t_series["value"], h_series["value"]]).max()
            y_upper = float(ymax) * 1.4 if pd.notna(ymax) else None

            fig_rate = go.Figure()
            fig_rate.add_trace(go.Scatter(
                x=h_series["íšŒì°¨"], y=h_series["value"],
                mode="lines+markers+text", name="ê°€êµ¬ì‹œì²­ë¥ ",
                text=[f"{v:.2f}" for v in h_series["value"]], textposition="top center"
            ))
            fig_rate.add_trace(go.Scatter(
                x=t_series["íšŒì°¨"], y=t_series["value"],
                mode="lines+markers+text", name="íƒ€ê¹ƒì‹œì²­ë¥ ",
                text=[f"{v:.2f}" for v in t_series["value"]], textposition="top center"
            ))
            fig_rate.update_xaxes(categoryorder="array", categoryarray=ep_order, title=None, fixedrange=True)
            fig_rate.update_yaxes(title=None, fixedrange=True, range=[0, y_upper] if y_upper else None)
            fig_rate.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8))
            st.plotly_chart(fig_rate, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì‹œì²­ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cB:
        st.markdown("<div class='sec-title'>ğŸ“Š TVING ì‹œì²­ì ì¶”ì´ (íšŒì°¨ë³„)</div>", unsafe_allow_html=True)
        t_keep = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        tsub = f[(f["metric"] == "ì‹œì²­ì¸êµ¬") & (f["ë§¤ì²´"].isin(t_keep))].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        tsub = tsub.sort_values("íšŒì°¨_num")
        if not tsub.empty:
            ep_order = tsub[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            pvt = tsub.pivot_table(index="íšŒì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
            pvt = pvt.reindex(ep_order)

            fig_tving = go.Figure()
            for col in [c for c in ["TVING LIVE", "TVING QUICK", "TVING VOD"] if c in pvt.columns]:
                fig_tving.add_trace(go.Bar(name=col, x=pvt.index, y=pvt[col], text=None))
            fig_tving.update_layout(
                barmode="stack", legend_title=None,
                bargap=0.15, bargroupgap=0.05,
                height=chart_h, margin=dict(l=8, r=8, t=10, b=8)
            )
            fig_tving.update_xaxes(categoryorder="array", categoryarray=ep_order, title=None, fixedrange=True)
            fig_tving.update_yaxes(title=None, fixedrange=True)
            st.plotly_chart(fig_tving, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  TVING ì‹œì²­ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Row2] ë””ì§€í„¸ì¡°íšŒìˆ˜ | ë””ì§€í„¸ì–¸ê¸‰ëŸ‰ ===
    cC, cD = st.columns(2)
    with cC:
        st.markdown("<div class='sec-title'>â–¶ ë””ì§€í„¸ ì¡°íšŒìˆ˜</div>", unsafe_allow_html=True)
        dview = f[(f["metric"] == "ì¡°íšŒìˆ˜") & ((f["ë§¤ì²´"]!="ìœ íŠœë¸Œ") | (f["ì„¸ë¶€ì†ì„±1"].isin(["PGC","UGC"])) )].copy()
        if not dview.empty:
            if has_week_col and dview["ì£¼ì°¨"].notna().any():
                order = (dview[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dview.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dview.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum")
                       .sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            fig_view = go.Figure()
            for col in pvt.columns:
                fig_view.add_trace(go.Bar(name=col, x=x_vals, y=pvt[col], text=None))
            fig_view.update_layout(
                barmode="stack", legend_title=None,
                bargap=0.15, bargroupgap=0.05,
                height=chart_h, margin=dict(l=8, r=8, t=10, b=8)
            )
            if use_category:
                fig_view.update_xaxes(categoryorder="array", categoryarray=x_vals, title=None, fixedrange=True)
            else:
                fig_view.update_xaxes(title=None, fixedrange=True)
            fig_view.update_yaxes(title=None, fixedrange=True)
            st.plotly_chart(fig_view, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì¡°íšŒìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cD:
        st.markdown("<div class='sec-title'>ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰</div>", unsafe_allow_html=True)
        dbuzz = f[f["metric"] == "ì–¸ê¸‰ëŸ‰"].copy()
        if not dbuzz.empty:
            if has_week_col and dbuzz["ì£¼ì°¨"].notna().any():
                order = (dbuzz[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dbuzz.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dbuzz.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum")
                       .sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            fig_buzz = go.Figure()
            for col in pvt.columns:
                fig_buzz.add_trace(go.Bar(name=col, x=x_vals, y=pvt[col], text=None))
            fig_buzz.update_layout(
                barmode="stack", legend_title=None,
                bargap=0.15, bargroupgap=0.05,
                height=chart_h, margin=dict(l=8, r=8, t=10, b=8)
            )
            if use_category:
                fig_buzz.update_xaxes(categoryorder="array", categoryarray=x_vals, title=None, fixedrange=True)
            else:
                fig_buzz.update_xaxes(title=None, fixedrange=True)
            fig_buzz.update_yaxes(title=None, fixedrange=True)
            st.plotly_chart(fig_buzz, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì–¸ê¸‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Row3] í™”ì œì„±  ===
    cE, cF = st.columns(2)
    with cE:
        st.markdown("<div class='sec-title'>ğŸ”¥ í™”ì œì„± ì§€ìˆ˜</div>", unsafe_allow_html=True)
        fdx = _metric_filter(f, "F_Total").copy()
        if not fdx.empty:
            fdx["ìˆœìœ„"] = pd.to_numeric(fdx["value"], errors="coerce").round().astype("Int64")

            if has_week_col and fdx["ì£¼ì°¨"].notna().any():
                order = (
                    fdx[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna()
                    .drop_duplicates()
                    .sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist()
                )
                s = fdx.groupby("ì£¼ì°¨", as_index=True)["ìˆœìœ„"].min().reindex(order).dropna()
                x_vals = s.index.tolist(); use_category = True
            else:
                s = fdx.set_index("ì£¼ì°¨ì‹œì‘ì¼")["ìˆœìœ„"].sort_index().dropna()
                x_vals = s.index.tolist(); use_category = False

            y_min, y_max = 0.5, 10
            labels = [f"{int(v)}ìœ„" for v in s.values]
            text_positions = ["bottom center" if (v <= 1.5) else "top center" for v in s.values]

            fig_fx = go.Figure()
            fig_fx.add_trace(go.Scatter(
                x=x_vals, y=s.values,
                mode="lines+markers+text", name="í™”ì œì„± ìˆœìœ„",
                text=labels, textposition=text_positions,
                textfont=dict(size=12, color="#111"),
                cliponaxis=False, marker=dict(size=8)
            ))
            fig_fx.update_yaxes(autorange=False, range=[y_max, y_min], dtick=1,
                                title=None, fixedrange=True)
            if use_category:
                fig_fx.update_xaxes(categoryorder="array", categoryarray=x_vals,
                                    title=None, fixedrange=True)
            else:
                fig_fx.update_xaxes(title=None, fixedrange=True)
            fig_fx.update_layout(legend_title=None, height=chart_h,
                                 margin=dict(l=8, r=8, t=10, b=8))
            st.plotly_chart(fig_fx, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  í™”ì œì„± ì§€ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cF:
        st.markdown("<div class='sec-title'>ğŸ”¥ í™”ì œì„± ì ìˆ˜</div>", unsafe_allow_html=True)
        fs = _metric_filter(f, "F_score").copy()
        if not fs.empty:
            fs["val"] = pd.to_numeric(fs["value"], errors="coerce")
            fs = fs.dropna(subset=["val"])
            if not fs.empty:
                # âœ… ì£¼ì°¨ Xì¶•(ë‹¤ë¥¸ ì£¼ì°¨ ê¸°ë°˜ ê·¸ë˜í”„ì™€ ë™ì¼ ë¡œì§)
                # 1) IP ì „ì²´ df fì—ì„œ ì£¼ì°¨ ìˆœì„œ ë§Œë“¤ê¸° (ì£¼ì°¨_numìœ¼ë¡œ ì •ë ¬)
                order = (
                    f[["ì£¼ì°¨", "ì£¼ì°¨_num"]]
                    .dropna()
                    .drop_duplicates()
                    .sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"]
                    .tolist()
                )
                # 2) F_scoreë¥¼ ì£¼ì°¨ë³„ í‰ê· ìœ¼ë¡œ ì§‘ê³„
                fs_week = fs.dropna(subset=["ì£¼ì°¨"]).groupby("ì£¼ì°¨", as_index=True)["val"].mean()
                # 3) ìœ„ì—ì„œ ë§Œë“  order ìˆœì„œì— ë§ì¶° reindex (ë¹ˆ êµ¬ê°„ë„ ìˆœì„œ ìœ ì§€)
                fs_plot = fs_week.reindex(order).dropna()

                x_vals = fs_plot.index.tolist()
                fig_fscore = go.Figure()
                fig_fscore.add_trace(go.Scatter(
                    x=x_vals, y=fs_plot.values,
                    mode="lines", name="F_score",
                    line_shape="spline"
                ))
                fig_fscore.update_xaxes(categoryorder="array", categoryarray=x_vals, title=None, fixedrange=True)
                fig_fscore.update_yaxes(title=None, fixedrange=True)
                fig_fscore.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8))
                st.plotly_chart(fig_fscore, use_container_width=True, config=common_cfg)
            else:
                st.info("í‘œì‹œí•  í™”ì œì„± ì ìˆ˜(F_score) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("í‘œì‹œí•  í™”ì œì„± ì ìˆ˜(F_score) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


    # === [Row4] TV/TVING ë°ëª¨ë¶„í¬  ===
    cG, cH = st.columns(2)

    tv_demo = f[(f["ë§¤ì²´"] == "TV") & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
    render_gender_pyramid(cG, "ğŸ¯ TV ë°ëª¨ ë¶„í¬", tv_demo, height=260)

    t_keep = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
    tving_demo = f[(f["ë§¤ì²´"].isin(t_keep)) & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
    render_gender_pyramid(cH, "ğŸ“º TVING ë°ëª¨ ë¶„í¬", tving_demo, height=260)

    st.divider()

    # === [Row5] ë°ëª¨ë¶„ì„ ìƒì„¸ í‘œ (AgGrid) ===
    st.markdown("#### ğŸ‘¥ ë°ëª¨ë¶„ì„ ìƒì„¸ í‘œ")

    # --- [í˜ì´ì§€ 2]ìš© ë°ëª¨ í…Œì´ë¸” ë¹Œë” ---
    def _build_demo_table_numeric(df_src: pd.DataFrame, medias: List[str]) -> pd.DataFrame:
        sub = df_src[
            (df_src["metric"] == "ì‹œì²­ì¸êµ¬") &
            (df_src["ë°ëª¨"].notna()) &
            (df_src["ë§¤ì²´"].isin(medias))
        ].copy()
        if sub.empty:
            return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

        sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(_gender_from_demo)  # 'ê¸°íƒ€' ë°˜í™˜
        sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)  # ê³µí†µ ìœ í‹¸
        sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()
        sub = sub.dropna(subset=["íšŒì°¨_num"])
        sub["íšŒì°¨_num"] = sub["íšŒì°¨_num"].astype(int)
        sub["ë¼ë²¨"] = sub.apply(lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)

        pvt = sub.pivot_table(index="íšŒì°¨_num", columns="ë¼ë²¨", values="value", aggfunc="sum").fillna(0)

        for c in DEMO_COLS_ORDER:  # ê³µí†µ ìœ í‹¸
            if c not in pvt.columns:
                pvt[c] = 0
        pvt = pvt[DEMO_COLS_ORDER].sort_index()
        pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))  # ê³µí†µ ìœ í‹¸
        return pvt.reset_index(drop=True)

    # --- [í˜ì´ì§€ 2]ìš© AgGrid ë Œë”ëŸ¬ ---
    diff_renderer = JsCode("""
    function(params){
      const api = params.api;
      const colId = params.column.getColId();
      const rowIndex = params.node.rowIndex;
      const val = Number(params.value || 0);
      if (colId === "íšŒì°¨") return params.value;

      let arrow = "";
      if (rowIndex > 0) {
        const prev = api.getDisplayedRowAtIndex(rowIndex - 1);
        if (prev && prev.data && prev.data[colId] != null) {
          const pv = Number(prev.data[colId] || 0);
          if (val > pv) arrow = "ğŸ”º";
          else if (val < pv) arrow = "â–¾";
        }
      }
      const txt = Math.round(val).toLocaleString();
      return arrow + txt;
    }
    """)

    _js_demo_cols = "[" + ",".join([f'"{c}"' for c in DEMO_COLS_ORDER]) + "]"
    cell_style_renderer = JsCode(f"""
    function(params){{
      const field = params.colDef.field;
      if (field === "íšŒì°¨") {{
        return {{'text-align':'left','font-weight':'600','background-color':'#fff'}};
      }}
      const COLS = {_js_demo_cols};
      let rowVals = [];
      for (let k of COLS) {{
        const v = Number((params.data && params.data[k] != null) ? params.data[k] : NaN);
        if (!isNaN(v)) rowVals.push(v);
      }}
      let bg = '#ffffff';
      if (rowVals.length > 0) {{
        const v = Number(params.value || 0);
        const mn = Math.min.apply(null, rowVals);
        const mx = Math.max.apply(null, rowVals);
        let norm = 0.5;
        if (mx > mn) norm = (v - mn) / (mx - mn);
        const alpha = 0.12 + 0.45 * Math.max(0, Math.min(1, norm));
        bg = 'rgba(30,90,255,' + alpha.toFixed(3) + ')';
      }}
      return {{
        'background-color': bg,
        'text-align': 'right',
        'padding': '2px 4px',
        'font-weight': '500'
      }};
    }}
    """)

    def _render_aggrid_table(df_numeric: pd.DataFrame, title: str, height: int = 320):
        st.markdown(f"###### {title}")
        if df_numeric.empty:
            st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        gb = GridOptionsBuilder.from_dataframe(df_numeric)
        gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
        gb.configure_default_column(
            sortable=False, resizable=True, filter=False,
            cellStyle={'textAlign': 'right'}, headerClass='centered-header bold-header'
        )
        gb.configure_column("íšŒì°¨", header_name="íšŒì°¨", cellStyle={'textAlign': 'left'})

        for c in [col for col in df_numeric.columns if col != "íšŒì°¨"]:
            gb.configure_column(
                c,
                header_name=c,
                cellRenderer=diff_renderer,
                cellStyle=cell_style_renderer
            )
        grid_options = gb.build()
        AgGrid(
            df_numeric,
            gridOptions=grid_options,
            theme="streamlit",
            height=height,
            fit_columns_on_grid_load=True,
            update_mode=GridUpdateMode.NO_UPDATE,
            allow_unsafe_jscode=True
        )

    tv_numeric = _build_demo_table_numeric(f, ["TV"])
    _render_aggrid_table(tv_numeric, "ğŸ“º TV (ì‹œì²­ììˆ˜)")

    tving_numeric = _build_demo_table_numeric(f, ["TVING LIVE", "TVING QUICK", "TVING VOD"])
    _render_aggrid_table(tving_numeric, "â–¶ï¸ TVING í•©ì‚° (LIVE/QUICK/VOD) ì‹œì²­ììˆ˜")
#endregion




#region [ 10. í˜ì´ì§€ 3: IPê°„ ë°ëª¨ë¶„ì„ ]
# =====================================================

# ===== [í˜ì´ì§€ 3] AgGrid ë Œë”ëŸ¬ (0-based % Diff) =====

# --- 1. ê°’ í¬ë§·í„° (ìˆ«ì + % + í™”ì‚´í‘œ) ---
index_value_formatter = JsCode("""
function(params) {
    const indexValue = params.value;
    if (indexValue == null || (typeof indexValue !== 'number')) return 'N/A';
    
    // 999 (INF) logic
    if (indexValue === 999) {
        // 0 ëŒ€ë¹„ A (A>0) ëŠ” INF
        return 'INF';
    }
    
    const roundedIndex = Math.round(indexValue);
    let arrow = '';
    
    // 5% ì´ìƒ ì°¨ì´ë‚  ë•Œë§Œ í™”ì‚´í‘œ í‘œì‹œ
    if (roundedIndex > 5) { arrow = ' â–²'; }
    else if (roundedIndex < -5) { arrow = ' â–¼'; }

    // ì–‘ìˆ˜ì¼ ë•Œ + ë¶€í˜¸ ì¶”ê°€
    let sign = roundedIndex > 0 ? '+' : '';
    if (roundedIndex === 0) sign = ''; // 0%
    
    return sign + roundedIndex + '%' + arrow; // e.g. +50% â–²
}""")

# --- 2. ì…€ ìŠ¤íƒ€ì¼ (ìƒ‰ìƒ) ---
index_cell_style = JsCode("""
function(params) {
    const indexValue = params.value;
    let color = '#333';
    let fontWeight = '500';

    if (indexValue == null || (typeof indexValue !== 'number')) {
        color = '#888'; // N/A
    } else if (indexValue === 999) {
        color = '#888'; // INF
    } else {
        // 5% ì´ìƒ ì°¨ì´ë‚  ë•Œë§Œ ìƒ‰ìƒ ë³€ê²½
        if (indexValue > 5) { color = '#d93636'; } // > +5%
        else if (indexValue < -5) { color = '#2a61cc'; } // < -5%
    }
    
    return {
        'color': color,
        'font-weight': fontWeight
    };
}""")


# ===== [í˜ì´ì§€ 3] AgGrid í…Œì´ë¸” ë Œë”ë§ í•¨ìˆ˜ =====
def render_index_table(df_index: pd.DataFrame, title: str, height: int = 400):
    st.markdown(f"###### {title}")

    if df_index.empty: st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    gb = GridOptionsBuilder.from_dataframe(df_index)
    gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
    gb.configure_default_column(sortable=False, resizable=True, filter=False,
                                cellStyle={'textAlign': 'center'}, headerClass='centered-header bold-header')
    gb.configure_column("íšŒì°¨", header_name="íšŒì°¨", cellStyle={'textAlign': 'left'}, pinned='left', width=70)

    # _base, _compë¡œ ëë‚˜ëŠ” ìˆ¨ê¹€ ì»¬ëŸ¼ ì œì™¸
    for c in [col for col in df_index.columns if col != "íšŒì°¨" and not col.endswith(('_base', '_comp'))]:
        gb.configure_column(
            c, 
            header_name=c.replace("ë‚¨ì„±","M").replace("ì—¬ì„±","F"), 
            valueFormatter=index_value_formatter, 
            cellStyle=index_cell_style,         
            width=80
        )
    # ìˆ¨ê¹€ ì»¬ëŸ¼
    for c in [col for col in df_index.columns if col.endswith(('_base', '_comp'))]:
        gb.configure_column(c, hide=True)

    grid_options = gb.build()
    AgGrid(df_index, gridOptions=grid_options, theme="streamlit", height=height,
           update_mode=GridUpdateMode.NO_UPDATE, allow_unsafe_jscode=True,
           enable_enterprise_modules=False
    )

# ===== [í˜ì´ì§€ 3] ì‹ ê·œ: íˆíŠ¸ë§µ ë Œë”ë§ í•¨ìˆ˜ =====
def render_heatmap(df_plot: pd.DataFrame, title: str):
    """
    ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ Plotly íˆíŠ¸ë§µì„ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    st.markdown(f"###### {title}")

    if df_plot.empty:
        st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. Plotlyê°€ íˆíŠ¸ë§µì„ ê·¸ë¦¬ë„ë¡ ë°ì´í„° ì¤€ë¹„ (íšŒì°¨ë¥¼ ì¸ë±ìŠ¤ë¡œ)
    df_heatmap = df_plot.set_index("íšŒì°¨")
    
    # _base, _comp í—¬í¼ ì»¬ëŸ¼ ì œê±°
    cols_to_drop = [c for c in df_heatmap.columns if c.endswith(('_base', '_comp'))]
    df_heatmap = df_heatmap.drop(columns=cols_to_drop)
    
    # 2. ê°’ì˜ min/maxë¥¼ êµ¬í•´ì„œ ìƒ‰ìƒ ë²”ìœ„ì˜ ì¤‘ê°„ì ì„ 0ìœ¼ë¡œ ì„¤ì •
    # (999 'INF' ê°’ì€ ì œì™¸í•˜ê³  min/max ê³„ì‚°)
    valid_values = df_heatmap.replace(999, np.nan).values
    if pd.isna(valid_values).all():
         v_min, v_max = -10.0, 10.0 # ëª¨ë“  ê°’ì´ INFì´ê±°ë‚˜ NaNì¼ ê²½ìš°
    else:
         v_min = np.nanmin(valid_values)
         v_max = np.nanmax(valid_values)
         if pd.isna(v_min): v_min = 0.0
         if pd.isna(v_max): v_max = 0.0
    
    # 0ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­ì ì¸ ìƒ‰ìƒ ë²”ìœ„ë¥¼ ë§Œë“¦
    abs_max = max(abs(v_min), abs(v_max), 10.0) # ìµœì†Œ 10%
    
    # 3. Plotly Expressë¡œ íˆíŠ¸ë§µ ìƒì„±
    fig = px.imshow(
        df_heatmap,
        text_auto=False, # í…ìŠ¤íŠ¸ëŠ” update_tracesë¡œ ë³„ë„ ì²˜ë¦¬
        aspect="auto",
        # 0(ì¤‘ê°„)ì„ í°ìƒ‰/ì—°íšŒìƒ‰, ì–‘ìˆ˜(â–²)ë¥¼ ë¹¨ê°„ìƒ‰, ìŒìˆ˜(â–¼)ë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ
        color_continuous_scale='RdBu_r', 
        range_color=[-abs_max, abs_max], # 0ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­
        color_continuous_midpoint=0
    )

    # 4. ì…€ì— í…ìŠ¤íŠ¸ í¬ë§·íŒ… (999ëŠ” 'INF'ë¡œ í‘œì‹œ)
    # np.whereëŠ” 2D ë°°ì—´ì„ ë°˜í™˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, applymap ì‚¬ìš©
    text_template_df = df_heatmap.applymap(
        lambda x: "INF" if x == 999 else (f"{x:+.0f}%" if pd.notna(x) else "")
    )

    fig.update_traces(
        text=text_template_df.values, # .valuesë¡œ 2D ë°°ì—´ ì „ë‹¬
        texttemplate="%{text}",
        hovertemplate="íšŒì°¨: %{y}<br>ë°ëª¨: %{x}<br>ì¦ê°: %{text}",
        textfont=dict(size=10, color="black") # í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê³ ì •
    )

    # 5. ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        # [ìˆ˜ì •] ìµœì†Œ ë†’ì´ 400 -> 520, í–‰ë‹¹ ë†’ì´ 35 -> 46
        height=max(520, len(df_heatmap.index) * 46), # íšŒì°¨ ìˆ˜ì— ë”°ë¼ ë†’ì´ ì¡°ì ˆ
        xaxis_title=None,
        yaxis_title=None,
        xaxis=dict(side="top"), # Xì¶• ë ˆì´ë¸”ì„ ìƒë‹¨ìœ¼ë¡œ
    )
    
    st.plotly_chart(fig, use_container_width=True)


# ===== [í˜ì´ì§€ 3] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_demographic():
    # --- ë°ì´í„° ë¡œë“œ ---
    # â—€â—€â—€ [ìˆ˜ì •] load_data() í˜¸ì¶œ ë°©ì‹ ë³€ê²½
    df_all = load_data()

    # --- í˜ì´ì§€ ì „ìš© í•„í„° (ë©”ì¸ ì˜ì—­) ---
    ip_options = sorted(df_all["IP"].dropna().unique().tolist())
    selected_ip1 = None; selected_ip2 = None; selected_group_criteria = None

    # [ìˆ˜ì •] í•„í„° ìˆœì„œ ë³€ê²½: [Title | Mode | Media | IP1 | IP2/Group]
    filter_cols = st.columns([3, 2, 2, 3, 3]) 

    with filter_cols[0]:
        st.markdown("### ğŸ‘¥ IP ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ")
    with st.expander("â„¹ï¸ ì‚¬ìš© ì„¤ëª… ë° ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)

        st.markdown(textwrap.dedent("""
**ì‚¬ìš©ë²•**
- **ìƒë‹¨ í•„í„°ì—ì„œ ë¹„êµê¸°ì¤€, í”Œë«í¼ê³¼ ê¸°ì¤€ IPë¥¼ ì„ íƒ**
- **ë¹„êµ ê¸°ì¤€** : `IPê°„ ë¹„êµ` , `ê·¸ë£¹ê³¼ ë¹„êµ`
        
**ì§€í‘œí•´ì„**
- **ê¸°ì¤€IPì™€ ë¹„êµëŒ€ìƒê°„ í•´ë‹¹ ì—°ë ¹ëŒ€ì˜ 'ì‹œì²­ììˆ˜'ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤**
- **ì˜ˆì‹œ** : 01í™” 20ëŒ€ ë‚¨ì„±ì´ +51%ì¸ ê²½ìš° â†’ `ê¸°ì¤€IPê°€ ë¹„êµëŒ€ìƒë³´ë‹¤ 20ëŒ€ ë‚¨ì„± ì‹œì²­ììˆ˜ê°€ 51% ë§ë‹¤`
""").strip())

        st.markdown("</div>", unsafe_allow_html=True)

    with filter_cols[1]:
        # [ìˆ˜ì •] st.radio -> st.selectbox
        comparison_mode = st.selectbox(
            "ë¹„êµ ëª¨ë“œ", 
            ["IP vs IP", "IP vs ê·¸ë£¹"], # ë¼ë²¨ ê°„ì†Œí™”
            index=0, # ê¸°ë³¸ê°’ IP vs IP ìœ ì§€
            key="demo_compare_mode",
            label_visibility="collapsed"
        )
        
    with filter_cols[2]:
        # [ìˆ˜ì •] st.radio -> st.selectbox
        selected_media_type = st.selectbox(
            "ë¶„ì„ ë§¤ì²´", 
            ["TV", "TVING"], # ë¼ë²¨ ì¶•ì•½
            index=0, # ê¸°ë³¸ê°’ TV ìœ ì§€
            key="demo_media_type",
            label_visibility="collapsed"
        )
            
    with filter_cols[3]:
        # [ìˆ˜ì •] ìœ„ì¹˜ ì´ë™
        selected_ip1 = st.selectbox(
            "ê¸°ì¤€ IP", ip_options, 
            index=0 if ip_options else None, 
            label_visibility="collapsed", 
            key="demo_ip1_unified"
        )

    with filter_cols[4]:
        # [ìˆ˜ì •] ìœ„ì¹˜ ì´ë™
        if comparison_mode == "IP vs IP":
            selected_ip2 = st.selectbox(
                "ë¹„êµ IP", [ip for ip in ip_options if ip != selected_ip1], 
                index=1 if len([ip for ip in ip_options if ip != selected_ip1]) > 1 else 0, 
                label_visibility="collapsed", 
                key="demo_ip2"
            )
        else: # "IP vs ê·¸ë£¹ í‰ê· "
            selected_group_criteria = st.multiselect(
                "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€", 
                ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"], 
                default=["ë™ì¼ í¸ì„±"], # ê¸°ë³¸ê°’ ìœ ì§€
                label_visibility="collapsed", 
                key="demo_group_criteria"
            )
            
    # ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ì „ì²´ ë¼ë²¨ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ media_list_labelì„ ì—¬ê¸°ì„œ ì •ì˜
    media_list_label = "TV" if selected_media_type == "TV" else "TVING (L+Q+V í•©ì‚°)"

    # (ê¸°ì¡´ 'with st.sidebar:' ë¸”ë¡ì€ ì‚­ì œë¨)

    # --- ë©”ì¸ í˜ì´ì§€ ë Œë”ë§ ---
    st.caption(f"ì„ íƒëœ ë‘ ëŒ€ìƒì˜ íšŒì°¨ë³„ ë°ëª¨ ì‹œì²­ì¸êµ¬ ë¹„êµ ( {media_list_label} / ë¹„êµëŒ€ìƒ ëŒ€ë¹„ % ì¦ê° )") # ìƒˆ ìº¡ì…˜
    st.divider()

    # --- ì…ë ¥ê°’ ìœ íš¨ì„± ê²€ì‚¬ ---
    if not selected_ip1: st.warning("ê¸°ì¤€ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return
    if comparison_mode == "IP vs IP" and (not selected_ip2): st.warning("ë¹„êµ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return

    # --- ë°ì´í„° ì¤€ë¹„ ---
    df_base = pd.DataFrame(); df_comp = pd.DataFrame(); comp_name = ""
    # media_list_label ëŒ€ì‹  selected_media_type ì‚¬ìš©
    media_list = ["TV"] if selected_media_type == "TV" else ["TVING LIVE", "TVING QUICK", "TVING VOD"]

    # ê¸°ì¤€ IP ë°ì´í„° ë¡œë“œ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    df_ip1_data = df_all[df_all["IP"] == selected_ip1].copy()
    if not df_ip1_data.empty:
        # ê·¸ë£¹ í‰ê·  ê³„ì‚° í•¨ìˆ˜(get_avg_demo_pop_by_episode)ëŠ” IPê°€ 1ê°œì¼ ë•Œë„ ì‘ë™í•¨
        df_base = get_avg_demo_pop_by_episode(df_ip1_data, media_list)

    # ë¹„êµ ëŒ€ìƒ ë°ì´í„° ë¡œë“œ
    if comparison_mode == "IP vs IP":
        if selected_ip2: # ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼í–ˆìœ¼ë¯€ë¡œ í•­ìƒ True
            df_ip2_data = df_all[df_all["IP"] == selected_ip2].copy()
            if not df_ip2_data.empty:
                 df_comp = get_avg_demo_pop_by_episode(df_ip2_data, media_list)
            comp_name = selected_ip2
        else:
             st.warning("ë¹„êµ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return # ë§Œì•½ì„ ìœ„í•œ ë°©ì–´
             
    else: # "IP vs ê·¸ë£¹ í‰ê· "
        df_group_filtered = df_all.copy(); group_name_parts = []
        base_ip_info_rows = df_all[df_all["IP"] == selected_ip1];
        if not base_ip_info_rows.empty:
            base_ip_prog = base_ip_info_rows["í¸ì„±"].dropna().mode().iloc[0] if not base_ip_info_rows["í¸ì„±"].dropna().empty else None
            date_col = "ë°©ì˜ì‹œì‘ì¼" if "ë°©ì˜ì‹œì‘ì¼" in df_all.columns and df_all["ë°©ì˜ì‹œì‘ì¼"].notna().any() else "ì£¼ì°¨ì‹œì‘ì¼"
            base_ip_year = base_ip_info_rows[date_col].dropna().dt.year.mode().iloc[0] if not base_ip_info_rows[date_col].dropna().empty else None
            
            # [ìˆ˜ì •] ê·¸ë£¹ ê¸°ì¤€ ì„ íƒ ë¡œì§
            if not selected_group_criteria:
                st.info("ë¹„êµ ê·¸ë£¹ ê¸°ì¤€ì´ ì„ íƒë˜ì§€ ì•Šì•„ 'ì „ì²´'ì™€ ë¹„êµí•©ë‹ˆë‹¤.")
                group_name_parts.append("ì „ì²´")
                # df_group_filteredëŠ” ì´ë¯¸ df_all.copy() ìƒíƒœ
            else:
                if "ë™ì¼ í¸ì„±" in selected_group_criteria:
                    if base_ip_prog: 
                        df_group_filtered = df_group_filtered[df_group_filtered["í¸ì„±"] == base_ip_prog]
                        group_name_parts.append(f"'{base_ip_prog}'")
                    else: st.warning("ê¸°ì¤€ IP í¸ì„± ì •ë³´ ì—†ìŒ (ë™ì¼ í¸ì„± ì œì™¸)", icon="âš ï¸")
                if "ë°©ì˜ ì—°ë„" in selected_group_criteria:
                    if base_ip_year: 
                        df_group_filtered = df_group_filtered[df_group_filtered[date_col].dt.year == int(base_ip_year)]
                        group_name_parts.append(f"{int(base_ip_year)}ë…„")
                    else: st.warning("ê¸°ì¤€ IP ì—°ë„ ì •ë³´ ì—†ìŒ (ë°©ì˜ ì—°ë„ ì œì™¸)", icon="âš ï¸")
                
                # ê¸°ì¤€ì„ ì„ íƒí–ˆì§€ë§Œ, ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ì ìš©ì´ ì•ˆëœ ê²½ìš°
                if not group_name_parts:
                    st.error("ë¹„êµ ê·¸ë£¹ì„ ì •ì˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê¸°ì¤€ IP ì •ë³´ ë¶€ì¡±)"); return

            # --- ê·¸ë£¹ ë°ì´í„° ê³„ì‚° ---
            if not df_group_filtered.empty:
                df_comp = get_avg_demo_pop_by_episode(df_group_filtered, media_list)
                comp_name = " & ".join(group_name_parts) + " í‰ê· "
            else:
                 st.warning("ì„ íƒí•˜ì‹  ê·¸ë£¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                 comp_name = " & ".join(group_name_parts) + " í‰ê· "
                 # df_compëŠ” ë¹„ì–´ìˆê²Œ ë¨ (ì•„ë˜ì—ì„œ ì²˜ë¦¬)

        else: 
            st.error("ê¸°ì¤€ IP ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    # --- Index ê³„ì‚° ---
    if df_base.empty:
        st.warning("ê¸°ì¤€ IPì˜ ë°ëª¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        render_heatmap(pd.DataFrame(), f"{media_list_label} ë°ëª¨XíšŒì°¨ ì‹œì²­ììˆ˜ ë¹„êµ ({selected_ip1} vs {comp_name})") # <-- íˆíŠ¸ë§µ í˜¸ì¶œ
        return
    if df_comp.empty:
         st.warning(f"ë¹„êµ ëŒ€ìƒ({comp_name})ì˜ ë°ëª¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Index ê³„ì‚° ì‹œ ë¹„êµê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
         df_comp = pd.DataFrame({'íšŒì°¨': df_base['íšŒì°¨']})
         for col in DEMO_COLS_ORDER: df_comp[col] = 0.0

    # íšŒì°¨ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•© (left join: ê¸°ì¤€ IPì˜ íšŒì°¨ ëª©ë¡ ê¸°ì¤€)
    df_merged = pd.merge(df_base, df_comp, on="íšŒì°¨", suffixes=('_base', '_comp'), how='left')

    # Index ê³„ì‚°ìš© ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
    df_index = df_merged[["íšŒì°¨"]].copy()

    for col in DEMO_COLS_ORDER:
        base_col = col + '_base'
        comp_col = col + '_comp'

        if base_col not in df_merged.columns: df_merged[base_col] = 0.0
        else: df_merged[base_col] = pd.to_numeric(df_merged[base_col], errors='coerce').fillna(0.0)

        if comp_col not in df_merged.columns: df_merged[comp_col] = 0.0
        else: df_merged[comp_col] = pd.to_numeric(df_merged[comp_col], errors='coerce').fillna(0.0)

        base_values = df_merged[base_col].values
        comp_values = df_merged[comp_col].values

        # [ìˆ˜ì •] (A-B)/B * 100 (0-based percentage diff)
        index_values = np.where(
            comp_values != 0,
            ((base_values - comp_values) / comp_values) * 100, # (A-B)/B * 100
            np.where(base_values == 0, 0.0, 999) # 0 if 0/0, 999 if A/0 (INF)
        )
        df_index[col] = index_values
        df_index[base_col] = base_values 
        df_index[comp_col] = comp_values 

    # --- í…Œì´ë¸” ë Œë”ë§ ---
    table_title = f"{media_list_label} ì—°ë ¹ëŒ€ë³„ ì‹œì²­ììˆ˜ ì°¨ì´ ({selected_ip1} vs {comp_name})"
    render_heatmap(df_index, table_title) # <-- ìƒˆë¡œìš´ íˆíŠ¸ë§µ í•¨ìˆ˜ í˜¸ì¶œ
#endregion

#region [ 11. í˜ì´ì§€ 4: IPê°„ ë¹„êµë¶„ì„ ]
# =====================================================

# ===== [í˜ì´ì§€ 4] ë°ì´í„° ë¡œë“œ ë° KPI ë°±ë¶„ìœ„ ê³„ì‚° (ìºì‹±) =====
@st.cache_data(ttl=600)
def get_kpi_data_for_all_ips(df_all: pd.DataFrame) -> pd.DataFrame:
    """
    ëª¨ë“  IPì— ëŒ€í•´ 6ê°€ì§€ í•µì‹¬ KPIë¥¼ ì§‘ê³„í•˜ê³  0-100ì (ë°±ë¶„ìœ„)ìœ¼ë¡œ ë³€í™˜ (0 íŒ¨ë”©ì€ ì œì™¸).
    """
    df = df_all.copy()
    # ì¼ê´„ ìˆ«ìí™” + 0 íŒ¨ë”© ì œê±°
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df.loc[df["value"] == 0, "value"] = np.nan

    # ê³µí†µ: íšŒì°¨ ìˆ«ì í•„í„°
    df = df.dropna(subset=["value"])
    if "íšŒì°¨_numeric" in df.columns:
        df = df.dropna(subset=["íšŒì°¨_numeric"])

    # 1) ì‹œì²­ë¥ (íšŒì°¨ í‰ê·  â†’ IP í‰ê· )
    def _ip_mean_of_ep_mean(metric_name: str) -> pd.Series:
        sub = df[df["metric"] == metric_name]
        if sub.empty: return pd.Series(dtype=float, name=metric_name)
        ep_mean = sub.groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
        return ep_mean.groupby("IP")["value"].mean().rename(metric_name)

    kpi_t_rating = _ip_mean_of_ep_mean("Tì‹œì²­ë¥ ")
    kpi_h_rating = _ip_mean_of_ep_mean("Hì‹œì²­ë¥ ")

    # 2) TVING VOD (íšŒì°¨ í•© â†’ IP í‰ê· )
    sub_vod = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"] == "TVING VOD")]
    if not sub_vod.empty:
        vod_ep_sum = sub_vod.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_vod = vod_ep_sum.groupby("IP")["value"].mean().rename("TVING VOD")
    else:
        kpi_vod = pd.Series(dtype=float, name="TVING VOD")

    # 3) TVING L+Q (íšŒì°¨ í•© â†’ IP í‰ê· )
    sub_lq = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"].isin(["TVING LIVE", "TVING QUICK"]))]
    if not sub_lq.empty:
        lq_ep_sum = sub_lq.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_livequick = lq_ep_sum.groupby("IP")["value"].mean().rename("TVING ë¼ì´ë¸Œ+QUICK")
    else:
        kpi_livequick = pd.Series(dtype=float, name="TVING ë¼ì´ë¸Œ+QUICK")

    # 4) ë””ì§€í„¸ í•©ì‚°(ë‹¨ìˆœ í•©) â€” 0ì€ ì´ë¯¸ NaNìœ¼ë¡œ ì œê±°ë¨
    kpi_view = df[(df["metric"] == "ì¡°íšŒìˆ˜") & ((df["ë§¤ì²´"]!="ìœ íŠœë¸Œ") | (df["ì„¸ë¶€ì†ì„±1"].isin(["PGC","UGC"])) )].groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì¡°íšŒìˆ˜")
    kpi_buzz = df[df["metric"] == "ì–¸ê¸‰ëŸ‰"].groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰")

    # í†µí•© & ë°±ë¶„ìœ„
    kpi_df = pd.concat([kpi_t_rating, kpi_h_rating, kpi_vod, kpi_livequick, kpi_view, kpi_buzz], axis=1)
    kpi_percentiles = kpi_df.rank(pct=True) * 100
    return kpi_percentiles.fillna(0)


# ===== [í˜ì´ì§€ 4] ë‹¨ì¼ IP/ê·¸ë£¹ KPI ê³„ì‚° =====
def get_agg_kpis_for_ip_page4(df_ip: pd.DataFrame) -> Dict[str, float | None]:
    """ë‹¨ì¼ IP ë˜ëŠ” IP ê·¸ë£¹ì— ëŒ€í•œ ì£¼ìš” KPI ì ˆëŒ€ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤. (í˜ì´ì§€ 4 ì „ìš©)"""
    kpis = {}
    kpis["Tì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Tì‹œì²­ë¥ ")
    kpis["Hì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Hì‹œì²­ë¥ ")
    kpis["TVING VOD"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
    kpis["TVING ë¼ì´ë¸Œ+QUICK"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING LIVE", "TVING QUICK"])
    kpis["ë””ì§€í„¸ ì¡°íšŒìˆ˜"] = mean_of_ip_sums(df_ip, "ì¡°íšŒìˆ˜")
    kpis["ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"] = mean_of_ip_sums(df_ip, "ì–¸ê¸‰ëŸ‰")
    
    fundex = df_ip[df_ip["metric"] == "F_Total"]["value"]
    kpis["í™”ì œì„± ìˆœìœ„"] = fundex.min() if not fundex.empty else None
    kpis["í™”ì œì„± ìˆœìœ„(í‰ê· )"] = fundex.mean() if not fundex.empty else None 

    return kpis

# ===== [í˜ì´ì§€ 4] "IP vs Group" ë Œë”ë§ =====
def render_ip_vs_group_comparison(
    df_all: pd.DataFrame, 
    ip: str, 
    group_criteria: List[str], 
    kpi_percentiles: pd.DataFrame 
):
    

    # --- ë°ì´í„° ì¤€ë¹„ ---
    df_ip = df_all[df_all["IP"] == ip].copy()
    df_group = df_all.copy()
    group_name_parts = []
    
    ip_prog = df_ip["í¸ì„±"].dropna().mode().iloc[0] if not df_ip["í¸ì„±"].dropna().empty else None
    date_col = "ë°©ì˜ì‹œì‘ì¼" if "ë°©ì˜ì‹œì‘ì¼" in df_ip.columns and df_ip["ë°©ì˜ì‹œì‘ì¼"].notna().any() else "ì£¼ì°¨ì‹œì‘ì¼"
    ip_year = df_ip[date_col].dropna().dt.year.mode().iloc[0] if not df_ip[date_col].dropna().empty else None

    # ê·¸ë£¹ í•„í„°ë§
    if "ë™ì¼ í¸ì„±" in group_criteria:
        if ip_prog: 
            df_group = df_group[df_group["í¸ì„±"] == ip_prog]
            group_name_parts.append(f"'{ip_prog}'")
        else: 
            st.warning(f"'{ip}'ì˜ í¸ì„± ì •ë³´ê°€ ì—†ì–´ 'ë™ì¼ í¸ì„±' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.")
            group_criteria.remove("ë™ì¼ í¸ì„±") 
            
    if "ë°©ì˜ ì—°ë„" in group_criteria:
        if ip_year: 
            df_group = df_group[df_group[date_col].dt.year == ip_year]
            group_name_parts.append(f"{int(ip_year)}ë…„")
        else: 
            st.warning(f"'{ip}'ì˜ ì—°ë„ ì •ë³´ê°€ ì—†ì–´ 'ë°©ì˜ ì—°ë„' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.")
            group_criteria.remove("ë°©ì˜ ì—°ë„") 

    if not group_name_parts: 
        st.error("ë¹„êµ ê·¸ë£¹ì„ ì •ì˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    group_name = " & ".join(group_name_parts) + " í‰ê· "
    
    st.markdown(
        f"#### âš–ï¸  <span style='color:#d93636;'>{ip}</span> vs <span style='color:#2a61cc;'>{group_name}</span>", 
        unsafe_allow_html=True
    )
    st.divider()

    # --- KPI ê°’ ê³„ì‚° ---
    kpis_ip = get_agg_kpis_for_ip_page4(df_ip)
    kpis_group = get_agg_kpis_for_ip_page4(df_group) 
    
    def calc_delta(ip_val, group_val): 
        ip_val = ip_val or 0
        group_val = group_val or 0
        if group_val is None or group_val == 0: return None
        return (ip_val - group_val) / group_val
        
    def calc_delta_rank(ip_val, group_val): 
        if ip_val is None or group_val is None: return None
        return ip_val - group_val
        
    delta_t = calc_delta(kpis_ip.get('Tì‹œì²­ë¥ '), kpis_group.get('Tì‹œì²­ë¥ '))
    delta_h = calc_delta(kpis_ip.get('Hì‹œì²­ë¥ '), kpis_group.get('Hì‹œì²­ë¥ '))
    delta_lq = calc_delta(kpis_ip.get('TVING ë¼ì´ë¸Œ+QUICK'), kpis_group.get('TVING ë¼ì´ë¸Œ+QUICK'))
    delta_vod = calc_delta(kpis_ip.get('TVING VOD'), kpis_group.get('TVING VOD'))
    delta_view = calc_delta(kpis_ip.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜'), kpis_group.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜'))
    delta_buzz = calc_delta(kpis_ip.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰'), kpis_group.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰'))
    delta_rank = calc_delta_rank(kpis_ip.get('í™”ì œì„± ìˆœìœ„'), kpis_group.get('í™”ì œì„± ìˆœìœ„'))

    # --- 1. ìš”ì•½ KPI ì¹´ë“œ (í•œ ì¤„) ---
    st.markdown(f"#### 1. ì£¼ìš” ì„±ê³¼ ({group_name} ëŒ€ë¹„)")
    
    kpi_cols = st.columns(7) 
    with kpi_cols[0]: 
        st.metric("ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", f"{kpis_ip.get('Tì‹œì²­ë¥ ', 0):.2f}%", f"{delta_t * 100:.1f}%" if delta_t is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('Tì‹œì²­ë¥ ', 0):.2f}%")
    with kpi_cols[1]: 
        st.metric("ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", f"{kpis_ip.get('Hì‹œì²­ë¥ ', 0):.2f}%", f"{delta_h * 100:.1f}%" if delta_h is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('Hì‹œì²­ë¥ ', 0):.2f}%")
    with kpi_cols[2]: 
        st.metric("âš¡ í‹°ë¹™ ë¼ì´ë¸Œ+QUICK", f"{kpis_ip.get('TVING ë¼ì´ë¸Œ+QUICK', 0):,.0f}", f"{delta_lq * 100:.1f}%" if delta_lq is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('TVING ë¼ì´ë¸Œ+QUICK', 0):,.0f}")
    with kpi_cols[3]: 
        st.metric("â–¶ï¸ í‹°ë¹™ VOD", f"{kpis_ip.get('TVING VOD', 0):,.0f}", f"{delta_vod * 100:.1f}%" if delta_vod is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('TVING VOD', 0):,.0f}")
    with kpi_cols[4]: 
        st.metric("ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", f"{kpis_ip.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜', 0):,.0f}", f"{delta_view * 100:.1f}%" if delta_view is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('ë””ì§€í„¸ ì¡°íšŒìˆ˜', 0):,.0f}")
    with kpi_cols[5]: 
        st.metric("ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", f"{kpis_ip.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰', 0):,.0f}", f"{delta_buzz * 100:.1f}%" if delta_buzz is not None else "N/A", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰', 0):,.0f}")
    with kpi_cols[6]: 
        st.metric("ğŸ”¥ í™”ì œì„±(ìµœê³ ìˆœìœ„)", f"{kpis_ip.get('í™”ì œì„± ìˆœìœ„', 0):.0f}ìœ„" if kpis_ip.get('í™”ì œì„± ìˆœìœ„') else "N/A", f"{delta_rank:.0f}ìœ„" if delta_rank is not None else "N/A", delta_color="inverse", help=f"ê·¸ë£¹ í‰ê· : {kpis_group.get('í™”ì œì„± ìˆœìœ„', 0):.1f}ìœ„")
        
    st.divider()

    # --- 2. ì„±ê³¼ ì‹œê·¸ë‹ˆì²˜ (Radar) + ì£¼ìš” ì§€í‘œ í¸ì°¨ (Bar) ---
    st.markdown(f"#### 2. ì„±ê³¼ í¬ì§€ì…”ë‹ ({group_name} ëŒ€ë¹„)")
    
    (col_radar,) = st.columns(1) 

    # ì™¼ìª½: Radar Chart
    with col_radar:
        st.markdown(f"###### ì„±ê³¼ ë°±ë¶„ìœ„ ì ìˆ˜")
        
        group_ips = df_group["IP"].unique()
        group_percentiles_avg = kpi_percentiles.loc[kpi_percentiles.index.isin(group_ips)].mean()
        
        radar_metrics = ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "TVING ë¼ì´ë¸Œ+QUICK", "TVING VOD", "ë””ì§€í„¸ ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"]
        
        score_ip_series = kpi_percentiles.loc[ip][radar_metrics]
        score_group_series = group_percentiles_avg[radar_metrics]
        
        fig_radar_group = go.Figure()
        fig_radar_group.add_trace(go.Scatterpolar(
            r=score_ip_series.values,
            theta=score_ip_series.index.map({ 
                "Tì‹œì²­ë¥ ": "íƒ€ê¹ƒ", "Hì‹œì²­ë¥ ": "ê°€êµ¬", 
                "TVING ë¼ì´ë¸Œ+QUICK": "TVING L+Q", "TVING VOD": "TVING VOD", 
                "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ì–¸ê¸‰ëŸ‰"
            }),
            fill='toself', name=ip, line=dict(color="#d93636") 
        ))
        fig_radar_group.add_trace(go.Scatterpolar(
            r=score_group_series.values,
            theta=score_group_series.index.map({
                 "Tì‹œì²­ë¥ ": "íƒ€ê¹ƒ", "Hì‹œì²­ë¥ ": "ê°€êµ¬", 
                 "TVING ë¼ì´ë¸Œ+QUICK": "TVING L+Q", "TVING VOD": "TVING VOD", 
                 "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ì–¸ê¸‰ëŸ‰"
            }),
            fill='toself', name=group_name, line=dict(color="#2a61cc") 
        ))
        fig_radar_group.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True, height=350, 
            margin=dict(l=60, r=60, t=40, b=40), 
            legend=dict(orientation="h", yanchor="bottom", y=1.05)
        )
        st.plotly_chart(fig_radar_group, use_container_width=True)


    st.divider()

    # --- 3. íŠ¸ë Œë“œ ë¹„êµ (íƒ€ê¹ƒ / ê°€êµ¬ ë¶„ë¦¬) ---
    st.markdown(f"#### 3. ì‹œì²­ë¥  íŠ¸ë Œë“œ ë¹„êµ ({group_name} ëŒ€ë¹„)")
    col_trend_t, col_trend_h = st.columns(2)
    
    with col_trend_t:
        st.markdown("###### ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥  (íšŒì°¨ë³„)")
        ip_trend_t = df_ip[df_ip["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        ip_trend_t["êµ¬ë¶„"] = ip
        group_ep_avg_t = df_group[df_group["metric"] == "Tì‹œì²­ë¥ "].groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
        group_trend_t = group_ep_avg_t.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        group_trend_t["êµ¬ë¶„"] = group_name
        trend_data_t = pd.concat([ip_trend_t, group_trend_t])
        
        if not trend_data_t.empty:
            fig_trend_t = px.line(
                trend_data_t, x="íšŒì°¨_numeric", y="value", color="êµ¬ë¶„", line_dash="êµ¬ë¶„", markers=True, 
                color_discrete_map={ip: "#d93636", group_name: "#aaaaaa"}, 
                line_dash_map={ip: "solid", group_name: "dot"}
            )
            fig_trend_t.update_layout(
                height=350, yaxis_title="íƒ€ê¹ƒì‹œì²­ë¥  (%)", xaxis_title="íšŒì°¨", 
                margin=dict(t=20, b=0), legend=dict(orientation="h", yanchor="bottom", y=1.02)
            )
            st.plotly_chart(fig_trend_t, use_container_width=True)
        else: 
            st.info("íƒ€ê¹ƒì‹œì²­ë¥  íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ")

    with col_trend_h:
        st.markdown("###### ğŸ  ê°€êµ¬ì‹œì²­ë¥  (íšŒì°¨ë³„)")
        ip_trend_h = df_ip[df_ip["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        ip_trend_h["êµ¬ë¶„"] = ip
        group_ep_avg_h = df_group[df_group["metric"] == "Hì‹œì²­ë¥ "].groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
        group_trend_h = group_ep_avg_h.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        group_trend_h["êµ¬ë¶„"] = group_name
        trend_data_h = pd.concat([ip_trend_h, group_trend_h])
        
        if not trend_data_h.empty:
            fig_trend_h = px.line(
                trend_data_h, x="íšŒì°¨_numeric", y="value", color="êµ¬ë¶„", line_dash="êµ¬ë¶„", markers=True, 
                color_discrete_map={ip: "#d93636", group_name: "#aaaaaa"}, 
                line_dash_map={ip: "solid", group_name: "dot"}
            )
            fig_trend_h.update_layout(
                height=350, yaxis_title="ê°€êµ¬ì‹œì²­ë¥  (%)", xaxis_title="íšŒì°¨", 
                margin=dict(t=20, b=0), legend=dict(orientation="h", yanchor="bottom", y=1.02)
            )
            st.plotly_chart(fig_trend_h, use_container_width=True)
        else: 
            st.info("ê°€êµ¬ì‹œì²­ë¥  íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ")
            
    st.divider()

    # --- 4. ë°ëª¨ ë¹„êµ (Grouped Bar, TV/TVING ë¶„ë¦¬, ì‹œì²­ì¸êµ¬ ë¹„êµ) ---
    st.markdown(f"#### 4. ì‹œì²­ì¸êµ¬ ë¹„êµ ({group_name} ëŒ€ë¹„)")
    col_demo_tv, col_demo_tving = st.columns(2)
    
    def get_demo_avg_pop(df_demo_src, media_filter: List[str]):
        df_demo = df_demo_src[
            (df_demo_src["metric"] == "ì‹œì²­ì¸êµ¬") & 
            (df_demo_src["ë§¤ì²´"].isin(media_filter)) & 
            (df_demo_src["ë°ëª¨"].notna())
        ].copy()
        df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
        df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
        df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & (df_demo["ì—°ë ¹ëŒ€_ëŒ€"] != "ê¸°íƒ€")]
        df_demo["ë°ëª¨_êµ¬ë¶„"] = df_demo["ì—°ë ¹ëŒ€_ëŒ€"] + df_demo["ì„±ë³„"]
        
        # IPë³„, íšŒì°¨ë³„ ë°ëª¨ í•©ê³„ -> ë°ëª¨ë³„ í‰ê·  (IP*íšŒì°¨ í‰ê· )
        agg = df_demo.groupby(["IP", "íšŒì°¨_numeric", "ë°ëª¨_êµ¬ë¶„"])["value"].sum().reset_index()
        avg_pop = agg.groupby("ë°ëª¨_êµ¬ë¶„")["value"].mean() 
        return avg_pop

    with col_demo_tv:
        st.markdown(f"###### ğŸ“º TV (í‰ê·  ì‹œì²­ì¸êµ¬)")
        ip_pop_tv = get_demo_avg_pop(df_ip, ["TV"])
        group_pop_tv = get_demo_avg_pop(df_group, ["TV"])
        df_demo_tv = pd.DataFrame({"IP": ip_pop_tv, "Group": group_pop_tv}).fillna(0).reset_index()
        df_demo_tv_melt = df_demo_tv.melt(id_vars="ë°ëª¨_êµ¬ë¶„", var_name="êµ¬ë¶„", value_name="ì‹œì²­ì¸êµ¬")
        
        sort_map = {f"{d}ëŒ€{'ë‚¨' if g == 0 else 'ì—¬'}": d*10 + g for d in range(1, 7) for g in range(2)}
        df_demo_tv_melt["sort_key"] = df_demo_tv_melt["ë°ëª¨_êµ¬ë¶„"].map(sort_map).fillna(999)
        df_demo_tv_melt = df_demo_tv_melt.sort_values("sort_key")

        if not df_demo_tv_melt.empty:
            fig_demo_tv = px.bar(
                df_demo_tv_melt, x="ë°ëª¨_êµ¬ë¶„", y="ì‹œì²­ì¸êµ¬", color="êµ¬ë¶„", barmode="group", 
                text="ì‹œì²­ì¸êµ¬", color_discrete_map={"IP": "#d93636", "Group": "#2a61cc"}
            )
            fig_demo_tv.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_demo_tv.update_layout(
                height=350, yaxis_title="í‰ê·  ì‹œì²­ì¸êµ¬", xaxis_title=None, 
                margin=dict(t=20, b=0), 
                legend=dict(title=None, orientation="h", yanchor="bottom", y=1.02)
            )
            st.plotly_chart(fig_demo_tv, use_container_width=True)
        else: 
            st.info("TV ë°ëª¨ ë°ì´í„° ì—†ìŒ")

    with col_demo_tving:
        st.markdown(f"###### â–¶ï¸ TVING (í‰ê·  ì‹œì²­ì¸êµ¬)")
        tving_media = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        ip_pop_tving = get_demo_avg_pop(df_ip, tving_media)
        group_pop_tving = get_demo_avg_pop(df_group, tving_media)
        df_demo_tving = pd.DataFrame({"IP": ip_pop_tving, "Group": group_pop_tving}).fillna(0).reset_index()
        df_demo_tving_melt = df_demo_tving.melt(id_vars="ë°ëª¨_êµ¬ë¶„", var_name="êµ¬ë¶„", value_name="ì‹œì²­ì¸êµ¬")
        
        df_demo_tving_melt["sort_key"] = df_demo_tving_melt["ë°ëª¨_êµ¬ë¶„"].map(sort_map).fillna(999)
        df_demo_tving_melt = df_demo_tving_melt.sort_values("sort_key")

        if not df_demo_tving_melt.empty:
            fig_demo_tving = px.bar(
                df_demo_tving_melt, x="ë°ëª¨_êµ¬ë¶„", y="ì‹œì²­ì¸êµ¬", color="êµ¬ë¶„", barmode="group", 
                text="ì‹œì²­ì¸êµ¬", color_discrete_map={"IP": "#d93636", "Group": "#2a61cc"}
            )
            fig_demo_tving.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_demo_tving.update_layout(
                height=350, yaxis_title="í‰ê·  ì‹œì²­ì¸êµ¬", xaxis_title=None, 
                margin=dict(t=20, b=0), 
                legend=dict(title=None, orientation="h", yanchor="bottom", y=1.02)
            )
            st.plotly_chart(fig_demo_tving, use_container_width=True)
        else: 
            st.info("TVING ë°ëª¨ ë°ì´í„° ì—†ìŒ")

# ===== [í˜ì´ì§€ 4] "IP vs IP" ë Œë”ë§ =====

# --- KPI ë¹„êµ ì¹´ë“œ ë Œë”ë§ í•¨ìˆ˜ ---
def _render_kpi_card_comparison(
    title: str, 
    val1: float | None, 
    val2: float | None, 
    ip1_name: str, 
    ip2_name: str, 
    format_str: str = "{:,.0f}",
    higher_is_better: bool = True 
):
    """2ê°œ IP ê°’ì„ ë¹„êµí•˜ëŠ” ì»¤ìŠ¤í…€ KPI ì¹´ë“œ ë Œë”ë§ í•¨ìˆ˜"""
    
    val1_disp = format_str.format(val1) if val1 is not None else "â€“"
    val2_disp = format_str.format(val2) if val2 is not None else "â€“"
    
    winner = 0 
    if val1 is not None and val2 is not None:
        if higher_is_better:
            if val1 > val2: winner = 1
            elif val2 > val1: winner = 2
        else: 
            if val1 < val2: winner = 1
            elif val2 < val1: winner = 2

    val1_style = "color:#d93636; font-weight: 700;" if winner == 1 else ("color:#888; font-weight: 400;" if winner == 2 else "color:#333; font-weight: 400;")
    val2_style = "color:#2a61cc; font-weight: 700;" if winner == 2 else ("color:#888; font-weight: 400;" if winner == 1 else "color:#333; font-weight: 400;")

    st.markdown(f"""
    <div class="kpi-card" style="height: 100px; display: flex; flex-direction: column; justify-content: center;">
        <div class="kpi-title">{title}</div>
        <div class="kpi_value" style="font-size: 1.1rem; line-height: 1.4; margin-top: 5px;">
            <span style="{val1_style}">
                <span style="font-size: 0.8em; color: #d93636;">{ip1_name}:</span> {val1_disp}
            </span>
            <br>
            <span style="{val2_style}">
                <span style="font-size: 0.8em; color: #2a61cc;">{ip2_name}:</span> {val2_disp}
            </span>
        </div>
    </div>
    """, unsafe_allow_html=True)

# --- IP vs IP ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ ---
def render_ip_vs_ip_comparison(df_all: pd.DataFrame, ip1: str, ip2: str, kpi_percentiles: pd.DataFrame):
    
    st.markdown(f"#### âš–ï¸ : <span style='color:#d93636;'>{ip1}</span> vs <span style='color:#2a61cc;'>{ip2}</span>", unsafe_allow_html=True)

    st.divider()

    # --- ë°ì´í„° ì¤€ë¹„ ---
    df1 = df_all[df_all["IP"] == ip1].copy()
    df2 = df_all[df_all["IP"] == ip2].copy()
    kpis1 = get_agg_kpis_for_ip_page4(df1)
    kpis2 = get_agg_kpis_for_ip_page4(df2)

    # --- [ìˆ˜ì •] 1. ìš”ì•½ KPI ì¹´ë“œ (ë‘ ì¤„ë¡œ ë³µì›) ---
    st.markdown("#### 1. ì£¼ìš” ì„±ê³¼ ìš”ì•½")
    
    kpi_cols_1 = st.columns(4) # 7ê°œ -> 4ê°œ (ì²« ì¤„)
    with kpi_cols_1[0]: _render_kpi_card_comparison("ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", kpis1.get("Tì‹œì²­ë¥ "), kpis2.get("Tì‹œì²­ë¥ "), ip1, ip2, "{:.2f}%")
    with kpi_cols_1[1]: _render_kpi_card_comparison("ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", kpis1.get("Hì‹œì²­ë¥ "), kpis2.get("Hì‹œì²­ë¥ "), ip1, ip2, "{:.2f}%")
    with kpi_cols_1[2]: _render_kpi_card_comparison("âš¡ í‹°ë¹™ ë¼ì´ë¸Œ+QUICK", kpis1.get("TVING ë¼ì´ë¸Œ+QUICK"), kpis2.get("TVING ë¼ì´ë¸Œ+QUICK"), ip1, ip2, "{:,.0f}")
    with kpi_cols_1[3]: _render_kpi_card_comparison("â–¶ï¸ í‹°ë¹™ VOD", kpis1.get("TVING VOD"), kpis2.get("TVING VOD"), ip1, ip2, "{:,.0f}")
    
    st.markdown("<div style='margin-top: 10px;'></div>", unsafe_allow_html=True)
    kpi_cols_2 = st.columns(4) # 4ê°œ (ë‘ ë²ˆì§¸ ì¤„)
    with kpi_cols_2[0]: _render_kpi_card_comparison("ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", kpis1.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), kpis2.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), ip1, ip2, "{:,.0f}")
    with kpi_cols_2[1]: _render_kpi_card_comparison("ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", kpis1.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), kpis2.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), ip1, ip2, "{:,.0f}")
    with kpi_cols_2[2]: _render_kpi_card_comparison("ğŸ”¥ í™”ì œì„±(ìµœê³ ìˆœìœ„)", kpis1.get("í™”ì œì„± ìˆœìœ„"), kpis2.get("í™”ì œì„± ìˆœìœ„"), ip1, ip2, "{:,.0f}ìœ„", higher_is_better=False)
    with kpi_cols_2[3]: st.markdown("") # ë¹ˆ ì¹¸

    st.divider()

    # --- 2. ì„±ê³¼ ì‹œê·¸ë‹ˆì²˜ (Radar Chart) ---
    st.markdown("#### 2. ì„±ê³¼ ì‹œê·¸ë‹ˆì²˜ (ë°±ë¶„ìœ„ ì ìˆ˜)")
    
    radar_metrics = ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "TVING ë¼ì´ë¸Œ+QUICK", "TVING VOD", "ë””ì§€í„¸ ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"]
    score1 = kpi_percentiles.loc[ip1][radar_metrics].reset_index().rename(columns={'index': 'metric', ip1: 'score'})
    score1["IP"] = ip1
    score2 = kpi_percentiles.loc[ip2][radar_metrics].reset_index().rename(columns={'index': 'metric', ip2: 'score'})
    score2["IP"] = ip2
    radar_data = pd.concat([score1, score2])
    radar_data["metric_label"] = radar_data["metric"].replace({"Tì‹œì²­ë¥ ": "íƒ€ê¹ƒ", "Hì‹œì²­ë¥ ": "ê°€êµ¬", "TVING ë¼ì´ë¸Œ+QUICK": "TVING L+Q", "TVING VOD": "TVING VOD", "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ì–¸ê¸‰ëŸ‰"})

    fig_radar = px.line_polar(radar_data, r="score", theta="metric_label", line_close=True, color="IP", 
                              color_discrete_map={ip1: "#d93636", ip2: "#2a61cc"}, range_r=[0, 100], markers=True)
    fig_radar.update_layout(height=400, margin=dict(l=80, r=80, t=40, b=40))
    st.plotly_chart(fig_radar, use_container_width=True)
    
    st.divider()

    # --- 3. íŠ¸ë Œë“œ ê²©ëŒ (Line Charts) ---
    st.markdown("#### 3. íŠ¸ë Œë“œ ë¹„êµ")
    
    c_trend1, c_trend2 = st.columns(2)
    with c_trend1:
        st.markdown("###### ğŸ“ˆ ì‹œì²­ë¥  ì¶”ì´ (íšŒì°¨ë³„)")
        t_trend1 = df1[df1["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().rename("íƒ€ê¹ƒ")
        h_trend1 = df1[df1["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().rename("ê°€êµ¬")
        t_trend2 = df2[df2["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().rename("íƒ€ê¹ƒ")
        h_trend2 = df2[df2["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨_numeric")["value"].mean().rename("ê°€êµ¬")
        
        fig_t = go.Figure()
        fig_t.add_trace(go.Scatter(x=h_trend1.index, y=h_trend1.values, name=f"{ip1} (ê°€êµ¬)", mode='lines+markers', line=dict(color="#d93636", dash="solid")))
        fig_t.add_trace(go.Scatter(x=t_trend1.index, y=t_trend1.values, name=f"{ip1} (íƒ€ê¹ƒ)", mode='lines+markers', line=dict(color="#2a61cc", dash="solid")))
        fig_t.add_trace(go.Scatter(x=h_trend2.index, y=h_trend2.values, name=f"{ip2} (ê°€êµ¬)", mode='lines+markers', line=dict(color="#d93636", dash="dot")))
        fig_t.add_trace(go.Scatter(x=t_trend2.index, y=t_trend2.values, name=f"{ip2} (íƒ€ê¹ƒ)", mode='lines+markers', line=dict(color="#2a61cc", dash="dot")))
        fig_t.update_layout(height=300, yaxis_title="ì‹œì²­ë¥  (%)", xaxis_title="íšŒì°¨", margin=dict(t=20, b=0), legend=dict(orientation="h", yanchor="bottom", y=1.02))
        st.plotly_chart(fig_t, use_container_width=True)

    with c_trend2:
        st.markdown("###### ğŸ”¥ í™”ì œì„± ìˆœìœ„ (ì£¼ì°¨ë³„)")
        f_trend1 = df1[df1["metric"] == "F_Total"].groupby("ì£¼ì°¨")["value"].min().reset_index(); f_trend1["IP"] = ip1
        f_trend2 = df2[df2["metric"] == "F_Total"].groupby("ì£¼ì°¨")["value"].min().reset_index(); f_trend2["IP"] = ip2
        f_trend_data = pd.concat([f_trend1, f_trend2])
        
        if not f_trend_data.empty:
            fig_f = px.line(f_trend_data, x="ì£¼ì°¨", y="value", color="IP", title=None, markers=True, color_discrete_map={ip1: "#d93636", ip2: "#2a61cc"})
            fig_f.update_layout(height=300, yaxis_title="í™”ì œì„± ìˆœìœ„", yaxis=dict(autorange="reversed"), margin=dict(t=20, b=0), legend=dict(orientation="h", yanchor="bottom", y=1.02))
            st.plotly_chart(fig_f, use_container_width=True)
        else: 
            st.info("í™”ì œì„± íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    st.divider()

    # --- 4. íƒ€ê¹ƒ ë°ëª¨ ë¹„êµ (Grouped Bar Chart) ---
    st.markdown("#### 4. TV ì‹œì²­ì ë°ëª¨ ë¹„êµ (TV ì‹œì²­ì¸êµ¬ ë¹„ì¤‘)")
    
    demo1 = df1[(df1["metric"] == "ì‹œì²­ì¸êµ¬") & (df1["ë§¤ì²´"] == "TV") & (df1["ë°ëª¨"].notna())]
    demo2 = df2[(df2["metric"] == "ì‹œì²­ì¸êµ¬") & (df2["ë§¤ì²´"] == "TV") & (df2["ë°ëª¨"].notna())]
    
    def prep_demo_data(df_demo, ip_name):
        df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
        df_demo = df_demo[df_demo["ì—°ë ¹ëŒ€_ëŒ€"] != "ê¸°íƒ€"]
        agg = df_demo.groupby("ì—°ë ¹ëŒ€_ëŒ€")["value"].sum()
        total = agg.sum()
        return pd.DataFrame({"ì—°ë ¹ëŒ€": agg.index, "ë¹„ì¤‘": (agg / total * 100) if total > 0 else agg, "IP": ip_name})
        
    demo_agg1 = prep_demo_data(demo1, ip1)
    demo_agg2 = prep_demo_data(demo2, ip2)
    demo_data_grouped = pd.concat([demo_agg1, demo_agg2])
    all_decades = sorted(demo_data_grouped["ì—°ë ¹ëŒ€"].unique(), key=_decade_key)
    
    fig_demo = px.bar(demo_data_grouped, x="ì—°ë ¹ëŒ€", y="ë¹„ì¤‘", color="IP", barmode="group", 
                      text="ë¹„ì¤‘", color_discrete_map={ip1: "#d93636", ip2: "#2a61cc"}, 
                      category_orders={"ì—°ë ¹ëŒ€": all_decades})
    fig_demo.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
    fig_demo.update_layout(height=350, margin=dict(t=20, b=20, l=20, r=20), 
                           yaxis_title="ì‹œì²­ ë¹„ì¤‘ (%)", xaxis_title="ì—°ë ¹ëŒ€", 
                           legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
    st.plotly_chart(fig_demo, use_container_width=True)

# ===== [í˜ì´ì§€ 4] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_comparison():
    # â—€â—€â—€ [ìˆ˜ì •] load_data() í˜¸ì¶œ ë°©ì‹ ë³€ê²½
    df_all = load_data()
    try: 
        kpi_percentiles = get_kpi_data_for_all_ips(df_all)
    except Exception as e: 
        st.error(f"KPI ë°±ë¶„ìœ„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        kpi_percentiles = pd.DataFrame() 

    # --- [ìˆ˜ì •] í•„í„° ë©”ì¸ ì˜ì—­ìœ¼ë¡œ ì´ë™ ---
    filter_cols = st.columns([3, 2, 3, 3]) # [Title, Mode, IP1, IP2/Group]
    ip_options = sorted(df_all["IP"].dropna().unique().tolist())
    selected_ip1 = None
    selected_ip2 = None
    selected_group_criteria = None

    with filter_cols[0]:
        st.markdown("## âš–ï¸ IPê°„ ë¹„êµë¶„ì„")
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("ë‚´ìš© ê¸°ì… í•„ìš”")

    with filter_cols[1]:
        comparison_mode = st.radio(
            "ë¹„êµ ëª¨ë“œ", 
            ["IP vs IP", "IP vs ê·¸ë£¹ í‰ê· "], 
            index=1, horizontal=True, label_visibility="collapsed"
        ) 
    
    with filter_cols[2]:
        selected_ip1 = st.selectbox(
            "ê¸°ì¤€ IP", 
            ip_options, index=0 if ip_options else None, 
            label_visibility="collapsed"
        )

    with filter_cols[3]:
        if comparison_mode == "IP vs IP":
            ip_options_2 = [ip for ip in ip_options if ip != selected_ip1]
            selected_ip2 = st.selectbox(
                "ë¹„êµ IP", 
                ip_options_2, 
                index=1 if len(ip_options_2) > 1 else (0 if len(ip_options_2) > 0 else None), 
                label_visibility="collapsed"
            )
        else: # "IP vs ê·¸ë£¹ í‰ê· "
            selected_group_criteria = st.multiselect(
                "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€", 
                ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"], 
                default=["ë™ì¼ í¸ì„±"], label_visibility="collapsed"
            )

    # (ê¸°ì¡´ 'with st.sidebar:' ë¸”ë¡ ì‚­ì œ)

    # ===== ë©”ì¸ í˜ì´ì§€ ë¼ìš°íŒ… =====
    # (ê¸°ì¡´ íƒ€ì´í‹€ 'st.markdown("## âš–ï¸ IPê°„ ë¹„êµë¶„ì„")' ì‚­ì œ)
    
    if comparison_mode == "IP vs ê·¸ë£¹ í‰ê· ": 
        if selected_ip1 and selected_group_criteria and not kpi_percentiles.empty: 
            render_ip_vs_group_comparison(df_all, selected_ip1, selected_group_criteria, kpi_percentiles)
        elif kpi_percentiles.empty:
             st.error("Radar Chart KPI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨.")
        elif not selected_group_criteria: 
            st.warning("í•„í„°ì—ì„œ ë¹„êµ ê·¸ë£¹ ê¸°ì¤€ì„ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.") # 'ì‚¬ì´ë“œë°”' -> 'í•„í„°'
        else: 
            st.info("í•„í„°ì—ì„œ ê¸°ì¤€ IPì™€ ë¹„êµ ê·¸ë£¹ ê¸°ì¤€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.") # 'ì‚¬ì´ë“œë°”' -> 'í•„í„°'
            
    else: # "IP vs IP"
        if selected_ip1 and selected_ip2 and not kpi_percentiles.empty: 
            render_ip_vs_ip_comparison(df_all, selected_ip1, selected_ip2, kpi_percentiles)
        elif kpi_percentiles.empty: 
            st.error("Radar Chart KPI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨.")
        else: 
            st.info("í•„í„°ì—ì„œ ë¹„êµí•  ë‘ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.") # 'ì‚¬ì´ë“œë°”' -> 'í•„í„°'
#endregion

#region [ 12. í˜ì´ì§€ 5: íšŒì°¨ë³„ ë¹„êµ ]
# =====================================================

# ===== [í˜ì´ì§€ 5] íŠ¹ì • íšŒì°¨ ë°ì´í„° ì²˜ë¦¬ =====
def filter_data_for_episode_comparison(
    df_all_filtered: pd.DataFrame,
    selected_episode: str,
    selected_metric: str
) -> pd.DataFrame:
    """íŠ¹ì • íšŒì°¨ ë¹„êµë¥¼ ìœ„í•œ ë°ì´í„° í•„í„°ë§ ë° ì§‘ê³„ (í•„í„°ë§ëœ IP ëŒ€ìƒ)"""
    # selected_episode ì˜ˆ: "1í™”", "2í™”" í˜¹ì€ "1 íšŒ"
    episode_num_str = str(selected_episode).strip().split()[0]
    target_episode_num_str = ''.join(ch for ch in episode_num_str if ch.isdigit() or ch == '.')
    try:
        target_episode_num = float(target_episode_num_str)
    except ValueError:
        return pd.DataFrame({'IP': df_all_filtered["IP"].unique(), 'value': 0})

    # --- í•´ë‹¹ íšŒì°¨ ë°ì´í„° í•„í„°ë§ ---
    if "íšŒì°¨_numeric" in df_all_filtered.columns:
        base_filtered = df_all_filtered[df_all_filtered["íšŒì°¨_numeric"] == target_episode_num].copy()
    else:
        base_filtered = pd.DataFrame()
    if base_filtered.empty and "íšŒì°¨" in df_all_filtered.columns:
        possible_strs = [f"{int(target_episode_num)}í™”", f"{int(target_episode_num)}ì°¨"]
        mask = df_all_filtered["íšŒì°¨"].isin(possible_strs)
        base_filtered = df_all_filtered[mask].copy()

    # --- ì§€í‘œë³„ ì§‘ê³„ ---
    result_df = pd.DataFrame(columns=["IP", "value"])

    if not base_filtered.empty:
        if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].mean().reset_index()

        elif selected_metric == "TVING ë¼ì´ë¸Œ+QUICK":
            df_lq = base_filtered[
                (base_filtered["metric"] == "ì‹œì²­ì¸êµ¬") &
                (base_filtered["ë§¤ì²´"].isin(["TVING LIVE", "TVING QUICK"]))]
            if not df_lq.empty:
                result_df = df_lq.groupby("IP")["value"].sum().reset_index()

        elif selected_metric == "TVING VOD":
            df_vod = base_filtered[
                (base_filtered["metric"] == "ì‹œì²­ì¸êµ¬") &
                (base_filtered["ë§¤ì²´"] == "TVING VOD")]
            if not df_vod.empty:
                result_df = df_vod.groupby("IP")["value"].sum().reset_index()

        elif selected_metric in ["ì¡°íšŒìˆ˜", "ì–¸ê¸‰ëŸ‰"]:
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if selected_metric == "ì¡°íšŒìˆ˜" and not filtered.empty:
                # ê·œì¹™: ìœ íŠœë¸Œì¼ ê²½ìš° ì„¸ë¶€ì†ì„±1ì´ PGC/UGCë§Œ í¬í•¨
                filtered = filtered[(filtered["ë§¤ì²´"] != "ìœ íŠœë¸Œ") | (filtered["ì„¸ë¶€ì†ì„±1"].isin(["PGC", "UGC"]))]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].sum().reset_index()

        else:  # ê¸°íƒ€ ì§€í‘œ
            filtered = base_filtered[base_filtered["metric"] == selected_metric]
            if not filtered.empty:
                result_df = filtered.groupby("IP")["value"].mean().reset_index()

    # --- ëª¨ë“  IP í¬í•¨ ë° ì •ë ¬ ---
    all_ips_in_filter = df_all_filtered["IP"].unique()
    if result_df.empty:
        result_df = pd.DataFrame({'IP': all_ips_in_filter, 'value': 0})
    else:
        result_df = result_df.set_index("IP").reindex(all_ips_in_filter, fill_value=0).reset_index()
    result_df['value'] = pd.to_numeric(result_df['value'], errors='coerce').fillna(0)
    return result_df.sort_values("value", ascending=False)


# ===== [í˜ì´ì§€ 5] íŠ¹ì • íšŒì°¨ ë¹„êµ ì‹œê°í™” =====
def plot_episode_comparison(
    df_result: pd.DataFrame,
    selected_metric: str,
    selected_episode: str,
    base_ip: str
):
    """íŠ¹ì • íšŒì°¨ ë¹„êµ ê²°ê³¼ ì‹œê°í™” (Bar Chart with Highlight)"""
    colors = ['#d93636' if ip == base_ip else '#666666' for ip in df_result['IP']]
    metric_label = selected_metric.replace("Tì‹œì²­ë¥ ", "íƒ€ê¹ƒ").replace("Hì‹œì²­ë¥ ", "ê°€êµ¬")

    fig = px.bar(
        df_result,
        x="IP",
        y="value",
        text="value",
        title=f"{selected_episode} - '{metric_label}' (ê¸°ì¤€: {base_ip})"
    )

    # âš ï¸ f-stringì„ ì“°ë©´ %{y}ê°€ íŒŒì´ì¬ í¬ë§·ìœ¼ë¡œ í•´ì„ë¨ â†’ ì¼ë°˜ ë¬¸ìì—´ ê²°í•© ì‚¬ìš©
    if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
        hover_template = "<b>%{x}</b><br>" + metric_label + ": %{y:.2f}%"
    else:
        hover_template = "<b>%{x}</b><br>" + metric_label + ": %{y:,}"

    fig.update_traces(
        marker_color=colors,
        textposition='outside',
        hovertemplate=hover_template
    )

    if selected_metric in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
        fig.update_traces(texttemplate='%{text:.2f}%')
        fig.update_layout(yaxis_title=metric_label + " (%)")
    else:
        fig.update_traces(texttemplate='%{text:,0f}')
        fig.update_layout(yaxis_title=metric_label)

    fig.update_layout(
        xaxis_title=None,
        xaxis=dict(tickfont=dict(size=11)),
        height=350,
        margin=dict(t=40, b=0, l=0, r=0)
    )
    st.plotly_chart(fig, use_container_width=True)


# ===== [í˜ì´ì§€ 5] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_episode():
    # --- ë°ì´í„° ë¡œë“œ ---
    df_all = load_data()

    # --- í•„í„°ë¥¼ í•œ í–‰ì— ëª¨ë‘ ë°°ì¹˜ (íƒ€ì´í‹€ | ê¸°ì¤€IP | íšŒì°¨ | ë¹„êµ ê·¸ë£¹ ê¸°ì¤€[ë‹¤ì¤‘]) ---
    filter_cols = st.columns([3, 3, 2, 3])  # [Title | Base IP | Episode | Group Criteria]
    ip_options_main = sorted(df_all["IP"].dropna().unique().tolist())
    episode_options_main = get_episode_options(df_all)  # ê³µí†µ ìœ í‹¸

    with filter_cols[0]:
        st.markdown("## ğŸ¬ íšŒì°¨ë³„ ë¹„êµ")  # íƒ€ì´í‹€

    with filter_cols[1]:
        selected_base_ip = st.selectbox(
            "ê¸°ì¤€ IP (í•˜ì´ë¼ì´íŠ¸)",
            ip_options_main,
            index=0 if ip_options_main else None,
            label_visibility="collapsed",
            key="ep_base_ip_main"
        )

    with filter_cols[2]:
        selected_episode = st.selectbox(
            "íšŒì°¨",
            episode_options_main,
            index=0 if episode_options_main else None,
            label_visibility="collapsed",
            key="ep_selected_episode_main"
        )

    # â—€â—€â—€ í•µì‹¬ ë³€ê²½: ë¹„êµëŒ€ìƒ ê·¸ë£¹ ë‹¨ì¼ â†’ ë‹¤ì¤‘ (ê°™ì€ í–‰ì— ë°°ì¹˜)
    with filter_cols[3]:
        selected_group_criteria = st.multiselect(
            "ë¹„êµ ê·¸ë£¹ ê¸°ì¤€",
            ["ë™ì¼ í¸ì„±", "ë°©ì˜ ì—°ë„"],
            default=["ë™ì¼ í¸ì„±"],
            label_visibility="collapsed",
            key="ep_group_criteria"
        )

    st.divider()

    if not selected_base_ip or not selected_episode:
        st.warning("í•„í„°ì—ì„œ ê¸°ì¤€ IPì™€ íšŒì°¨ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # --- ë‹¤ì¤‘ ê¸°ì¤€ ì ìš© ë¡œì§ ---
    df_filtered_main = df_all.copy()
    group_filter_applied = []

    if selected_group_criteria:
        base_rows = df_all[df_all["IP"] == selected_base_ip]
        if not base_rows.empty:
            base_prog = base_rows["í¸ì„±"].dropna().mode().iloc[0] if not base_rows["í¸ì„±"].dropna().empty else None
            date_col = "ë°©ì˜ì‹œì‘ì¼" if ("ë°©ì˜ì‹œì‘ì¼" in df_all.columns and df_all["ë°©ì˜ì‹œì‘ì¼"].notna().any()) else "ì£¼ì°¨ì‹œì‘ì¼"
            base_year = base_rows[date_col].dropna().dt.year.mode().iloc[0] if not base_rows[date_col].dropna().empty else None

            if "ë™ì¼ í¸ì„±" in selected_group_criteria and base_prog:
                df_filtered_main = df_filtered_main[df_filtered_main["í¸ì„±"] == base_prog]
                group_filter_applied.append(f"í¸ì„±='{base_prog}'")
            elif "ë™ì¼ í¸ì„±" in selected_group_criteria and not base_prog:
                st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}'ì˜ í¸ì„± ì •ë³´ ì—†ìŒ")

            if "ë°©ì˜ ì—°ë„" in selected_group_criteria and base_year:
                df_filtered_main = df_filtered_main[df_filtered_main[date_col].dt.year == int(base_year)]
                group_filter_applied.append(f"ì—°ë„={int(base_year)}")
            elif "ë°©ì˜ ì—°ë„" in selected_group_criteria and not base_year:
                st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}'ì˜ ì—°ë„ ì •ë³´ ì—†ìŒ")
        else:
            st.warning(f"ê¸°ì¤€ IP '{selected_base_ip}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            df_filtered_main = pd.DataFrame()

    if df_filtered_main.empty:
        st.warning("ì„ íƒí•˜ì‹  í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if selected_base_ip not in df_filtered_main["IP"].unique():
        st.warning("ì„ íƒí•˜ì‹  ê·¸ë£¹ ì¡°ê±´ì— ê¸°ì¤€ IPê°€ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # --- ì£¼ìš” ì§€í‘œ ëª©ë¡ ---
    key_metrics = ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "TVING ë¼ì´ë¸Œ+QUICK", "TVING VOD", "ì¡°íšŒìˆ˜", "ì–¸ê¸‰ëŸ‰"]
    filter_desc = " (" + ", ".join(group_filter_applied) + ")" if group_filter_applied else " (ì „ì²´ IP)"
    st.markdown(f"#### {selected_episode} ì„±ê³¼ ë¹„êµ{filter_desc} (ê¸°ì¤€ IP: {selected_base_ip})")
    st.caption("ì„ íƒëœ IP ê·¸ë£¹ì˜ ì„±ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°ì¤€ IPëŠ” ë¶‰ì€ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
    st.markdown("---")

    chart_cols = st.columns(2)
    for i, metric in enumerate(key_metrics):
        with chart_cols[i % 2]:
            try:
                df_result = filter_data_for_episode_comparison(df_filtered_main, selected_episode, metric)
                if df_result.empty or df_result['value'].isnull().all() or (df_result['value'] == 0).all():
                    metric_label = metric.replace("Tì‹œì²­ë¥ ", "íƒ€ê¹ƒ").replace("Hì‹œì²­ë¥ ", "ê°€êµ¬")
                    st.markdown(f"###### {selected_episode} - '{metric_label}'")
                    st.info("ë°ì´í„° ì—†ìŒ")
                    st.markdown("---")
                else:
                    plot_episode_comparison(df_result, metric, selected_episode, selected_base_ip)
                    st.markdown("---")
            except Exception as e:
                st.error(f"ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜({metric}): {e}")

#endregion


#region [ 13. í˜ì´ì§€ 6: ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì„±ê³¼  ]
# =====================================================

def render_growth_score():
    """
    ë ˆì´ì•„ì›ƒ: [ìƒë‹¨ í—¤ë”: 'ì„ íƒí•œ ì‘í’ˆ' | IPì„ íƒ | íšŒì°¨ê¸°ì¤€] â†’ [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ] â†’ [í¬ì§€ì…”ë‹ë§µ] â†’ [ì „ì²´í‘œ]
    ë³€ê²½ì‚¬í•­ ë°˜ì˜:
      - íƒ€ì´í‹€ì„ '[ì„ íƒí•œ ì‘í’ˆëª…] ìŠ¤ì½”ì–´' ë¡œ í‘œì‹œ
      - 'ì¢…í•©ë“±ê¸‰' ì¹´ë“œ 2ì¹¸(ê°•ì¡°)
      - í¬ì§€ì…”ë‹ë§µ: ë‹¨ì¼ê³„ì—´(Blues) ê·¸ë¼ë°ì´ì…˜, ì¶• í‘œê¸° ì œê±°, ì…€ ì¢Œìƒë‹¨ì— 'S+2' ë“±ê¸‰ í¼ì§€ë§‰í•˜ê²Œ
        ì‘í’ˆëª…ì€ ì¤„ë°”ê¿ˆ ì ìš©(í•œ ì¤„ í•œ ì‘í’ˆ), ê°€ë¡œ/ì„¸ë¡œ íŒ¨ë”© ìµœì†Œí™”, ì„¸ë¡œ ê¸¸ì´ í™•ëŒ€
      - ì „ì²´í‘œ ì •ë ¬: ì¢…í•©ì˜ 'ì ˆëŒ€ë“±ê¸‰' ìš°ì„  ë‚´ë¦¼ì°¨ìˆœ, ë™ë¥  ì‹œ 'ìƒìŠ¹ë“±ê¸‰' ë†’ì€ ìˆœ
      - (ì´ë²ˆ ìˆ˜ì •) ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘==1 â†’ TVING VOD ì‹œì²­ì¸êµ¬ ì ˆëŒ€ê°’ë§Œ Ã—1.4 ë³´ì •, ìƒìŠ¹ë“±ê¸‰ ê²½ë¡œ ë¯¸ì ìš©
      - (ì´ë²ˆ ìˆ˜ì •) ìƒìŠ¹ë“±ê¸‰ ë¼ë²¨ ìƒìˆ˜í™”ë¡œ '+-2' ë²„ê·¸ ì œê±°
    """
    # â—€â—€â—€ [ìˆ˜ì •] load_data() í˜¸ì¶œ ë°©ì‹ ë³€ê²½
    df_all = load_data().copy()

    # ---------- ì„¤ì • ----------
    EP_CHOICES = [2, 4, 6, 8, 10, 12, 14, 16]
    ROW_LABELS = ["S","A","B","C","D"]      # ì ˆëŒ€
    COL_LABELS = ["+2","+1","0","-1","-2"]  # ìƒìŠ¹
    ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
    SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}
    SLOPE_LABELS = ["+2", "+1", "0", "-1", "-2"]  # â† ìƒìŠ¹ ë¼ë²¨ ìƒìˆ˜(ë²„ê·¸ ë°©ì§€)
    NETFLIX_VOD_FACTOR = 1.4  # â† ë³´ì • ê³„ìˆ˜

    METRICS = [
        ("ê°€êµ¬ì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", None),     # ratings mean
        ("íƒ€ê¹ƒì‹œì²­ë¥ ", "Tì‹œì²­ë¥ ", None),     # ratings mean
        ("TVING LIVE", "ì‹œì²­ì¸êµ¬", "LIVE"), # ep sum mean
        ("TVING VOD",  "ì‹œì²­ì¸êµ¬", "VOD"),  # ep sum mean  â† â˜† ì ˆëŒ€ë§Œ ë³´ì • ì ìš©
    ]

    ips = sorted(df_all["IP"].dropna().unique().tolist())
    if not ips:
        st.warning("IP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    # ì‘ì€ ìŠ¤íƒ€ì¼(ìš”ì•½ì¹´ë“œ ê³µí†µ)
    

    # ---------- í—¤ë”(íƒ€ì´í‹€/ì„ íƒ) ----------
    _ep_display = st.session_state.get("growth_ep_cutoff", 4)

    head = st.columns([5, 3, 2])
    with head[0]:
        st.markdown(
            f"## ğŸš€ ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ <span style='font-size:20px;color:#6b7b93'>(~{_ep_display}íšŒ ê¸°ì¤€)</span>",
            unsafe_allow_html=True
        )
    with head[1]:
        selected_ip = st.selectbox(
            "IP ì„ íƒ", ips, index=0,
            key="growth_ip_select", label_visibility="collapsed"
        )
    with head[2]:
        ep_cutoff = st.selectbox(
            "íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1,
            key="growth_ep_cutoff", label_visibility="collapsed"
        )

    # ---------- ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´ ----------
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("""
    **ë“±ê¸‰ ì²´ê³„**
    - **ì ˆëŒ€ê°’ ë“±ê¸‰**: ê° ì§€í‘œì˜ ì ˆëŒ€ ìˆ˜ì¤€ì„ IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ë¡œ êµ¬ë¶„ â†’ `S / A / B / C / D`
    - **ìƒìŠ¹ë¥  ë“±ê¸‰**: ë™ì¼ ê¸°ê°„(ì„ íƒ íšŒì°¨ ë²”ìœ„) ë‚´ íšŒì°¨-ê°’ ì„ í˜•íšŒê·€ ê¸°ìš¸ê¸°(slope)ë¥¼ IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ë¡œ êµ¬ë¶„ â†’ `+2 / +1 / 0 / -1 / -2`
    - **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€ê°’ê³¼ ìƒìŠ¹ë¥  ë“±ê¸‰ì„ ê²°í•©í•´ í‘œê¸° (ì˜ˆ: `A+2`).

    **íšŒì°¨ ê¸°ì¤€(~NíšŒ)**
    - ê° IPì˜ **1~NíšŒ** ë°ì´í„°ë§Œ ì‚¬ìš©.
    - **0/ë¹„ì •ìƒê°’ ì œì™¸**: ìˆ«ì ë³€í™˜ ì‹¤íŒ¨/0ì€ `NaN` ì²˜ë¦¬ í›„ í‰ê· /íšŒê·€ì—ì„œ ì œì™¸.
            """)

    # ì„ íƒí•œ ì‘í’ˆ íƒ€ì´í‹€
    st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>",
            unsafe_allow_html=True
        )

    # ---------- ê³µí†µ ìœ í‹¸ ----------
    def _filter_to_ep(df, n):
        """íšŒì°¨ n ì´í•˜ë§Œ ì‚¬ìš©(ì ì‘ëª¨ë“œ: ì—†ëŠ” íšŒì°¨ëŠ” ìë™ ì œì™¸)"""
        if "íšŒì°¨_numeric" in df.columns:
            return df[pd.to_numeric(df["íšŒì°¨_numeric"], errors="coerce") <= float(n)]
        m = df["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False)
        return df[pd.to_numeric(m, errors="coerce") <= float(n)]

    def _series_for_reg(ip_df, metric, media):
        # âš ï¸ ìƒìŠ¹ë“±ê¸‰(ê¸°ìš¸ê¸°) ê²½ë¡œ â€” ë³´ì • ë¯¸ì ìš© (ê¸°ìš¸ê¸° ë“±ê¸‰ ìœ ì§€)
        sub = ip_df[ip_df["metric"] == metric].copy()
        if media == "LIVE":
            sub = sub[sub["ë§¤ì²´"] == "TVING LIVE"]
        elif media == "VOD":
            sub = sub[sub["ë§¤ì²´"] == "TVING VOD"]
        sub = _filter_to_ep(sub, ep_cutoff)
        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        if sub.empty: return None
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            s = sub.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        else:
            s = sub.groupby("íšŒì°¨_numeric")["value"].sum().reset_index()
        s = s.sort_values("íšŒì°¨_numeric")
        x = s["íšŒì°¨_numeric"].astype(float).values
        y = s["value"].astype(float).values
        return (x, y) if len(x) >= 2 else None

    def _slope(ip_df, metric, media=None):
        xy = _series_for_reg(ip_df, metric, media)
        if xy is None: return np.nan
        try: return float(np.polyfit(xy[0], xy[1], 1)[0])
        except Exception: return np.nan

    def _abs_value(ip_df, metric, media=None):
        # â˜† ì ˆëŒ€ë“±ê¸‰ ì‚°ì¶œë§Œ ë³´ì • ì ìš© (ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘==1 & TVING VOD & ì‹œì²­ì¸êµ¬)
        ip_df = _filter_to_ep(ip_df, ep_cutoff)
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            return mean_of_ip_episode_mean(ip_df, metric)
        if metric == "ì‹œì²­ì¸êµ¬" and media == "LIVE":
            return mean_of_ip_episode_sum(ip_df, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
        if metric == "ì‹œì²­ì¸êµ¬" and media == "VOD":
            adj = ip_df.copy()
            if "ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘" in adj.columns:
                msk = (adj.get("ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘", 0) == 1) & (adj["ë§¤ì²´"] == "TVING VOD") & (adj["metric"] == "ì‹œì²­ì¸êµ¬")
                if msk.any():
                    adj.loc[msk, "value"] = pd.to_numeric(adj.loc[msk, "value"], errors="coerce") * NETFLIX_VOD_FACTOR
            return mean_of_ip_episode_sum(adj, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
        return None

    def _quintile_grade(series, labels):
        s = pd.Series(series).astype(float)
        valid = s.dropna()
        if valid.empty:
            return pd.Series(index=s.index, data=np.nan)
        ranks = valid.rank(method="average", ascending=False, pct=True)
        bins = [0, .2, .4, .6, .8, 1.0000001]
        idx = np.digitize(ranks.values, bins, right=True) - 1
        idx = np.clip(idx, 0, 4)
        out = pd.Series([labels[i] for i in idx], index=valid.index)
        return out.reindex(s.index)

    def _to_percentile(s):
        s = pd.Series(s).astype(float)
        return s.rank(pct=True) * 100

    # ---------- IPë³„ ì ˆëŒ€/ê¸°ìš¸ê¸° ----------
    rows = []
    for ip in ips:
        ip_df = df_all[df_all["IP"] == ip]
        row = {"IP": ip}
        for disp, metric, media in METRICS:
            row[f"{disp}_ì ˆëŒ€"] = _abs_value(ip_df, metric, media)
            row[f"{disp}_ê¸°ìš¸ê¸°"] = _slope(ip_df, metric, media)
        rows.append(row)
    base = pd.DataFrame(rows)

    # ---------- ë“±ê¸‰ ì‚°ì • ----------
    for disp, _, _ in METRICS:
        base[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(base[f"{disp}_ì ˆëŒ€"], ["S","A","B","C","D"])
        base[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(base[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
        base[f"{disp}_ì¢…í•©"]   = base[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + base[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str)

    base["_ABS_PCT_MEAN"]   = pd.concat([_to_percentile(base[f"{d}_ì ˆëŒ€"])   for d,_,_ in METRICS], axis=1).mean(axis=1)
    base["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(base[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_ in METRICS], axis=1).mean(axis=1)
    base["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(base["_ABS_PCT_MEAN"],   ["S","A","B","C","D"])
    base["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(base["_SLOPE_PCT_MEAN"], SLOPE_LABELS)
    base["ì¢…í•©ë“±ê¸‰"] = base["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + base["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str)

    # ---------- [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ] ----------
    focus = base[base["IP"] == selected_ip].iloc[0]

    card_cols = st.columns([2, 1, 1, 1, 1])  # ì¢…í•© 2ì¹¸
    # ì¢…í•© ì¹´ë“œ (ê°•ì¡°)
    with card_cols[0]:
        st.markdown(
            f"""
            <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
              <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
              <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
            </div>
            """,
            unsafe_allow_html=True
        )
    # ë‚˜ë¨¸ì§€ 4ê°œ
    def _grade_card(col, title, val):
        with col:
            st.markdown(
                f"""
                <div class="kpi-card" style="height:110px;">
                  <div class="kpi-title">{title}</div>
                  <div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div>
                </div>
                """,
                unsafe_allow_html=True
            )
    _grade_card(card_cols[1], "ê°€êµ¬ì‹œì²­ë¥  ë“±ê¸‰", focus["ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©"])
    _grade_card(card_cols[2], "íƒ€ê¹ƒì‹œì²­ë¥  ë“±ê¸‰", focus["íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©"])
    _grade_card(card_cols[3], "TVING LIVE ë“±ê¸‰", focus["TVING LIVE_ì¢…í•©"])
    _grade_card(card_cols[4], "TVING VOD ë“±ê¸‰",  focus["TVING VOD_ì¢…í•©"])

    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)
    # ===== [íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´: ì„ íƒ IP] ==========================================
    from plotly import graph_objects as go, express as px

    # --- (1) ì„ íƒ IPì˜ 'ì‹¤ì œ ê°’'ì´ ìˆëŠ” íšŒì°¨ê¹Œì§€ë§Œ Ns ìƒì„± ---
    _ip_all = df_all[df_all["IP"] == selected_ip].copy()
    if "íšŒì°¨_numeric" in _ip_all.columns:
        _ip_all["ep"] = pd.to_numeric(_ip_all["íšŒì°¨_numeric"], errors="coerce")
    else:
        _ip_all["ep"] = pd.to_numeric(_ip_all["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False), errors="coerce")

    _ip_all["value_num"] = pd.to_numeric(_ip_all["value"], errors="coerce").replace(0, np.nan)
    _valid_eps = _ip_all.loc[_ip_all["value_num"].notna(), "ep"]

    if _valid_eps.notna().any():
        _max_ep = int(np.nanmax(_valid_eps))
        _Ns = [n for n in EP_CHOICES if n <= _max_ep]
    else:
        _Ns = [min(EP_CHOICES)]  # ìœ íš¨ ë°ì´í„° ì—†ìœ¼ë©´ ìµœì†Œê°’ë§Œ

    # --- (2) cutoff=Në§ˆë‹¤ ì „ì²´ IP ê¸°ì¤€ìœ¼ë¡œ ë“±ê¸‰ ì‚°ì • í›„, ì„ íƒ IP í•œ ì¤„ë§Œ ë½‘ê¸° ---
    ABS_NUM = {"S":5, "A":4, "B":3, "C":2, "D":1}

    def _abs_value_n(ip_df, metric, media, n):
        sub = _filter_to_ep(ip_df, n)
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            return mean_of_ip_episode_mean(sub, metric)
        if metric == "ì‹œì²­ì¸êµ¬" and media == "LIVE":
            return mean_of_ip_episode_sum(sub, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
        if metric == "ì‹œì²­ì¸êµ¬" and media == "VOD":
            # â˜† ì ˆëŒ€ê°’(íšŒì°¨ N ê¸°ì¤€)ë§Œ ë³´ì •
            adj = sub.copy()
            if "ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘" in adj.columns:
                msk = (adj.get("ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘", 0) == 1) & (adj["ë§¤ì²´"] == "TVING VOD") & (adj["metric"] == "ì‹œì²­ì¸êµ¬")
                if msk.any():
                    adj.loc[msk, "value"] = pd.to_numeric(adj.loc[msk, "value"], errors="coerce") * NETFLIX_VOD_FACTOR
            return mean_of_ip_episode_sum(adj, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])
        return None

    def _slope_n(ip_df, metric, media, n):
        # âš ï¸ ìƒìŠ¹ë“±ê¸‰ìš© ê²½ë¡œ â€” ë³´ì • ë¯¸ì ìš©
        sub = ip_df[ip_df["metric"] == metric].copy()
        if media == "LIVE":
            sub = sub[sub["ë§¤ì²´"] == "TVING LIVE"]
        elif media == "VOD":
            sub = sub[sub["ë§¤ì²´"] == "TVING VOD"]
        sub = _filter_to_ep(sub, n)
        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        if sub.empty:
            return np.nan
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            s = sub.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        else:
            s = sub.groupby("íšŒì°¨_numeric")["value"].sum().reset_index()
        s = s.sort_values("íšŒì°¨_numeric")
        x = s["íšŒì°¨_numeric"].astype(float).values
        y = s["value"].astype(float).values
        if len(x) < 2:
            return np.nan
        try:
            return float(np.polyfit(x, y, 1)[0])
        except Exception:
            return np.nan

    evo_rows = []
    for n in _Ns:
        # ì „ì²´ IPì— ëŒ€í•´ ì ˆëŒ€/ê¸°ìš¸ê¸° ê³„ì‚°
        tmp = []
        for ip in ips:
            ip_df = df_all[df_all["IP"] == ip]
            row = {"IP": ip}
            for disp, metric, media in METRICS:
                row[f"{disp}_ì ˆëŒ€"]   = _abs_value_n(ip_df, metric, media, n)
                row[f"{disp}_ê¸°ìš¸ê¸°"] = _slope_n(ip_df, metric, media, n)
            tmp.append(row)
        tmp = pd.DataFrame(tmp)

        # ë“±ê¸‰ ì‚°ì •(ê° ì§€í‘œ â†’ ì ˆëŒ€/ìƒìŠ¹ â†’ ì¢…í•©, ê·¸ ë‹¤ìŒ 'ì¢…í•©'ì˜ ì ˆëŒ€/ìƒìŠ¹)
        for disp, _, _ in METRICS:
            tmp[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp[f"{disp}_ì ˆëŒ€"],   ["S","A","B","C","D"])
            tmp[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
        tmp["_ABS_PCT_MEAN"]   = pd.concat([_to_percentile(tmp[f"{d}_ì ˆëŒ€"])   for d,_,_ in METRICS], axis=1).mean(axis=1)
        tmp["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(tmp[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_ in METRICS], axis=1).mean(axis=1)
        tmp["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp["_ABS_PCT_MEAN"],   ["S","A","B","C","D"])
        tmp["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp["_SLOPE_PCT_MEAN"], SLOPE_LABELS)

        # ì„ íƒ IPë§Œ ì¶”ì¶œ
        row = tmp[tmp["IP"] == selected_ip]
        if not row.empty and pd.notna(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]):
            ag = str(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"])
            sg = str(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
            evo_rows.append({
                "N": n,
                "íšŒì°¨ë¼ë²¨": f"{n}íšŒì°¨",
                "ABS_GRADE": ag,
                "SLOPE_GRADE": sg,
                "ABS_NUM": ABS_NUM.get(ag, np.nan)
            })

    evo = pd.DataFrame(evo_rows)
    if evo.empty:
        st.info("íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        # --- (3) ë¼ì¸ ì°¨íŠ¸
        fig_e = go.Figure()
        fig_e.add_vrect(
            x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5,
            fillcolor="rgba(0,90,200,0.12)", line_width=0
        )
        fig_e.add_trace(go.Scatter(
            x=evo["N"], y=evo["ABS_NUM"],
            mode="lines+markers",
            line=dict(shape="spline", width=3),
            marker=dict(size=8),
            name=selected_ip,
            hoverinfo="skip"
        ))
        for xi, yi, ag, sg in zip(evo["N"], evo["ABS_NUM"], evo["ABS_GRADE"], evo["SLOPE_GRADE"]):
            label = f"{ag}{sg}" if isinstance(ag, str) and isinstance(sg, str) else ""
            fig_e.add_annotation(
                x=xi, y=yi, text=label, showarrow=False,
                font=dict(size=12, color="#333", family="sans-serif"), yshift=14
            )
        fig_e.update_xaxes(
            tickmode="array",
            tickvals=evo["N"].tolist(),
            ticktext=[f"{int(n)}íšŒì°¨" for n in evo["N"].tolist()],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_yaxes(
            tickmode="array",
            tickvals=[5,4,3,2,1],
            ticktext=["S","A","B","C","D"],
            range=[0.7, 5.3],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_layout(
            height=200,
            margin=dict(l=8, r=8, t=8, b=8),
            showlegend=False
        )
        st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})

    st.divider()

    # ---------- [í¬ì§€ì…”ë‹ë§µ] ----------
    st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")

    # ì…€ë³„ ì‘í’ˆ ëª¨ìœ¼ê¸°
    pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
    for _, r in base.iterrows():
        ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
        rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
        if ra in ROW_LABELS and rs in COL_LABELS:
            pos_map[(ra, rs)].append(r["IP"])

    # ìƒ‰ ê°’(ì ìˆ˜â†‘=ë” ì–´ë‘¡ê²Œ)
    z = []
    for rr in ROW_LABELS:
        row_z = []
        for cc in COL_LABELS:
            row_z.append((ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0)
        z.append(row_z)

    fig = px.imshow(
        z,
        x=COL_LABELS, y=ROW_LABELS,
        origin="upper",
        color_continuous_scale="Blues",
        range_color=[1, 5],
        text_auto=False,
        aspect="auto"
    ).update_traces(xgap=0.0, ygap=0.0)

    # ì¶•/ëˆˆê¸ˆ/ì»¬ëŸ¬ë°”/ë§ˆì§„ ìµœì†Œí™”
    fig.update_xaxes(showticklabels=False, title=None, ticks="")
    fig.update_yaxes(showticklabels=False, title=None, ticks="")
    fig.update_layout(
        height=760,
        margin=dict(l=2, r=2, t=2, b=2),
        coloraxis_showscale=False
    )
    fig.update_traces(hovertemplate="<extra></extra>")  # hover ê¹”ë”

    # ì–´ë‘ìš´ ì…€ì—” í° ê¸€ì, ë°ì€ ì…€ì—” ì§™ì€ íšŒìƒ‰
    def _font_color(val: float) -> str:
        return "#FFFFFF" if val >= 3.3 else "#111111"

    # ë“±ê¸‰ì€ ì¢Œìƒë‹¨(í¬ê²Œ), ì‘í’ˆëª…ì€ ì¤‘ì•™(ì¤„ë°”ê¿ˆ)
    for r_idx, rr in enumerate(ROW_LABELS):
        for c_idx, cc in enumerate(COL_LABELS):
            cell_val = z[r_idx][c_idx]
            names = pos_map[(rr, cc)]
            color = _font_color(cell_val)

            # 1) ë“±ê¸‰ ë¼ë²¨
            fig.add_annotation(
                x=cc, y=rr, xref="x", yref="y",
                text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>",
                showarrow=False,
                font=dict(size=22, color=color, family="sans-serif"),
                xanchor="center", yanchor="top",
                xshift=0, yshift=80, align="left"
            )

            # 2) ì‘í’ˆëª…
            if names:
                fig.add_annotation(
                    x=cc, y=rr, xref="x", yref="y",
                    text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>",
                    showarrow=False,
                    font=dict(size=12, color=color, family="sans-serif"),
                    xanchor="center", yanchor="middle",
                    yshift=6
                )

    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # ---------- [ì „ì²´í‘œ] (ì •ë ¬ ê·œì¹™: ì ˆëŒ€ > ìƒìŠ¹ ë‚´ë¦¼ì°¨ìˆœ) ----------
    table = base[[
        "IP","ì¢…í•©_ì ˆëŒ€ë“±ê¸‰","ì¢…í•©_ìƒìŠ¹ë“±ê¸‰","ì¢…í•©ë“±ê¸‰",
        "ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©","TVING LIVE_ì¢…í•©","TVING VOD_ì¢…í•©"
    ]].copy()

    # ì •ë ¬ í‚¤
    table["_abs_key"]   = table["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].map(ABS_SCORE).fillna(0)
    table["_slope_key"] = table["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].map(SLO_SCORE).fillna(0)
    table = table.sort_values(["_abs_key","_slope_key","IP"], ascending=[False, False, True])

    table_view = table[[
        "IP","ì¢…í•©ë“±ê¸‰","ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©","TVING LIVE_ì¢…í•©","TVING VOD_ì¢…í•©"
    ]].rename(columns={
        "ì¢…í•©ë“±ê¸‰":"ì¢…í•©",
        "ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©":"ê°€êµ¬ì‹œì²­ë¥ ",
        "íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©":"íƒ€ê¹ƒì‹œì²­ë¥ ",
        "TVING LIVE_ì¢…í•©":"TVING LIVE",
        "TVING VOD_ì¢…í•©":"TVING VOD"
    })

    # ë“±ê¸‰ ì…€ ìŠ¤íƒ€ì¼
    from st_aggrid import GridOptionsBuilder, AgGrid, GridUpdateMode, JsCode
    grade_cell = JsCode("""
    function(params){
      const v = (params.value || '').toString();
      let bg='#fff', color='#111', fw='700';
      if (v.startsWith('S')) { bg='rgba(0,91,187,0.14)'; color='#003d80'; }
      else if (v.startsWith('A')) { bg='rgba(0,91,187,0.08)'; color='#004a99'; }
      else if (v.startsWith('B')) { bg='rgba(0,0,0,0.03)'; color:'#333'; fw='600'; }
      else if (v.startsWith('C')) { bg='rgba(42,97,204,0.08)'; color:'#2a61cc'; }
      else if (v.startsWith('D')) { bg='rgba(42,97,204,0.14)'; color:'#1a44a3'; }
      return {'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'};
    }""")

    gb = GridOptionsBuilder.from_dataframe(table_view)
    gb.configure_default_column(resizable=True, sortable=True, filter=False,
                                headerClass='centered-header bold-header',
                                cellStyle={'textAlign':'center'})
    gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
    for colname in ["ì¢…í•©","ê°€êµ¬ì‹œì²­ë¥ ","íƒ€ê¹ƒì‹œì²­ë¥ ","TVING LIVE","TVING VOD"]:
        gb.configure_column(colname, cellStyle=grade_cell, width=120)
    grid_options = gb.build()

    st.markdown("#### ğŸ“‹ IPì „ì²´")
    AgGrid(
        table_view,
        gridOptions=grid_options,
        theme="streamlit",
        height=420,
        fit_columns_on_grid_load=True,
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )

# =====================================================
#endregion




#region [ 14. í˜ì´ì§€ 7: ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸ ]
# =====================================================

def render_growth_score_digital():

    """
    ë ˆì´ì•„ì›ƒ: [ìƒë‹¨ í—¤ë”: íƒ€ì´í‹€ | IPì„ íƒ | íšŒì°¨ê¸°ì¤€] â†’ [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ]
           â†’ [íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´(ì„ íƒ IP)] â†’ [í¬ì§€ì…”ë‹ë§µ] â†’ [ì „ì²´í‘œ]

    ì‚¬ìš© ë©”íŠ¸ë¦­(ê³ ì •):
      - ì¡°íšŒìˆ˜: íšŒì°¨í•© ì‹œê³„ì—´ â†’ ì ˆëŒ€(í‰ê· ), ìƒìŠ¹(íšŒê·€ ê¸°ìš¸ê¸°)
      - í™”ì œì„±: íšŒì°¨í•© ì‹œê³„ì—´ â†’ ì ˆëŒ€(í‰ê· ), ìƒìŠ¹(íšŒê·€ ê¸°ìš¸ê¸°)
    """
    import numpy as np
    import pandas as pd
    import plotly.express as px
    from plotly import graph_objects as go
    import streamlit as st

    # â—€â—€â—€ [ìˆ˜ì •] load_data() í˜¸ì¶œ ë°©ì‹ ë³€ê²½
    df_all = load_data().copy()

    # ---------- ì„¤ì • ----------
    EP_CHOICES = [2, 4, 6, 8, 10, 12, 14, 16]

    ROW_LABELS = ["S","A","B","C","D"]     # ì ˆëŒ€
    COL_LABELS = ["+2","+1","0","-1","-2"] # ìƒìŠ¹
    ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
    SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}
    ABS_NUM    = {"S":5, "A":4, "B":3, "C":2, "D":1}

    # (í‘œì‹œëª…, metricëª…, ì§‘ê³„íƒ€ì…, slopeì‚¬ìš©ì—¬ë¶€)
    # type: "sum" â†’ íšŒì°¨í•©, "rank_inv" â†’(ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) í‰ê·  í›„ -1 ê³±í•´ ìƒí–¥í™”
    METRICS = [
("ì¡°íšŒìˆ˜",     "ì¡°íšŒìˆ˜",   "sum",      True),
    ("í™”ì œì„±", "F_Score", "mean", True),
]

    ips = sorted(df_all["IP"].dropna().unique().tolist())
    if not ips:
        st.warning("IP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    # ì‘ì€ ìŠ¤íƒ€ì¼(ìš”ì•½ì¹´ë“œ ê³µí†µ)
    

    # ---------- í—¤ë”(íƒ€ì´í‹€/ì„ íƒ) ----------
    _ep_display = st.session_state.get("growth_d_ep_cutoff", 4)
    head = st.columns([5, 3, 2])
    with head[0]:
        st.markdown(
            f"## ğŸ›°ï¸ ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸ <span style='font-size:20px;color:#6b7b93'>(~{_ep_display}íšŒ ê¸°ì¤€)</span>",
            unsafe_allow_html=True
        )
    with head[1]:
        selected_ip = st.selectbox("IP ì„ íƒ", ips, index=0,
                                   key="growth_d_ip_select", label_visibility="collapsed")
    with head[2]:
        ep_cutoff = st.selectbox("íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1,
                                 key="growth_d_ep_cutoff", label_visibility="collapsed")

    # ---------- ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´ ----------
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("""
**ë””ì§€í„¸ ì§€í‘œ ì •ì˜(ê³ ì •)**
- **ì¡°íšŒìˆ˜, í™”ì œì„±**: íšŒì°¨ë³„ í•©(ì—í”¼ì†Œë“œ ë‹¨ìœ„)ì„ ì‚¬ìš© â†’ 1~NíšŒ ì§‘ê³„ ì‹œê³„ì—´ì˜ í‰ê· /íšŒê·€
  *(â€» í™”ì œì„±ì€ **ìƒìŠ¹ìŠ¤ì½”ì–´ ë¯¸ì‚¬ìš©**, ì ˆëŒ€ìŠ¤ì½”ì–´ë§Œ ë“±ê¸‰í™”)*

**ë“±ê¸‰ ì²´ê³„(ê³µí†µ)**
- **ì ˆëŒ€ê°’ ë“±ê¸‰**: IP ê°„ ë°±ë¶„ìœ„ 20% ë‹¨ìœ„ `S/A/B/C/D`
- **ìƒìŠ¹ë¥  ë“±ê¸‰**: íšŒê·€ê¸°ìš¸ê¸° slopeì˜ IP ê°„ ë°±ë¶„ìœ„ 20% `+2/+1/0/-1/-2`
- **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€+ìƒìŠ¹ ê²°í•©(ì˜ˆ: `A+2`)  
  *(í™”ì œì„±ì€ ìƒìŠ¹ NaN ì²˜ë¦¬ë˜ì–´ ì¢…í•© ìƒìŠ¹ í‰ê· ì—ì„œ ìë™ ì œì™¸)*

**íšŒì°¨ ê¸°ì¤€(~NíšŒ)**
- ê° IPì˜ **1~NíšŒ** ë°ì´í„°ë§Œ ì‚¬ìš©(ì—†ëŠ” íšŒì°¨ ìë™ ì œì™¸)
- 0/ë¹„ì •ìƒê°’ì€ NaN ì²˜ë¦¬í•´ ì™œê³¡ ë°©ì§€
        """)

    st.markdown(
        f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>",
        unsafe_allow_html=True
    )

    # ---------- ê³µí†µ ìœ í‹¸ ----------
    def _filter_to_ep(df, n: int):
        """
        íšŒì°¨ 1ì´ìƒ ~ nì´í•˜ë§Œ ë‚¨ê¸´ë‹¤(00íšŒì°¨ ë“± ë°©ì˜ì „ ë°ì´í„° ì œê±°).
        'íšŒì°¨_numeric'ì´ ì—†ìœ¼ë©´ ìƒì„±í•´ì„œ downstream(groupby)ì— ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë§ì¶˜ë‹¤.
        ë˜í•œ valueë¥¼ ìˆ«ìë¡œ ìºìŠ¤íŒ…í•˜ê³  0ì€ NaNìœ¼ë¡œ ì¹˜í™˜í•œë‹¤.
        """
        if "íšŒì°¨_numeric" in df.columns:
            ep = pd.to_numeric(df["íšŒì°¨_numeric"], errors="coerce")
        else:
            ep = pd.to_numeric(df["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False), errors="coerce")
        mask = (ep >= 1) & (ep <= float(n))
        out = df.loc[mask].copy()
        out["íšŒì°¨_numeric"] = ep.loc[mask]
        if "value" in out.columns:
            out["value"] = pd.to_numeric(out["value"], errors="coerce").replace(0, np.nan)
        return out

    def _subset_by_metric(df, metric_name:str):
        return df[df["metric"].astype(str) == metric_name].copy()

    def _series_for_reg(ip_df, metric_name:str, mtype:str, n:int):
        sub = _subset_by_metric(ip_df, metric_name)
        sub = _filter_to_ep(sub, n)
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        if sub.empty:
            return None
        # íšŒì°¨ë³„ ì§‘ê³„
        if mtype == "sum":
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].sum()
        elif mtype == "rank_inv":
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].mean()  # ìˆœìœ„ â†’ í‰ê· 
            s["value"] = -1 * s["value"]  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ìƒí–¥ ìŠ¤ì¼€ì¼
        else:
            s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].mean()
        s = s.sort_values("íšŒì°¨_numeric")
        x = s["íšŒì°¨_numeric"].astype(float).values
        y = s["value"].astype(float).values
        return (x, y) if len(x) >= 1 else None

    def _abs_value(ip_df, metric_name:str, mtype:str, n:int):
        xy = _series_for_reg(ip_df, metric_name, mtype, n)
        if xy is None:
            return None
        return float(np.nanmean(xy[1])) if len(xy[1]) else None

    def _slope(ip_df, metric_name:str, mtype:str, n:int, use_slope:bool):
        if not use_slope:
            return np.nan  # â† í™”ì œì„±ì€ ìƒìŠ¹ ë¯¸ì‚¬ìš©
        xy = _series_for_reg(ip_df, metric_name, mtype, n)
        if xy is None or len(xy[0]) < 2:
            return np.nan
        try:
            return float(np.polyfit(xy[0], xy[1], 1)[0])
        except Exception:
            return np.nan

    def _quintile_grade(series, labels):
        s = pd.Series(series).astype(float)
        valid = s.dropna()
        if valid.empty:
            return pd.Series(index=s.index, data=np.nan)
        ranks = valid.rank(method="average", ascending=False, pct=True)
        bins = [0, .2, .4, .6, .8, 1.0000001]
        idx = np.digitize(ranks.values, bins, right=True) - 1
        idx = np.clip(idx, 0, 4)
        out = pd.Series([labels[i] for i in idx], index=valid.index)
        return out.reindex(s.index)

    def _to_percentile(s):
        s = pd.Series(s).astype(float)
        return s.rank(pct=True) * 100

    # ---------- IPë³„ ì ˆëŒ€/ê¸°ìš¸ê¸° (ep_cutoff ê¸°ì¤€) ----------
    rows = []
    for ip in ips:
        ip_df = df_all[df_all["IP"] == ip]
        row = {"IP": ip}
        for disp, metric_name, mtype, use_slope in METRICS:
            row[f"{disp}_ì ˆëŒ€"]   = _abs_value(ip_df, metric_name, mtype, ep_cutoff)
            row[f"{disp}_ê¸°ìš¸ê¸°"] = _slope(ip_df, metric_name, mtype, ep_cutoff, use_slope)
        rows.append(row)
    base = pd.DataFrame(rows)

    # ---------- ë“±ê¸‰ ì‚°ì • ----------
    for disp, _, _, _ in METRICS:
        base[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(base[f"{disp}_ì ˆëŒ€"],   ["S","A","B","C","D"])
        base[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(base[f"{disp}_ê¸°ìš¸ê¸°"], ["+2","+1","0","-1","-2"])
        base[f"{disp}_ì¢…í•©"]     = base[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + base[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str)

    base["_ABS_PCT_MEAN"]   = pd.concat([_to_percentile(base[f"{d}_ì ˆëŒ€"])   for d,_,_,_ in METRICS], axis=1).mean(axis=1)
    base["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(base[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_,_ in METRICS], axis=1).mean(axis=1)
    base["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(base["_ABS_PCT_MEAN"],   ["S","A","B","C","D"])
    base["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(base["_SLOPE_PCT_MEAN"], ["+2","+1","0","-1","-2"])
    base["ì¢…í•©ë“±ê¸‰"] = base["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + base["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str)

    # ---------- [ì„ íƒì‘í’ˆ ìš”ì•½ì¹´ë“œ] ----------
    focus = base[base["IP"] == selected_ip].iloc[0]

    card_cols = st.columns([2, 1, 1, 1, 1])  # ì¢…í•© 2ì¹¸
    with card_cols[0]:
        st.markdown(
            f"""
            <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
              <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
              <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
            </div>
            """, unsafe_allow_html=True
        )
    def _grade_card(col, title, val):
        with col:
            st.markdown(
                f"""
                <div class="kpi-card" style="height:110px;">
                  <div class="kpi-title">{title}</div>
                  <div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div>
                </div>
                """, unsafe_allow_html=True
            )
    _grade_card(card_cols[1], "ì¡°íšŒìˆ˜ ë“±ê¸‰",         focus["ì¡°íšŒìˆ˜_ì¢…í•©"])
    _grade_card(card_cols[2], "í™”ì œì„± ë“±ê¸‰",         focus["í™”ì œì„±_ì¢…í•©"])
    # í™”ì œì„±ì€ 'ì ˆëŒ€'ë§Œ í‘œê¸°
    _grade_card(card_cols[4], " ",  " ")  # ìë¦¬ ê· í˜•ìš©(í•„ìš” ì‹œ ë‹¤ë¥¸ ì§€í‘œ ëŒ€ì²´ ê°€ëŠ¥)

    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)

    # ===== [íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´: ì„ íƒ IP] =====
    _ip_all = df_all[df_all["IP"] == selected_ip].copy()
    # ep ìƒì„±
    if "íšŒì°¨_numeric" in _ip_all.columns:
        _ip_all["ep"] = pd.to_numeric(_ip_all["íšŒì°¨_numeric"], errors="coerce")
    else:
        _ip_all["ep"] = pd.to_numeric(_ip_all["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False), errors="coerce")
    _ip_all["value_num"] = pd.to_numeric(_ip_all["value"], errors="coerce").replace(0, np.nan)

    # ì„ íƒ IPì˜ ì¡°íšŒìˆ˜ 1Â·2íšŒì°¨ ë³´ìœ  ì—¬ë¶€(â€œN=2â€ ë¼ë²¨ ì²˜ë¦¬ì— ì‚¬ìš©)
    _v_view = df_all[(df_all["IP"] == selected_ip) & (df_all["metric"] == "ì¡°íšŒìˆ˜") & ((df_all["ë§¤ì²´"]!="ìœ íŠœë¸Œ") | (df_all["ì„¸ë¶€ì†ì„±1"].isin(["PGC","UGC"])) )].copy()
    _v_view["ep"] = pd.to_numeric(
        _v_view["íšŒì°¨_numeric"] if "íšŒì°¨_numeric" in _v_view.columns
        else _v_view["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False),
        errors="coerce"
    )
    _v_view["val"] = pd.to_numeric(_v_view["value"], errors="coerce").replace(0, np.nan)
    has_ep1 = bool(_v_view.loc[_v_view["ep"] == 1, "val"].notna().any())
    has_ep2 = bool(_v_view.loc[_v_view["ep"] == 2, "val"].notna().any())

    # â–¶ ì‹¤ì œ ê°’ì´ ì¡´ì¬í•˜ëŠ” ë§ˆì§€ë§‰ íšŒì°¨ê¹Œì§€ë§Œ Ns ìƒì„± (ep >= 1ë§Œ ì¸ì •)
    _valid_eps = _ip_all.loc[(_ip_all["value_num"].notna()) & (_ip_all["ep"] >= 1), "ep"]
    if _valid_eps.notna().any():
        _max_ep = int(np.nanmax(_valid_eps))
        _Ns = [n for n in EP_CHOICES if n <= _max_ep]
    else:
        _Ns = [min(EP_CHOICES)]

    evo_rows = []
    for n in _Ns:
        tmp = []
        for ip in ips:
            ip_df = df_all[df_all["IP"] == ip]
            row = {"IP": ip}
            for disp, metric_name, mtype, use_slope in METRICS:
                row[f"{disp}_ì ˆëŒ€"]   = _abs_value(ip_df, metric_name, mtype, n)
                row[f"{disp}_ê¸°ìš¸ê¸°"] = _slope(ip_df, metric_name, mtype, n, use_slope)
            tmp.append(row)
        tmp = pd.DataFrame(tmp)

        for disp, _, _, _ in METRICS:
            tmp[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp[f"{disp}_ì ˆëŒ€"],   ["S","A","B","C","D"])
            tmp[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp[f"{disp}_ê¸°ìš¸ê¸°"], ["+2","+1","0","-1","-2"])
        tmp["_ABS_PCT_MEAN"]   = pd.concat([_to_percentile(tmp[f"{d}_ì ˆëŒ€"])   for d,_,_,_ in METRICS], axis=1).mean(axis=1)
        tmp["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(tmp[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_,_ in METRICS], axis=1).mean(axis=1)
        tmp["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp["_ABS_PCT_MEAN"],   ["S","A","B","C","D"])
        tmp["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp["_SLOPE_PCT_MEAN"], ["+2","+1","0","-1","-2"])

        row = tmp[tmp["IP"] == selected_ip]
        if not row.empty and pd.notna(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]):
            ag = str(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"])
            sg = str(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
            evo_rows.append({
                "N": n,
                "ABS_GRADE": ag,
                "SLOPE_GRADE": sg,
                "ABS_NUM": ABS_NUM.get(ag, np.nan)
            })

    evo = pd.DataFrame(evo_rows)
    if evo.empty:
        st.info("íšŒì°¨ë³„ ë“±ê¸‰ ì¶”ì´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        fig_e = go.Figure()
        fig_e.add_vrect(x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5,
                        fillcolor="rgba(0,90,200,0.12)", line_width=0)

        fig_e.add_trace(go.Scatter(
            x=evo["N"], y=evo["ABS_NUM"],
            mode="lines+markers",
            line=dict(shape="spline", width=3),
            marker=dict(size=8),
            name=selected_ip,
            hoverinfo="skip"
        ))
        # ê° ì§€ì  ë¼ë²¨: ê¸°ë³¸ì€ "S+1" ë“±ê¸‰, ë‹¨ N=2ì´ê³  ì¡°íšŒìˆ˜ 1Â·2íšŒê°€ ë¹„ì–´ìˆìœ¼ë©´ '-' í‘œê¸°
        for xi, yi, ag, sg in zip(evo["N"], evo["ABS_NUM"], evo["ABS_GRADE"], evo["SLOPE_GRADE"]):
            label = f"{ag}{sg}" if isinstance(ag, str) and isinstance(sg, str) else ""
            if int(xi) == 2 and (not has_ep1 or not has_ep2):
                label = "-"  # â† ìš”êµ¬ì‚¬í•­ ë°˜ì˜
            fig_e.add_annotation(
                x=xi, y=yi, text=label,
                showarrow=False, font=dict(size=12, color="#333", family="sans-serif"),
                yshift=14
            )
        fig_e.update_xaxes(
            tickmode="array",
            tickvals=evo["N"].tolist(),
            ticktext=[f"{int(n)}íšŒì°¨" for n in evo["N"].tolist()],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_yaxes(
            tickmode="array",
            tickvals=[5,4,3,2,1],
            ticktext=["S","A","B","C","D"],
            range=[0.7, 5.3],
            showgrid=False, zeroline=False, showline=False
        )
        fig_e.update_layout(height=200, margin=dict(l=8, r=8, t=8, b=8), showlegend=False)
        st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})

    st.divider()

    # ---------- [í¬ì§€ì…”ë‹ë§µ] ----------
    st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")

    pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
    for _, r in base.iterrows():
        ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
        rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
        if ra in ROW_LABELS and rs in COL_LABELS:
            pos_map[(ra, rs)].append(r["IP"])

    # ìƒ‰ê°’(ì ìˆ˜â†‘=ì§„í•˜ê²Œ)
    z = []
    for rr in ROW_LABELS:
        row_z = []
        for cc in COL_LABELS:
            row_z.append((ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0)
        z.append(row_z)

    fig = px.imshow(
        z, x=COL_LABELS, y=ROW_LABELS, origin="upper",
        color_continuous_scale="Blues", range_color=[1, 5],
        text_auto=False, aspect="auto"
    ).update_traces(xgap=0.0, ygap=0.0)

    fig.update_xaxes(showticklabels=False, title=None, ticks="")
    fig.update_yaxes(showticklabels=False, title=None, ticks="")
    fig.update_layout(height=760, margin=dict(l=2, r=2, t=2, b=2), coloraxis_showscale=False)
    fig.update_traces(hovertemplate="<extra></extra>")

    def _font_color(val: float) -> str:
        return "#FFFFFF" if val >= 3.3 else "#111111"

    for r_idx, rr in enumerate(ROW_LABELS):
        for c_idx, cc in enumerate(COL_LABELS):
            cell_val = z[r_idx][c_idx]
            names = pos_map[(rr, cc)]
            color = _font_color(cell_val)

            fig.add_annotation(
                x=cc, y=rr, xref="x", yref="y",
                text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>",
                showarrow=False, font=dict(size=22, color=color, family="sans-serif"),
                xanchor="center", yanchor="top",
                xshift=0, yshift=80, align="left"
            )
            if names:
                fig.add_annotation(
                    x=cc, y=rr, xref="x", yref="y",
                    text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>",
                    showarrow=False, font=dict(size=12, color=color, family="sans-serif"),
                    xanchor="center", yanchor="middle",
                    yshift=6
                )

    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # ---------- [ì „ì²´í‘œ] ----------
    table = base[[
        "IP","ì¢…í•©_ì ˆëŒ€ë“±ê¸‰","ì¢…í•©_ìƒìŠ¹ë“±ê¸‰","ì¢…í•©ë“±ê¸‰",
        "ì¡°íšŒìˆ˜_ì¢…í•©","í™”ì œì„±_ì¢…í•©"
    ]].copy()

    # ì •ë ¬ í‚¤: ì¢…í•© ì ˆëŒ€ â†’ ì¢…í•© ìƒìŠ¹ â†’ IP
    table["_abs_key"]   = table["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].map(ABS_SCORE).fillna(0)
    table["_slope_key"] = table["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].map(SLO_SCORE).fillna(0)
    table = table.sort_values(["_abs_key","_slope_key","IP"], ascending=[False, False, True])

    # í™”ë©´ í‘œì‹œ ì»¬ëŸ¼(í™”ì œì„±ì€ ì ˆëŒ€ë§Œ ë…¸ì¶œ)
    table_view = table[[
        "IP","ì¢…í•©ë“±ê¸‰","ì¡°íšŒìˆ˜_ì¢…í•©","í™”ì œì„±_ì¢…í•©"
    ]].rename(columns={
        "ì¢…í•©ë“±ê¸‰":"ì¢…í•©",
        "ì¡°íšŒìˆ˜_ì¢…í•©":"ì¡°íšŒìˆ˜",
        "í™”ì œì„±_ì¢…í•©":"í™”ì œì„±",
    })

    from st_aggrid import GridOptionsBuilder, AgGrid, GridUpdateMode, JsCode
    grade_cell = JsCode("""
    function(params){
      const v = (params.value || '').toString();
      let bg='#fff', color='#111', fw='700';
      if (v.startsWith('S')) { bg='rgba(0,91,187,0.14)'; color='#003d80'; }
      else if (v.startsWith('A')) { bg='rgba(0,91,187,0.08)'; color='#004a99'; }
      else if (v.startsWith('B')) { bg='rgba(0,0,0,0.03)'; color:'#333'; fw='600'; }
      else if (v.startsWith('C')) { bg='rgba(42,97,204,0.08)'; color='#2a61cc'; }
      else if (v.startsWith('D')) { bg='rgba(42,97,204,0.14)'; color='#1a44a3'; }
      return {'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'};
    }""")

    gb = GridOptionsBuilder.from_dataframe(table_view)
    gb.configure_default_column(resizable=True, sortable=True, filter=False,
                                headerClass='centered-header bold-header',
                                cellStyle={'textAlign':'center'})
    gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
    for colname in ["ì¢…í•©","ì¡°íšŒìˆ˜","í™”ì œì„±"]:
        gb.configure_column(colname, cellStyle=grade_cell, width=120)
    grid_options = gb.build()

    st.markdown("#### ğŸ“‹ IPì „ì²´-ë””ì§€í„¸")
    AgGrid(
        table_view.fillna("â€“"),
        gridOptions=grid_options,
        theme="streamlit",
        height=420,
        fit_columns_on_grid_load=True,
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )

# =====================================================
#endregion

#region [ 15. ë©”ì¸ ë¼ìš°í„° ]
# =====================================================
if st.session_state["page"] == "Overview":
    render_overview()
elif st.session_state["page"] == "IP ì„±ê³¼":
    render_ip_detail()
elif st.session_state["page"] == "ë°ëª¨ê·¸ë˜í”½":
    render_demographic()
elif st.session_state["page"] == "ë¹„êµë¶„ì„":
    render_comparison()
elif st.session_state["page"] == "íšŒì°¨ë³„":
    render_episode()
elif st.session_state["page"] == "ì„±ì¥ìŠ¤ì½”ì–´-ë°©ì˜ì§€í‘œ":
    render_growth_score()
elif st.session_state["page"] == "ì„±ì¥ìŠ¤ì½”ì–´-ë””ì§€í„¸":
    render_growth_score_digital()
else:
    st.write("í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

#endregion


def fmt_eokman(n):
    """ì •ìˆ˜ nì„ '#ì–µ####ë§Œ' í˜•ì‹ìœ¼ë¡œ (ë§Œ ì´í•˜ ì ˆì‚­) í‘œí˜„"""
    import math

#region [ 3. ê³µí†µ ìœ í‹¸ & ìƒìˆ˜ (Refactor Kit) ]
# =====================================================
from __future__ import annotations
import re as _re, math as _math, numpy as _np, pandas as _pd
from typing import Dict as _Dict, Any as _Any, Iterable as _Iterable, Optional as _Optional
import streamlit as _st
from st_aggrid import GridOptionsBuilder as _GridOptionsBuilder, JsCode as _JsCode

ROW_LABELS = ["S","A","B","C","D"]
COL_LABELS = ["+2","+1","0","-1","-2"]
ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}

def inject_global_css() -> None:
    _

def kpi_card(title: str, value: _Optional[float|int|str], sub: _Optional[str]=None, intlike=False, digits=3):
    main = (
        f"{value:,.0f}" if (intlike and value is not None and not _pd.isna(value))
        else (f"{value:.{digits}f}" if (value is not None and not _pd.isna(value)) else "â€“")
    )
    _st.markdown(
        f"<div class='kpi-card'><div class='kpi-title'>{title}</div><div class='kpi-value'>{main}</div>"
        + (f"<div class='kpi-sub'>{sub}</div>" if sub else "") + "</div>", unsafe_allow_html=True
    )

def to_numeric_clean(s: "_pd.Series") -> "_pd.Series":
    s2 = _pd.to_numeric(s, errors="coerce")
    s2 = s2.replace(0, _np.nan)
    return s2

def episode_col(df: "_pd.DataFrame") -> str:
    return "íšŒì°¨_numeric" if "íšŒì°¨_numeric" in df.columns else ("íšŒì°¨_num" if "íšŒì°¨_num" in df.columns else "íšŒì°¨")

def get_current_page_default(default_key: str) -> str:
    try:
        qp = _st.query_params
        p = str(qp.get("page") or default_key)
        return p
    except Exception:
        return default_key

def set_page_query_param(page_key: str) -> None:
    try:
        qp = _st.query_params; qp["page"] = page_key; _st.query_params = qp
    except Exception:
        _st.experimental_set_query_params(page=page_key)

def render_sidebar_nav(NAV_ITEMS: "_Dict[str, str]", current_page: str) -> str:
    with _st.sidebar:
        _st.markdown('<div class="sidebar-hr"></div>', unsafe_allow_html=True)
        _st.markdown(
            """<div class='page-title-wrap'><span class='page-title-main'>ë“œë¼ë§ˆ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ</span></div>""",
            unsafe_allow_html=True
        )
        _st.markdown("<hr style='border:1px solid #eee; margin:0;'>", unsafe_allow_html=True)
        for key, label in NAV_ITEMS.items():
            is_active = (current_page == key)
            wrapper_cls = "nav-active" if is_active else "nav-inactive"
            _st.markdown(f'<div class="{wrapper_cls}">', unsafe_allow_html=True)
            clicked = _st.button(label, key=f"navbtn__{key}", use_container_width=True, type=("primary" if is_active else "secondary"))
            _st.markdown('</div>', unsafe_allow_html=True)
            if clicked and not is_active:
                _st.session_state["page"] = key
                set_page_query_param(key)
                if hasattr(_st, "rerun"): _st.rerun()
                else: _st.experimental_rerun()
    return current_page

FMT_FIXED3   = _JsCode("function(p){ if(p.value==null||isNaN(p.value)) return ''; return Number(p.value).toFixed(3);}")
FMT_THOUSANDS= _JsCode("function(p){ if(p.value==null||isNaN(p.value)) return ''; return Math.round(p.value).toLocaleString();}")
FMT_RANK     = _JsCode("function(p){ if(p.value==null||isNaN(p.value)) return ''; return Math.round(p.value)+'ìœ„';}")

def build_aggrid_options(df: "_pd.DataFrame", *, center=True, default_sortable=True,
                         format_map: "_Optional[dict[str, str]]"=None,
                         cell_renderer_map: "_Optional[dict[str, _JsCode]]"=None):
    gb = _GridOptionsBuilder.from_dataframe(df)
    gb.configure_grid_options(rowHeight=34, suppressMenuHide=True, domLayout='normal')
    gb.configure_default_column(
        sortable=default_sortable, resizable=True, filter=False,
        cellStyle={'textAlign': 'center' if center else 'left'},
        headerClass='centered-header bold-header' if center else 'bold-header'
    )
    fmts = {"fixed3": FMT_FIXED3, "thousands": FMT_THOUSANDS, "rank": FMT_RANK}
    format_map = format_map or {}
    cell_renderer_map = cell_renderer_map or {}
    for col, kind in format_map.items():
        if col in df.columns and kind in fmts:
            gb.configure_column(col, valueFormatter=fmts[kind])
    for col, renderer in cell_renderer_map.items():
        if col in df.columns:
            gb.configure_column(col, cellRenderer=renderer)
    return gb.build()
#endregion


    try:
        if n is None:
            return "â€“"
        n = int(float(n))
    except Exception:
        return "â€“"
    eok = n // 100_000_000
    man = (n % 100_000_000) // 10_000
    return f"{eok}ì–µ{man:04d}ë§Œ"


# === [HOVER FIX OVERRIDE â€¢ 2025-11-06 â€¢ v2] ================================
# ì¦ìƒ: í˜ì´ì§€ ì „ì²´ê°€ ë– ì˜¤ë¦„ â†’ ì›ì¸: ìƒìœ„ wrapperê¹Œì§€ :has(.hover) ì¡°ê±´ì— ê±¸ë¦¼
# í•´ê²°: "ê°€ì¥ ê°€ê¹Œìš´(wrapper)ë§Œ" lift ë˜ë„ë¡, í•˜ìœ„ wrapperê°€ ë™ì¼ ì¡°ê±´ì´ë©´ ìƒìœ„ëŠ” ì œì™¸

# =========================================================================


# === [SIDEBAR CARD STRIP â€¢ v2 â€¢ 2025-11-06] ==================================
# ì‚¬ì´ë“œë°” ë‚´ë¶€ì˜ ëª¨ë“  ì¹´ë“œ ë°•ìŠ¤(ë°°ê²½/ë³´ë”/ì„€ë„ìš°/íŒ¨ë”©) ì œê±° + hover íš¨ê³¼ ë¬´ë ¥í™”

# ============================================================================
