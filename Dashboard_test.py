# ğŸ“Š Overview / IP ì„±ê³¼ ëŒ€ì‹œë³´ë“œ â€” v2.0 


# =====================================================
#region [ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ]
import re
from typing import List, Dict, Any, Optional 
import time, uuid
import textwrap
import hashlib
import datetime
import numpy as np
import pandas as pd
import plotly.express as px
from plotly import graph_objects as go
import plotly.io as pio
import streamlit as st
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode
import gspread
from google.oauth2.service_account import Credentials
import extra_streamlit_components as stx
from plotly import graph_objects as go
#endregion


# =====================================================
#region [ 2. í˜ì´ì§€ ì„¤ì • ]
st.set_page_config(
    page_title="Drama Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)


# =====================================================
#endregion
#region [ 3. ì¸ì¦/ì¿ í‚¤ ê²Œì´íŠ¸ ]
def _rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()

# ì¿ í‚¤ ì´ë¦„ ë° ìœ íš¨ê¸°ê°„ ì„¤ì •
COOKIE_NAME = "dmb_auth_token"
COOKIE_EXPIRY_DAYS = 1

def get_cookie_manager():
    return stx.CookieManager(key="dmb_cookie_manager")

def _hash_password(password: str) -> str:
    return hashlib.sha256(str(password).encode()).hexdigest()

def check_password_with_cookie() -> bool:
    cookie_manager = get_cookie_manager()
    
    # 1. Streamlit Secrets í™•ì¸
    secret_pwd = st.secrets.get("DASHBOARD_PASSWORD")
    if not secret_pwd:
        st.error("ì„¤ì • íŒŒì¼(.streamlit/secrets.toml)ì— 'DASHBOARD_PASSWORD'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
        
    hashed_secret = _hash_password(str(secret_pwd))
    
    # 2. ì¿ í‚¤ ì½ê¸°
    cookies = cookie_manager.get_all()
    current_token = cookies.get(COOKIE_NAME)
    
    # ì¿ í‚¤ê°€ ìˆê±°ë‚˜, ë°©ê¸ˆ ë¡œê·¸ì¸ì„ ì„±ê³µí•´ì„œ ì„¸ì…˜ì— ê¸°ë¡ì´ ë‚¨ì•„ìˆë‹¤ë©´ í†µê³¼
    is_cookie_valid = (current_token == hashed_secret)
    is_session_valid = st.session_state.get("auth_success", False)
    
    if is_cookie_valid or is_session_valid:
        # ì¿ í‚¤ê°€ ìœ íš¨í•˜ë©´ ì„¸ì…˜ë„ Trueë¡œ ê°±ì‹  (ìƒˆë¡œê³ ì¹¨ ëŒ€ë¹„)
        if is_cookie_valid:
            st.session_state["auth_success"] = True
        return True

    # 4. ë¡œê·¸ì¸ UI
    with st.sidebar:
        st.markdown("## ğŸ” ë¡œê·¸ì¸")
        input_pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="__login_pwd__")
        login_btn = st.button("ë¡œê·¸ì¸")

    # 5. ë¡œê·¸ì¸ ì²˜ë¦¬
    if login_btn:
        if _hash_password(input_pwd) == hashed_secret:
            # A. ì¿ í‚¤ êµ½ê¸° (ë¸Œë¼ìš°ì € ì €ì¥ìš©)
            expires = datetime.datetime.now() + datetime.timedelta(days=COOKIE_EXPIRY_DAYS)
            cookie_manager.set(COOKIE_NAME, hashed_secret, expires_at=expires)
            
            # B. [í•µì‹¬] ì„¸ì…˜ì— 'ë¡œê·¸ì¸ ì„±ê³µ' ë„ì¥ ì°ê¸° (ì¿ í‚¤ ë”œë ˆì´ ë°©ì–´ìš©)
            st.session_state["auth_success"] = True
            
            st.success("ë¡œê·¸ì¸ ì„±ê³µ! ì ì‹œ í›„ ì´ë™í•©ë‹ˆë‹¤.")
            time.sleep(1.5) # ë”œë ˆì´ë¥¼ ì•½ê°„ ëŠ˜ë¦¼ (ì•ˆì •ì„± í™•ë³´)
            _rerun()
        else:
            st.sidebar.warning("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
    return False

if not check_password_with_cookie():
    st.stop()


# =====================================================

st.markdown("""
<style>
            
 /* -------------------------------------------------------------------
   0. [ì¶”ê°€] ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸°ë³¸ í—¤ë”(Toolbar) ìˆ¨ê¸°ê¸°
   ------------------------------------------------------------------- */
header[data-testid="stHeader"] {
    display: none !important; /* ìƒë‹¨ í—¤ë” ì˜ì—­ ì „ì²´ ìˆ¨ê¹€ */
}
div[data-testid="stDecoration"] {
    display: none !important; /* ìƒë‹¨ ì»¬ëŸ¬ ë°ì½”ë ˆì´ì…˜ ë°” ìˆ¨ê¹€ */
}
                       
/* -------------------------------------------------------------------
   1. ì•± ì „ì²´ ê¸°ë³¸ ì„¤ì •
   ------------------------------------------------------------------- */
@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');

html, body, [class*="css"] {
    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, Roboto, sans-serif !important;
}

/* í˜ì´ì§€ ë°°ê²½: í°ìƒ‰ */
[data-testid="stAppViewContainer"] {
    background-color: #f9fafb !important;
    background-image: none !important;
}

/* ìƒë‹¨ ì—¬ë°± */
.block-container {
    padding-top: 2rem;
    padding-bottom: 5rem;
    max-width: 1600px !important;
}


/* -------------------------------------------------------------------
   2. ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ 
   ------------------------------------------------------------------- */
section[data-testid="stSidebar"] {
    background-color: #ffffff !important; 
    border-right: 1px solid #e0e0e0;
    box-shadow: 4px 0 15px rgba(0, 0, 0, 0.1); /* ì˜¤ë¥¸ìª½(10px)ìœ¼ë¡œ í¼ì§€ëŠ” ì—°í•œ ê·¸ë¦¼ì */
    min-width: 280px !important;
    max-width: 280px !important;
    padding-top: 1rem;
    padding-left: 0 !important;
    padding-right: 0 !important;
}

/* ë‚´ë¶€ ì—¬ë°± ì •ë¦¬ */
section[data-testid="stSidebar"] .block-container,
section[data-testid="stSidebar"] [data-testid="stSidebarContent"] {
    padding-left: 0 !important;
    padding-right: 0 !important;
    width: 100% !important;
}

/* ë‚´ë¶€ ì¹´ë“œ íš¨ê³¼ ì œê±° */
section[data-testid="stSidebar"] div[data-testid="stVerticalBlockBorderWrapper"] {
    background: transparent !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
    transform: none !important;
}

/* [í•µì‹¬ 1] ë²„íŠ¼ ì»¨í…Œì´ë„ˆ í‹ˆ ì œê±° */
section[data-testid="stSidebar"] div[data-testid="stVerticalBlock"] {
    gap: 0rem !important;
}

section[data-testid="stSidebar"] .stButton {
    margin: 0 !important;
    padding: 0 !important;
    width: 100% !important;
}

/* [í•µì‹¬ 2] ë²„íŠ¼ ìŠ¤íƒ€ì¼: íŒ¨ë”©ì„ 8pxë¡œ í™• ì¤„ì—¬ì„œ 'ë‹¤ë‹¥ë‹¤ë‹¥' êµ¬í˜„ */
section[data-testid="stSidebar"] .stButton > button {
    width: 100%;
    box-sizing: border-box;
    text-align: left;
    
    margin: 0 !important;
    
    border-radius: 0px !important;
    border: none !important;
    border-bottom: 1px solid #e9ecef !important; /* ì—°í•œ êµ¬ë¶„ì„  */
    
    background: transparent !important;
    color: #333333 !important;
    font-weight: 600;
    
    box-shadow: none !important;
    transition: background-color 0.15s;
}

/* ë²„íŠ¼ í˜¸ë²„ */
section[data-testid="stSidebar"] .stButton > button:hover {
    background: #e5e7eb !important;
    color: #000000 !important;
}

/* ì„ íƒëœ ë²„íŠ¼ (Active): íŒŒë€ ë°°ê²½ + í°ìƒ‰ ê¸€ì”¨ */
section[data-testid="stSidebar"] [data-testid="baseButton-primary"] > button,
section[data-testid="stSidebar"] .stButton > button[kind="primary"] {
    background: #0b61ff !important;    
    color: #ffffff !important;         
    border-bottom: 1px solid #0b61ff !important;
    font-weight: 700;
}

section[data-testid="stSidebar"] button svg { display: none !important; }

/* ì‚¬ì´ë“œë°” í…ìŠ¤íŠ¸ ì—¬ë°± */
section[data-testid="stSidebar"] h1, section[data-testid="stSidebar"] h2, 
section[data-testid="stSidebar"] h3, section[data-testid="stSidebar"] .stMarkdown, 
section[data-testid="stSidebar"] .stSelectbox, section[data-testid="stSidebar"] .stMultiSelect {
    padding-left: 0px !important;
    padding-right: 0px !important;
}

/* [í•µì‹¬ 3] ì‚¬ì´ë“œë°” ì œëª©: ê½‰ ì°¨ê³  í¬ê²Œ */
.page-title-wrap { 
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 8px; 
    margin: 10px 0 20px 0; 
    padding: 0 0px;
    width: 100%;
}
.page-title-emoji { font-size: 26px; line-height: 1; }
.page-title-main {
    font-size: 24px;
    font-weight: 800; 
    letter-spacing: -0.5px;
    line-height: 1.2;
    background: linear-gradient(90deg, #6A5ACD, #FF7A8A);
    -webkit-background-clip: text; -webkit-text-fill-color: transparent;
    text-align: center;
    width: 100%;
    white-space: nowrap; /* ì¤„ë°”ê¿ˆ ë°©ì§€ */
}


/* -------------------------------------------------------------------
   3. ë©”ì¸ ì»¨í…ì¸  ì¹´ë“œ 
   ------------------------------------------------------------------- */
div[data-testid="stVerticalBlockBorderWrapper"] {
    background-color: #ffffff;
    border: 1px solid #e5e7eb;
    border-radius: 12px;
    box-shadow: 0 2px 5px rgba(0,0,0,0.03);
    
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    
    /* ë“¤ì©ì„ ë°©ì§€ */
    transition: transform 0.25s ease, box-shadow 0.25s ease;
    will-change: transform, box-shadow;
    backface-visibility: hidden; 
}

/* ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ í”Œë¡œíŒ… */
div[data-testid="stVerticalBlockBorderWrapper"]:hover {
    transform: translateY(-4px);
    box-shadow: 0 12px 24px rgba(0,0,0,0.08);
    border-color: #d1d5db;
    z-index: 5;
}

/* íˆ¬ëª… ì˜ˆì™¸ ì²˜ë¦¬ */
div[data-testid="stVerticalBlockBorderWrapper"]:has(.kpi-card),
div[data-testid="stVerticalBlockBorderWrapper"]:has(.page-title),
div[data-testid="stVerticalBlockBorderWrapper"]:has(h1),
div[data-testid="stVerticalBlockBorderWrapper"]:has(h2),
div[data-testid="stVerticalBlockBorderWrapper"]:has(h3),
div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stSelectbox"]),
div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stMultiSelect"]),
div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stSlider"]),
div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stRadio"]),
div[data-testid="stVerticalBlockBorderWrapper"]:has(.filter-group),
div[data-testid="stVerticalBlockBorderWrapper"]:has(.mode-switch) {
    background: transparent !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
    margin-bottom: 0.5rem !important;
    transform: none !important; 
}


/* -------------------------------------------------------------------
   4. ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸
   ------------------------------------------------------------------- */
h1, h2, h3 { color: #111827; font-weight: 800; letter-spacing: -0.02em; }

.page-title {
    font-size: 28px;
    font-weight: 800;
    display: inline-flex; align-items: center; gap: 10px;
    margin: 10px 0 20px 0;
}

/* KPI ì¹´ë“œ (ìì²´ í”Œë¡œíŒ…) */
.kpi-card {
    background: #ffffff;
    border: 1px solid #e5e7eb;
    border-radius: 12px;
    padding: 20px 15px;
    text-align: center;
    box-shadow: 0 2px 5px rgba(0,0,0,0.03); 
    height: 100%;
    display: flex; flex-direction: column; justify-content: center;
    
    transition: transform 0.25s ease, box-shadow 0.25s ease;
    will-change: transform, box-shadow;
}
.kpi-card:hover { 
    transform: translateY(-4px); 
    box-shadow: 0 12px 24px rgba(0,0,0,0.08);
    border-color: #d1d5db;
}

.kpi-title { font-size: 14px; font-weight: 600; color: #6b7280; margin-bottom: 8px; }
.kpi-value { font-size: 26px; font-weight: 800; color: #111827; line-height: 1.2; }
.kpi-subwrap { margin-top: 8px; font-size: 12px; color: #9ca3af; }

.ag-theme-streamlit .ag-header { 
    background-color: #f9fafb; font-weight: 700; color: #374151; 
    border-bottom: 1px solid #e5e7eb;
}

</style>
""", unsafe_allow_html=True)


# =====================================================

# ===== ë„¤ë¹„ê²Œì´ì…˜ ì•„ì´í…œ ì •ì˜ =====
NAV_ITEMS = {
    "Overview": "Overview",
    "IP ì„±ê³¼": "IP ì„±ê³¼ ìì„¸íˆë³´ê¸°",
    "ì‚¬ì „ì§€í‘œ": "ì‚¬ì „ì§€í‘œ ë¶„ì„",
    "ë¹„êµë¶„ì„": "ì„±ê³¼ ë¹„êµë¶„ì„", 
    "ì„±ì¥ìŠ¤ì½”ì–´": "ì„±ì¥ìŠ¤ì½”ì–´", 
}

# ===== ë°ëª¨ ì»¬ëŸ¼ ìˆœì„œ (í˜ì´ì§€ 2, 3ì—ì„œ ê³µí†µ ì‚¬ìš©) =====
DECADES = ["10ëŒ€","20ëŒ€","30ëŒ€","40ëŒ€","50ëŒ€","60ëŒ€"]
DEMO_COLS_ORDER = [f"{d}ë‚¨ì„±" for d in DECADES] + [f"{d}ì—¬ì„±" for d in DECADES]

# ===== Plotly ê³µí†µ í…Œë§ˆ ì„¤ì • =====
dashboard_theme = go.Layout(
    paper_bgcolor='rgba(0,0,0,0)',
    plot_bgcolor='rgba(0,0,0,0)',
    font=dict(family='sans-serif', size=12, color='#333333'),
    title=dict(font=dict(size=16, color="#111"), x=0.05),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='right',
        x=1,
        bgcolor='rgba(0,0,0,0)'
    ),
    margin=dict(l=20, r=20, t=50, b=20),
    xaxis=dict(
        showgrid=False, 
        zeroline=True, 
        zerolinecolor='#e0e0e0', 
        zerolinewidth=1
    ),
    yaxis=dict(
        showgrid=True, 
        gridcolor='#f0f0f0',
        zeroline=True, 
        zerolinecolor='#e0e0e0'
    ),
)
pio.templates['dashboard_theme'] = go.layout.Template(layout=dashboard_theme)
pio.templates.default = 'dashboard_theme'
# =====================================================


# =====================================================

# ===== 3.1. ë°ì´í„° ë¡œë“œ (MongoDB) =====
@st.cache_data(ttl=600)
#endregion
#region [ 4. ë°ì´í„° ë¡œë“œ / ì „ì²˜ë¦¬ ]
def load_data() -> pd.DataFrame:
    """
    [ìˆ˜ì •] Streamlit Secretsì™€ gspreadë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ê³µê°œ Google Sheetì—ì„œ ë°ì´í„°ë¥¼ ì¸ì¦í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤.
    st.secretsì— 'gcp_service_account', 'SHEET_ID', 'SHEET_NAME'ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    # --- 1. Google Sheets ì¸ì¦ ---
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    
    try:
        creds_info = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        client = gspread.authorize(creds)

        # --- 2. ë°ì´í„° ë¡œë“œ ---
        sheet_id = st.secrets["SHEET_ID"]
        worksheet_name = st.secrets["SHEET_NAME"] 
        
        spreadsheet = client.open_by_key(sheet_id)
        worksheet = spreadsheet.worksheet(worksheet_name)
        
        data = worksheet.get_all_records() 
        df = pd.DataFrame(data)

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"Streamlit Secretsì˜ SHEET_NAME ê°’ ('{worksheet_name}')ì— í•´ë‹¹í•˜ëŠ” ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    except KeyError as e:
        st.error(f"Streamlit Secretsì— í•„ìš”í•œ í‚¤({e})ê°€ ì—†ìŠµë‹ˆë‹¤. TOML ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

    # --- 3. ë°ì´í„° ì „ì²˜ë¦¬ (ì›ë³¸ ì½”ë“œì™€ ë™ì¼) ---
    if "ì£¼ì°¨ì‹œì‘ì¼" in df.columns:
        df["ì£¼ì°¨ì‹œì‘ì¼"] = pd.to_datetime(
            df["ì£¼ì°¨ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", 
            errors="coerce"
        )
    if "ë°©ì˜ì‹œì‘ì¼" in df.columns:
        df["ë°©ì˜ì‹œì‘ì¼"] = pd.to_datetime(
            df["ë°©ì˜ì‹œì‘ì¼"].astype(str).str.strip(),
            format="%Y. %m. %d", 
            errors="coerce"
        )

    if "value" in df.columns:
        v = df["value"].astype(str).str.replace(",", "", regex=False).str.replace("%", "", regex=False)
        df["value"] = pd.to_numeric(v, errors="coerce").fillna(0)

    for c in ["IP", "í¸ì„±", "ì§€í‘œêµ¬ë¶„", "ë§¤ì²´", "ë°ëª¨", "metric", "íšŒì°¨", "ì£¼ì°¨"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip() 

    if "íšŒì°¨" in df.columns:
        df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    else:
        df["íšŒì°¨_numeric"] = pd.NA
    return df


# ===== 3.x. ê³µí†µ í•„í„°: ë°©ì˜ ì‹œì‘ì¼ì´ 'ë¯¸ë˜'ì¸ IP ì œì™¸ (í‰ê· /ìˆœìœ„ ì‚°ì •ìš©) =====
def fmt(v, digits=3, intlike=False):
    """
    ìˆ«ì í¬ë§·íŒ… í—¬í¼ (Noneì´ë‚˜ NaNì€ 'â€“'ë¡œ í‘œì‹œ)
    """
    if v is None or pd.isna(v):
        return "â€“"
    return f"{v:,.0f}" if intlike else f"{v:.{digits}f}"

#endregion
#region [ 5. ê³µí†µ ìœ í‹¸ / ì»´í¬ë„ŒíŠ¸ / ì§‘ê³„ ]
def kpi(col, title, value):
    """
    Streamlit ì»¬ëŸ¼ ë‚´ì— KPI ì¹´ë“œë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. (CSS .kpi-card í•„ìš”)
    """
    with col:
        st.markdown(
            f'<div class="kpi-card"><div class="kpi-title">{title}</div>'
            f'<div class="kpi-value">{value}</div></div>',
            unsafe_allow_html=True
        )

def render_gradient_title(main_text: str, emoji: str = "ğŸ¬"):
    """
    ì‚¬ì´ë“œë°”ìš© ê·¸ë¼ë””ì–¸íŠ¸ íƒ€ì´í‹€ì„ ë Œë”ë§í•©ë‹ˆë‹¤. (CSS .page-title-wrap í•„ìš”)
    """
    st.markdown(
        f"""
        <div class="page-title-wrap">
          <span class="page-title-emoji">{emoji}</span>
          <span class="page-title-main">{main_text}</span>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ===== 3.3. í˜ì´ì§€ ë¼ìš°íŒ… / ë°ì´í„° í—¬í¼ í•¨ìˆ˜ =====

def get_current_page_default(default="Overview"):
    """
    URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°(?page=...)ì—ì„œ í˜„ì¬ í˜ì´ì§€ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    """
    try:
        qp = st.query_params
        p = qp.get("page", None)
        if p is None:
            return default
        return p if isinstance(p, str) else p[0]
    except Exception:
        # êµ¬ë²„ì „ í˜¸í™˜ì„±
        return default

def _set_page_query_param(page_key: str):
    """
    URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì— page í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    try:
        st.query_params["page"] = page_key
    except Exception:
        pass

def get_episode_options(df: pd.DataFrame) -> List[str]:
    """ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì°¨ ëª©ë¡ (ë¬¸ìì—´)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    valid_options = []
    if "íšŒì°¨_numeric" in df.columns:
        unique_episodes_num = sorted([
            int(ep) for ep in df["íšŒì°¨_numeric"].dropna().unique() if ep > 0
        ])
        if unique_episodes_num:
            max_ep_num = unique_episodes_num[-1]
            valid_options = [str(ep) for ep in unique_episodes_num]
            
            last_ep_str = str(max_ep_num)
            if len(valid_options) > 0 and "(ë§ˆì§€ë§‰í™”)" not in valid_options[-1]:
                 valid_options[-1] = f"{last_ep_str} (ë§ˆì§€ë§‰í™”)"
            return valid_options
    return []

# ===== 3.4. í†µí•© ë°ì´í„° í•„í„°ë§ ìœ í‹¸ =====

def _get_view_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    'ì¡°íšŒìˆ˜' metricë§Œ í•„í„°ë§í•˜ê³ , ìœ íŠœë¸Œ PGC/UGC ê·œì¹™ì„ ì ìš©í•˜ëŠ” ê³µí†µ ìœ í‹¸.
    """
    sub = df[df["metric"] == "ì¡°íšŒìˆ˜"].copy()
    if sub.empty:
        return sub
        
    if "ë§¤ì²´" in sub.columns and "ì„¸ë¶€ì†ì„±1" in sub.columns:
        yt_mask = (sub["ë§¤ì²´"] == "ìœ íŠœë¸Œ")
        attr_mask = sub["ì„¸ë¶€ì†ì„±1"].isin(["PGC", "UGC"])
        sub = sub[~yt_mask | (yt_mask & attr_mask)]
    
    return sub

# ===== 3.5. ì§‘ê³„ ê³„ì‚° ìœ í‹¸ =====

def _episode_col(df: pd.DataFrame) -> str:
    """ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” íšŒì°¨ ìˆ«ì ì»¬ëŸ¼ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return "íšŒì°¨_numeric" if "íšŒì°¨_numeric" in df.columns else ("íšŒì°¨_num" if "íšŒì°¨_num" in df.columns else "íšŒì°¨")


def _mean_of_ip_episode_agg(df: pd.DataFrame, metric_name: str, media=None, episode_agg: str = "sum") -> float | None:
    """IPë³„ (íšŒì°¨ ë‹¨ìœ„ ì§‘ê³„ -> IPë³„ í‰ê·  -> ì „ì²´ í‰ê· ) ê°’ì„ ê³„ì‚°í•œë‹¤.
    episode_agg: 'sum' or 'mean'
    """
    sub = df[(df["metric"] == metric_name)].copy()
    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]
    if sub.empty:
        return None

    ep_col = _episode_col(sub)
    sub = sub.dropna(subset=[ep_col]).copy()

    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    if episode_agg == "mean":
        ep_level = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
    else:
        ep_level = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()

    per_ip_mean = ep_level.groupby("IP")["value"].mean()
    return float(per_ip_mean.mean()) if not per_ip_mean.empty else None


def mean_of_ip_episode_sum(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    return _mean_of_ip_episode_agg(df, metric_name, media=media, episode_agg="sum")

def mean_of_ip_episode_mean(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    return _mean_of_ip_episode_agg(df, metric_name, media=media, episode_agg="mean")

def _mean_of_ip_sums_from_subset(sub: pd.DataFrame) -> float | None:
    if sub.empty:
        return None
    sub = sub.copy()
    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])
    per_ip_sum = sub.groupby("IP")["value"].sum()
    return float(per_ip_sum.mean()) if not per_ip_sum.empty else None


def mean_of_ip_sums(df: pd.DataFrame, metric_name: str, media=None) -> float | None:
    if metric_name == "ì¡°íšŒìˆ˜":
        sub = _get_view_data(df)
    else:
        sub = df[df["metric"] == metric_name].copy()

    if media is not None:
        sub = sub[sub["ë§¤ì²´"].isin(media)]

    return _mean_of_ip_sums_from_subset(sub)

current_page = get_current_page_default("Overview")
st.session_state["page"] = current_page

# ì‚¬ì´ë“œë°”ìš© ë°ì´í„° ë¡œë“œ
df_nav = load_data()

# [ìˆ˜ì •] IP ë¦¬ìŠ¤íŠ¸ ì •ë ¬: 'ë°©ì˜ì‹œì‘' ê¸°ì¤€ ìµœì‹ ìˆœ (ì»¬ëŸ¼ëª… ìˆ˜ì • ë°˜ì˜)
if not df_nav.empty and "ë°©ì˜ì‹œì‘" in df_nav.columns:
    all_ips = (
        df_nav.groupby("IP")["ë°©ì˜ì‹œì‘"]
        .max()
        .sort_values(ascending=False, na_position='last') # ìµœì‹ ìˆœ ì •ë ¬
        .index.tolist()
    )
else:
    # 'ë°©ì˜ì‹œì‘' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ì¡´ ê°€ë‚˜ë‹¤ìˆœ ìœ ì§€
    all_ips = sorted(df_nav["IP"].dropna().unique().tolist()) if not df_nav.empty else []


with st.sidebar:
    render_gradient_title("ë“œë¼ë§ˆ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", emoji="") # (í°íŠ¸ í‚¤ìš´ ë²„ì „ ì ìš©ë¨)
    
    # 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì„¤ì •)
    if "global_ip" not in st.session_state:
        st.session_state["global_ip"] = None

    if all_ips:
        # 2. í˜„ì¬ ì„ íƒëœ IPì˜ ì¸ë±ìŠ¤ ì°¾ê¸° (ì—†ê±°ë‚˜ Noneì´ë©´ idxëŠ” None)
        current_ip = st.session_state.get("global_ip")
        idx = all_ips.index(current_ip) if current_ip in all_ips else None

        selected_global_ip = st.selectbox(
            "ë¶„ì„í•  IPë¥¼ ì„ íƒí•˜ì„¸ìš”",
            all_ips,
            index=idx,                       # Noneì´ë©´ placeholderê°€ ë³´ì„
            placeholder="IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”",   # ë””í´íŠ¸ ì•ˆë‚´ ë¬¸êµ¬
            key="global_ip_select",
            label_visibility="collapsed"
        )
        st.session_state["global_ip"] = selected_global_ip
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´
    for key, label in NAV_ITEMS.items():
        is_active = (current_page == key)
        wrapper_cls = "nav-active" if is_active else "nav-inactive"
        st.markdown(f'<div class="{wrapper_cls}">', unsafe_allow_html=True)

        clicked = st.button(
            label,
            key=f"navbtn__{key}",
            use_container_width=True,
            type=("primary" if is_active else "secondary")
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        if clicked and not is_active:
            st.session_state["page"] = key
            _set_page_query_param(key)
            _rerun()
            
    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)
    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)
    st.markdown(
        "<p class='sidebar-contact' style='font-size:12px; color:gray;'>ë¬¸ì˜ : ë¯¸ë””ì–´)ë§ˆì¼€íŒ…íŒ€ ë°ì´í„°ì¸ì‚¬ì´íŠ¸íŒŒíŠ¸</p>",
        unsafe_allow_html=True
    )


# =====================================================
# NOTE: ì§‘ê³„ ìœ í‹¸ì€ ìƒë‹¨ì˜ '3.5. ì§‘ê³„ ê³„ì‚° ìœ í‹¸' ì„¹ì…˜ì— ë‹¨ì¼ ì •ì˜ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
#       (ì¤‘ë³µ ì •ì˜ ë°©ì§€: ê²°ê³¼ê°’/ë™ì‘ ë™ì¼ ìœ ì§€)



# =====================================================

# ===== 6.1. ë°ëª¨ ë¬¸ìì—´ íŒŒì‹± ìœ í‹¸ =====
def _gender_from_demo(s: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„(ë‚¨/ì—¬/ê¸°íƒ€)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]): return "ë‚¨"
    return "ê¸°íƒ€"

def gender_from_demo(s: str):
    """ 'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì„±ë³„ (ë‚¨/ì—¬) ì¶”ì¶œ, ê·¸ ì™¸ None (í˜ì´ì§€ 3ìš©) """
    s = str(s)
    if any(k in s for k in ["ì—¬", "F", "female", "Female"]): return "ì—¬"
    if any(k in s for k in ["ë‚¨", "M", "male", "Male"]):     return "ë‚¨"
    return None

def _to_decade_label(x: str):
    """'ë°ëª¨' ë¬¸ìì—´ì—ì„œ ì—°ë ¹ëŒ€(10ëŒ€, 20ëŒ€...)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(x))
    if not m: return "ê¸°íƒ€"
    n = int(m.group(0))
    return f"{(n//10)*10}ëŒ€"

def _decade_label_clamped(x: str):
    """ 10ëŒ€~60ëŒ€ ë²”ìœ„ë¡œ ì—°ë ¹ëŒ€ ë¼ë²¨ ìƒì„±, ê·¸ ì™¸ëŠ” None (í˜ì´ì§€ 2, 3ìš©) """
    m = re.search(r"\d+", str(x))
    if not m: return None
    n = int(m.group(0))
    n = max(10, min(60, (n // 10) * 10))
    return f"{n}ëŒ€"

def _decade_key(s: str):
    """ì—°ë ¹ëŒ€ ì •ë ¬ì„ ìœ„í•œ ìˆ«ì í‚¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (í˜ì´ì§€ 1, 2, 4ìš©)"""
    m = re.search(r"\d+", str(s))
    return int(m.group(0)) if m else 999

def _fmt_ep(n):
    """ íšŒì°¨ ë²ˆí˜¸ë¥¼ '01í™”' í˜•íƒœë¡œ í¬ë§·íŒ… (í˜ì´ì§€ 2, 3ìš©) """
    try:
        return f"{int(n):02d}í™”"
    except Exception:
        return str(n)

# ===== 6.2. í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ë Œë”ë§ (í˜ì´ì§€ 1, 2) =====
COLOR_MALE = "#2a61cc"
COLOR_FEMALE = "#d93636"

def render_gender_pyramid(container, title: str, df_src: pd.DataFrame, height: int = 260):

    if df_src.empty:
        container.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_demo = df_src.copy()
    df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
    df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
    df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & df_demo["ì—°ë ¹ëŒ€_ëŒ€"].notna()]

    if df_demo.empty:
        container.info("í‘œì‹œí•  ë°ëª¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    order = sorted(df_demo["ì—°ë ¹ëŒ€_ëŒ€"].unique().tolist(), key=_decade_key)

    pvt = (
        df_demo.groupby(["ì—°ë ¹ëŒ€_ëŒ€","ì„±ë³„"])["value"]
               .sum()
               .unstack("ì„±ë³„")
               .reindex(order)
               .fillna(0)
    )

    male = -pvt.get("ë‚¨", pd.Series(0, index=pvt.index))
    female = pvt.get("ì—¬", pd.Series(0, index=pvt.index))

    max_abs = float(max(male.abs().max(), female.max()) or 1)

    male_share = (male.abs() / male.abs().sum() * 100) if male.abs().sum() else male.abs()
    female_share = (female / female.sum() * 100) if female.sum() else female

    male_text = [f"{v:.1f}%" for v in male_share]
    female_text = [f"{v:.1f}%" for v in female_share]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=pvt.index, x=male, name="ë‚¨",
        orientation="h",
        marker_color=COLOR_MALE,
        text=male_text,
        textposition="inside",
        insidetextanchor="end",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ë‚¨ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([male.abs(), male_share])
    ))
    fig.add_trace(go.Bar(
        y=pvt.index, x=female, name="ì—¬",
        orientation="h",
        marker_color=COLOR_FEMALE,
        text=female_text,
        textposition="inside",
        insidetextanchor="start",
        textfont=dict(color="#ffffff", size=12),
        hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ì—¬ì„±=%{customdata[0]:,.0f}ëª…<br>ì„±ë³„ë‚´ ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
        customdata=np.column_stack([female, female_share])
    ))

    fig.update_layout(
        barmode="overlay",
        height=height,
        margin=dict(l=8, r=8, t=48, b=8),
        legend_title=None,
        bargap=0.15,
        bargroupgap=0.05,
    )
    # í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ì „ìš© ë¡œì»¬ ì œëª© (ì „ì—­ í…Œë§ˆ ì˜¤ë²„ë¼ì´ë“œ)
    fig.update_layout(
        title=dict(
            text=title,
            x=0.0, xanchor="left",
            y=0.98, yanchor="top",
            font=dict(size=14)
        )
    )
    fig.update_yaxes(
        categoryorder="array",
        categoryarray=order,
        title=None,
        tickfont=dict(size=12),
        fixedrange=True
    )
    fig.update_xaxes(
        range=[-max_abs*1.05, max_abs*1.05],
        title=None,
        showticklabels=False,
        showgrid=False,
        zeroline=True,
        zerolinewidth=1,
        zerolinecolor="#888",
        fixedrange=True
    )

    container.plotly_chart(fig, use_container_width=True,
                           config={"scrollZoom": False, "staticPlot": False, "displayModeBar": False})

# ===== 6.3. ê·¸ë£¹ ë°ëª¨ í‰ê·  ê³„ì‚° (í˜ì´ì§€ 3, 4 í†µí•©ìš©) =====
def get_avg_demo_pop_by_episode(df_src: pd.DataFrame, medias: List[str], max_ep: float = None) -> pd.DataFrame:
    """
    ì—¬ëŸ¬ IPê°€ í¬í•¨ëœ df_srcì—ì„œ, íšŒì°¨ë³„/ë°ëª¨ë³„ *í‰ê· * ì‹œì²­ììˆ˜(ì‹œì²­ì¸êµ¬)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    # 1. ë§¤ì²´ ë° ì§€í‘œ í•„í„°ë§
    sub = df_src[
        (df_src["metric"] == "ì‹œì²­ì¸êµ¬") &
        (df_src["ë°ëª¨"].notna()) &
        (df_src["ë§¤ì²´"].isin(medias))
    ].copy()

    if sub.empty:
        return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)
    
    # 2. íšŒì°¨ Numeric ì»¬ëŸ¼ í™•ë³´ ë° í•„í„°ë§
    if "íšŒì°¨_numeric" not in sub.columns:
        sub["íšŒì°¨_numeric"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    
    sub = sub.dropna(subset=["íšŒì°¨_numeric"])
    
    # [í•µì‹¬] max_epê°€ ìˆìœ¼ë©´ ê·¸ ì´í•˜ íšŒì°¨ë§Œ ë‚¨ê¹€
    if max_ep is not None:
        sub = sub[sub["íšŒì°¨_numeric"] <= max_ep]

    if sub.empty:
        return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

    sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
    sub = sub.dropna(subset=["value"])

    sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(gender_from_demo)
    sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)
    sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()
    sub["íšŒì°¨_num"] = sub["íšŒì°¨_numeric"].astype(int)

    sub["ë¼ë²¨"] = sub.apply(lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)

    ip_ep_demo_sum = sub.groupby(["IP", "íšŒì°¨_num", "ë¼ë²¨"])["value"].sum().reset_index()
    ep_demo_mean = ip_ep_demo_sum.groupby(["íšŒì°¨_num", "ë¼ë²¨"])["value"].mean().reset_index()

    pvt = ep_demo_mean.pivot_table(index="íšŒì°¨_num", columns="ë¼ë²¨", values="value").fillna(0)

    for c in DEMO_COLS_ORDER:
        if c not in pvt.columns:
            pvt[c] = 0
    pvt = pvt[DEMO_COLS_ORDER].sort_index()

    pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))
    return pvt.reset_index(drop=True)

# ===== 6.4. [ì´ë™] íˆíŠ¸ë§µ ë Œë”ë§ (êµ¬ Region 9ì—ì„œ ì´ë™) =====
def render_heatmap(df_plot: pd.DataFrame, title: str):
    """
    ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ Plotly íˆíŠ¸ë§µì„ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    st.markdown(f"###### {title}")

    if df_plot.empty:
        st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_heatmap = df_plot.set_index("íšŒì°¨")
    
    cols_to_drop = [c for c in df_heatmap.columns if c.endswith(('_base', '_comp'))]
    df_heatmap = df_heatmap.drop(columns=cols_to_drop)
    
    valid_values = df_heatmap.replace(999, np.nan).values
    if pd.isna(valid_values).all():
         v_min, v_max = -10.0, 10.0
    else:
         v_min = np.nanmin(valid_values)
         v_max = np.nanmax(valid_values)
         if pd.isna(v_min): v_min = 0.0
         if pd.isna(v_max): v_max = 0.0
    
    abs_max = max(abs(v_min), abs(v_max), 10.0)
    
    fig = px.imshow(
        df_heatmap,
        text_auto=False, 
        aspect="auto",
        color_continuous_scale='RdBu_r', 
        range_color=[-abs_max, abs_max], 
        color_continuous_midpoint=0
    )

    text_template_df = df_heatmap.applymap(
        lambda x: "INF" if x == 999 else (f"{x:+.0f}%" if pd.notna(x) else "")
    )

    fig.update_traces(
        text=text_template_df.values,
        texttemplate="%{text}",
        hovertemplate="íšŒì°¨: %{y}<br>ë°ëª¨: %{x}<br>ì¦ê°: %{text}<extra></extra>",
        textfont=dict(size=10, color="black")
    )

    fig.update_layout(
        height=max(520, len(df_heatmap.index) * 46), 
        xaxis_title=None,
        yaxis_title=None,
        xaxis=dict(side="top"),
    )
    
    c_heatmap, = st.columns(1)
    with c_heatmap:
        st.plotly_chart(fig, use_container_width=True)

# =====================================================
# [ì¶”ê°€] ë™ì¼ í¸ì„± ì „ì‘ ì°¾ê¸° ìœ í‹¸
def get_previous_work_ip(df_full: pd.DataFrame, target_ip: str) -> str | None:
    """
    ë™ì¼ í¸ì„± ë‚´ì—ì„œ, íƒ€ê²Ÿ IPë³´ë‹¤ 'ë°©ì˜ì‹œì‘ì¼'ì´ ë°”ë¡œ ì•ì„  ì‘í’ˆì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    if df_full.empty or "ë°©ì˜ì‹œì‘" not in df_full.columns: # ì»¬ëŸ¼ëª… "ë°©ì˜ì‹œì‘" ì²´í¬
        return None
    
    # íƒ€ê²Ÿ IP ì •ë³´
    target_rows = df_full[df_full["IP"] == target_ip]
    if target_rows.empty: return None
    
    # íƒ€ê²Ÿì˜ í¸ì„± ë° ë°©ì˜ì‹œì‘ì¼
    target_prog = target_rows["í¸ì„±"].dropna().iloc[0] if not target_rows["í¸ì„±"].dropna().empty else None
    target_start = target_rows["ë°©ì˜ì‹œì‘"].dropna().iloc[0] if not target_rows["ë°©ì˜ì‹œì‘"].dropna().empty else None
    
    if not target_prog or pd.isna(target_start): return None
    
    # ë™ì¼ í¸ì„± && ë°©ì˜ì¼ì´ íƒ€ê²Ÿë³´ë‹¤ ì´ì „ì¸ ì‘í’ˆë“¤
    candidates = df_full[
        (df_full["í¸ì„±"] == target_prog) & 
        (df_full["ë°©ì˜ì‹œì‘"] < target_start) & 
        (df_full["IP"] != target_ip)
    ].copy()
    
    if candidates.empty: return None
    
    # ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ìµœì‹ (ë°©ì˜ì‹œì‘ì¼ì´ ê°€ì¥ í°) ì‘í’ˆ
    prev_work = candidates.sort_values("ë°©ì˜ì‹œì‘", ascending=False).iloc[0]["IP"]
    return prev_work

# =====================================================
#endregion
#region [ 6. í˜ì´ì§€ ë Œë”ëŸ¬ ]
def render_overview():
    df = load_data() 
  
    # --- í˜ì´ì§€ ì „ìš© í•„í„° ---   
    filter_cols = st.columns(4)
    
    with filter_cols[0]:
        st.markdown("### ğŸ“Š Overview")
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ & íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE UV** `íšŒì°¨í‰ê· `: ì‹¤ì‹œê°„ ì‹œì²­ UV
        - **í‹°ë¹™ ë‹¹ì¼ VOD UV** `íšŒì°¨í‰ê· `: ë³¸ë°©ì†¡ ë‹¹ì¼ VOD UV
        - **í‹°ë¹™ ì£¼ê°„ VOD UV** `íšŒì°¨í‰ê· `: [íšŒì°¨ ë°©ì˜ì¼ë¶€í„° +6ì¼ê¹Œì§€ì˜ 7ì¼ê°„ VOD UV] - [í‹°ë¹™ ë‹¹ì¼ VOD]
        - **ë””ì§€í„¸ ì¡°íšŒ** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ê°„ ì›”~ì¼ ë°œìƒ ì´í•© / ìœ íŠœë¸Œ,ì¸ìŠ¤íƒ€ê·¸ë¨,í‹±í†¡,ë„¤ì´ë²„TV,í˜ì´ìŠ¤ë¶
        - **ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•© / ì»¤ë®¤ë‹ˆí‹°,íŠ¸ìœ„í„°,ë¸”ë¡œê·¸                            
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ì˜ í‰ê·  (í€ë±ìŠ¤)
        - **ì•µì»¤ë“œë¼ë§ˆ ê¸°ì¤€**: í† ì¼ 3%â†‘, ì›”í™” 2%â†‘
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)


    with filter_cols[1]:
        prog_sel = st.multiselect(
            "í¸ì„±", 
            sorted(df["í¸ì„±"].dropna().unique().tolist()),
            placeholder="í¸ì„± ì„ íƒ",
            label_visibility="collapsed"
        )

    # ì—°ë„ í•„í„°: 'í¸ì„±ì—°ë„' ì»¬ëŸ¼ ì‚¬ìš©
    all_years = []
    if "í¸ì„±ì—°ë„" in df.columns:
        unique_vals = df["í¸ì„±ì—°ë„"].dropna().unique()
        try:
            all_years = sorted(unique_vals, reverse=True)
        except:
            all_years = sorted([str(x) for x in unique_vals], reverse=True)

    # ì›” í•„í„°
    if "ë°©ì˜ì‹œì‘ì¼" in df.columns and df["ë°©ì˜ì‹œì‘ì¼"].notna().any():
        date_col_for_month = "ë°©ì˜ì‹œì‘ì¼"
    else:
        date_col_for_month = "ì£¼ì°¨ì‹œì‘ì¼"
    
    all_months = []
    if date_col_for_month in df.columns:
        date_series = df[date_col_for_month].dropna()
        if not date_series.empty:
            all_months = sorted(date_series.dt.month.unique().tolist())

    with filter_cols[2]:
        year_sel = st.multiselect(
            "ì—°ë„", 
            all_years, 
            placeholder="ì—°ë„ ì„ íƒ",
            label_visibility="collapsed"
        )
    with filter_cols[3]:
        month_sel = st.multiselect(
            "ì›”", 
            all_months, 
            placeholder="ì›” ì„ íƒ",
            label_visibility="collapsed"
        )

    # --- í•„í„° ì ìš© ---
    f = df.copy()
    if prog_sel:
        f = f[f["í¸ì„±"].isin(prog_sel)]
    
    if year_sel and "í¸ì„±ì—°ë„" in f.columns:
        f = f[f["í¸ì„±ì—°ë„"].isin(year_sel)]
        
    if month_sel and date_col_for_month in f.columns:
        f = f[f[date_col_for_month].dt.month.isin(month_sel)]

    # --- ìš”ì•½ì¹´ë“œ ê³„ì‚° ì„œë¸Œí•¨ìˆ˜ (KPI ê³µí†µ ìœ í‹¸ ì‚¬ìš©) ---
    def avg_of_ip_means(metric_name: str):
        return mean_of_ip_episode_mean(f, metric_name) # [5. ê³µí†µ í•¨ìˆ˜]

    def avg_of_ip_tving_epSum_mean(media_name: str):
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", [media_name]) # [5. ê³µí†µ í•¨ìˆ˜]

    def avg_of_ip_tving_quick():
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])

    def avg_of_ip_tving_vod_weekly():
        return mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])

    def avg_of_ip_sums(metric_name: str):
        return mean_of_ip_sums(f, metric_name) # [5. ê³µí†µ í•¨ìˆ˜]

    def count_ip_with_min1(metric_name: str):
        sub = f[f["metric"] == metric_name]
        if sub.empty: return 0
        ip_min = sub.groupby("IP")["value"].min()
        return (ip_min == 1).sum()

    def count_anchor_dramas():
        sub = f[f["metric"]=="Tì‹œì²­ë¥ "].groupby(["IP","í¸ì„±"])["value"].mean().reset_index()
        mon_tue = sub[(sub["í¸ì„±"]=="ì›”í™”") & (sub["value"]>2)].shape[0]
        sat_sun = sub[(sub["í¸ì„±"]=="í† ì¼") & (sub["value"]>3)].shape[0]
        return mon_tue + sat_sun

    # --- ìš”ì•½ ì¹´ë“œ ---
    st.caption('â–¶ IPë³„ í‰ê· ')

    c1, c2, c3, c4, c5 = st.columns(5)
    st.markdown("<div style='margin-top:20px'></div>", unsafe_allow_html=True)
    c6, c7, c8, c9, c10 = st.columns(5)

    t_rating   = avg_of_ip_means("Tì‹œì²­ë¥ ")
    h_rating   = avg_of_ip_means("Hì‹œì²­ë¥ ")
    tving_live = avg_of_ip_tving_epSum_mean("TVING LIVE")
    tving_quick= avg_of_ip_tving_quick()        
    tving_vod  = avg_of_ip_tving_vod_weekly()   

    digital_view = avg_of_ip_sums("ì¡°íšŒìˆ˜")
    digital_buzz = avg_of_ip_sums("ì–¸ê¸‰ëŸ‰")
    f_score      = avg_of_ip_means("F_Score")
    fundex_top1 = count_ip_with_min1("F_Total")
    anchor_total = count_anchor_dramas()

    kpi(c1, "ğŸ¯ íƒ€ê¹ƒ ì‹œì²­ë¥ ", fmt(t_rating, digits=3))
    kpi(c2, "ğŸ  ê°€êµ¬ ì‹œì²­ë¥ ", fmt(h_rating, digits=3))
    kpi(c3, "ğŸ“º í‹°ë¹™ LIVE UV", fmt(tving_live, intlike=True))
    kpi(c4, "âš¡ í‹°ë¹™ ë‹¹ì¼ VOD UV", fmt(tving_quick, intlike=True)) 
    kpi(c5, "â–¶ï¸ í‹°ë¹™ ì£¼ê°„ VOD UV", fmt(tving_vod, intlike=True))   
    
    kpi(c6, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", fmt(digital_view, intlike=True))
    kpi(c7, "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", fmt(digital_buzz, intlike=True))
    kpi(c8, "ğŸ”¥ í™”ì œì„± ì ìˆ˜",  fmt(f_score, intlike=True))
    kpi(c9, "ğŸ¥‡ í€ë±ìŠ¤ 1ìœ„", f"{fundex_top1}ì‘í’ˆ")
    kpi(c10, "âš“ ì•µì»¤ë“œë¼ë§ˆ", f"{anchor_total}ì‘í’ˆ")

    st.divider()

    # --- ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ (Stacked Bar) ---
    df_trend = f[f["metric"]=="ì‹œì²­ì¸êµ¬"].copy()
    if not df_trend.empty:
        tv_weekly = df_trend[df_trend["ë§¤ì²´"]=="TV"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
        
        tving_live_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING LIVE"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()
        tving_quick_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING QUICK"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum() 
        tving_vod_weekly = df_trend[df_trend["ë§¤ì²´"]=="TVING VOD"].groupby("ì£¼ì°¨ì‹œì‘ì¼")["value"].sum()     

        all_dates = sorted(list(
            set(tv_weekly.index) | set(tving_live_weekly.index) | 
            set(tving_quick_weekly.index) | set(tving_vod_weekly.index)
        ))
        
        if all_dates:
            df_bar = pd.DataFrame({"ì£¼ì°¨ì‹œì‘ì¼": all_dates})
            df_bar["TV ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tv_weekly).fillna(0)
            df_bar["í‹°ë¹™ ë³¸ë°©"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_live_weekly).fillna(0)
            df_bar["í‹°ë¹™ ë‹¹ì¼"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_quick_weekly).fillna(0) 
            df_bar["í‹°ë¹™ ì£¼ê°„"] = df_bar["ì£¼ì°¨ì‹œì‘ì¼"].map(tving_vod_weekly).fillna(0)   

            df_long = df_bar.melt(id_vars="ì£¼ì°¨ì‹œì‘ì¼",
                                  value_vars=["TV ë³¸ë°©","í‹°ë¹™ ë³¸ë°©","í‹°ë¹™ ë‹¹ì¼","í‹°ë¹™ ì£¼ê°„"],
                                  var_name="êµ¬ë¶„", value_name="ì‹œì²­ììˆ˜")

            def fmt_kor_hover(x):
                if pd.isna(x) or x == 0: return "0"
                val = int(round(x / 10000))
                uk = val // 10000
                man = val % 10000
                if uk > 0: return f"{uk}ì–µ{man:04d}ë§Œ"
                else: return f"{man}ë§Œ"

            df_long["hover_txt"] = df_long["ì‹œì²­ììˆ˜"].apply(fmt_kor_hover)

            fig = px.bar(
                df_long, x="ì£¼ì°¨ì‹œì‘ì¼", y="ì‹œì²­ììˆ˜", color="êµ¬ë¶„",
                title="ğŸ“Š ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜",
                color_discrete_map={
                    "TV ë³¸ë°©": "#2c3e50",     
                    "í‹°ë¹™ ë³¸ë°©": "#d32f2f",   
                    "í‹°ë¹™ ë‹¹ì¼": "#ff5252",   
                    "í‹°ë¹™ ì£¼ê°„": "#ffcdd2"    
                },
                custom_data=["hover_txt"]
            )
            
            fig.update_layout(
                xaxis_title=None, yaxis_title=None,
                barmode="stack", legend_title="êµ¬ë¶„",
                title_font=dict(size=20),
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),
                margin=dict(t=60) 
            )
            
            fig.update_traces(
                textposition='none', 
                hovertemplate="<b>%{x}</b><br>%{data.name}: %{customdata[0]}<extra></extra>"
            )
            
            c_trend, = st.columns(1)
            with c_trend:
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì£¼ì°¨ë³„ ì‹œì²­ììˆ˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


    st.divider()

    # --- ì£¼ìš”ì‘í’ˆ í…Œì´ë¸” (AgGrid) ---
    st.markdown("#### ğŸ¬ ì „ì²´ ì‘í’ˆ RAW")

    def calculate_overview_performance(df):
        all_ips = df["IP"].unique()
        if len(all_ips) == 0: return pd.DataFrame()

        ep_col = _episode_col(df) # [5. ê³µí†µ í•¨ìˆ˜]
        
        def _get_mean_of_ep_sums(df, metric_name, media_list=None):
            sub = df[df["metric"] == metric_name]
            if media_list: sub = sub[sub["ë§¤ì²´"].isin(media_list)]
            if sub.empty or ep_col not in sub.columns: 
                return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            sub = sub.dropna(subset=[ep_col]).copy()
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value"])
            if sub.empty: return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
            per_ip_mean = ep_sum.groupby("IP")["value"].mean()
            return per_ip_mean.reindex(all_ips).fillna(0) 

        def _get_mean_of_ep_means(df, metric_name):
            sub = df[df["metric"] == metric_name]
            if sub.empty or ep_col not in sub.columns:
                return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            sub = sub.dropna(subset=[ep_col]).copy()
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value"])
            if sub.empty: return pd.Series(dtype=float).reindex(all_ips).fillna(0)
            ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
            per_ip_mean = ep_mean.groupby("IP")["value"].mean()
            return per_ip_mean.reindex(all_ips).fillna(0)
        
        aggs = {}
        aggs["íƒ€ê¹ƒì‹œì²­ë¥ "] = _get_mean_of_ep_means(df, "Tì‹œì²­ë¥ ")
        aggs["ê°€êµ¬ì‹œì²­ë¥ "] = _get_mean_of_ep_means(df, "Hì‹œì²­ë¥ ")
        aggs["í‹°ë¹™LIVE"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
        aggs["í‹°ë¹™ë‹¹ì¼"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
        aggs["í‹°ë¹™ì£¼ê°„"] = _get_mean_of_ep_sums(df, "ì‹œì²­ì¸êµ¬", ["TVING VOD"]) 
        aggs["ë””ì§€í„¸ì–¸ê¸‰ëŸ‰"] = df[df["metric"] == "ì–¸ê¸‰ëŸ‰"].groupby("IP")["value"].sum().reindex(all_ips).fillna(0)
        aggs["ë””ì§€í„¸ì¡°íšŒìˆ˜"] = _get_view_data(df).groupby("IP")["value"].sum().reindex(all_ips).fillna(0)
        aggs["í™”ì œì„±ìˆœìœ„"] = df[df["metric"] == "F_Total"].groupby("IP")["value"].min().reindex(all_ips).fillna(0)
        aggs["í™”ì œì„±ì ìˆ˜"] = _get_mean_of_ep_sums(df, "F_Score", media_list=None)

        df_perf = pd.DataFrame(aggs).fillna(0).reset_index().rename(columns={"index": "IP"})
        return df_perf.sort_values("íƒ€ê¹ƒì‹œì²­ë¥ ", ascending=False)

    df_perf = calculate_overview_performance(f)

    # í¬ë§·í„° ì •ì˜
    fmt_fixed3 = JsCode("""function(params){ if(params.value==null||isNaN(params.value))return ''; return Number(params.value).toFixed(3); }""")
    fmt_thousands = JsCode("""function(params){ if(params.value==null||isNaN(params.value))return ''; return Math.round(params.value).toLocaleString(); }""")
    fmt_rank = JsCode("""function(params){ if(params.value==null||isNaN(params.value))return ''; if(params.value==0) return 'â€“'; return Math.round(params.value)+'ìœ„'; }""")

    # [ì‹ ê·œ] ì„ íƒëœ IP í–‰ í•˜ì´ë¼ì´íŠ¸ ìŠ¤íƒ€ì¼
    target_ip = st.session_state.get("global_ip", "")
    
    highlight_jscode = JsCode(f"""
    function(params) {{
        if (params.data.IP === '{target_ip}') {{
            return {{
                'background-color': '#fffde7',  /* ì—°í•œ ë…¸ë€ìƒ‰ */
                'font-weight': 'bold',
                'border-left': '5px solid #d93636' /* ë¹¨ê°„ ê°•ì¡°ì„  */
            }};
        }}
        return {{}};
    }}
    """)

    gb = GridOptionsBuilder.from_dataframe(df_perf)
    gb.configure_default_column(
        sortable=True, resizable=True, filter=False,
        cellStyle={'textAlign': 'center'},
        headerClass='centered-header'
    )
    
    # [í•µì‹¬] getRowStyle ì ìš©
    gb.configure_grid_options(
        rowHeight=34, 
        suppressMenuHide=True, 
        domLayout='normal',
        getRowStyle=highlight_jscode 
    )
    
    gb.configure_column('IP', header_name='IP', cellStyle={'textAlign':'left'}) 
    gb.configure_column('íƒ€ê¹ƒì‹œì²­ë¥ ', valueFormatter=fmt_fixed3, sort='desc')
    gb.configure_column('ê°€êµ¬ì‹œì²­ë¥ ', valueFormatter=fmt_fixed3)
    gb.configure_column('í‹°ë¹™LIVE', valueFormatter=fmt_thousands)
    gb.configure_column('í‹°ë¹™ë‹¹ì¼', header_name="í‹°ë¹™ ë‹¹ì¼ VOD", valueFormatter=fmt_thousands)
    gb.configure_column('í‹°ë¹™ì£¼ê°„', header_name="í‹°ë¹™ ì£¼ê°„ VOD", valueFormatter=fmt_thousands)
    gb.configure_column('ë””ì§€í„¸ì¡°íšŒìˆ˜', valueFormatter=fmt_thousands)
    gb.configure_column('ë””ì§€í„¸ì–¸ê¸‰ëŸ‰', valueFormatter=fmt_thousands)
    gb.configure_column('í™”ì œì„±ìˆœìœ„', valueFormatter=fmt_rank)
    gb.configure_column('í™”ì œì„±ì ìˆ˜', valueFormatter=fmt_thousands)

    grid_options = gb.build()

    AgGrid(
        df_perf,
        gridOptions=grid_options,
        theme="streamlit",
        height=300,
        fit_columns_on_grid_load=True, 
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )


# =====================================================
def render_ip_detail():
    
    df_full = load_data() # [3. ê³µí†µ í•¨ìˆ˜]

    ip_selected = st.session_state.get("global_ip")
    if not ip_selected or ip_selected not in df_full["IP"].values:
        st.error("ì„ íƒëœ IP ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    filter_cols = st.columns([5, 2, 2])

    with filter_cols[0]:
        st.markdown(f"<div class='page-title'>ğŸ“ˆ {ip_selected} ì„±ê³¼ ìƒì„¸</div>", unsafe_allow_html=True)
    
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `ëˆ„ì  íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ & íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE UV** `ëˆ„ì  íšŒì°¨í‰ê· `: ì‹¤ì‹œê°„ ì‹œì²­ UV
        - **í‹°ë¹™ ë‹¹ì¼ VOD UV** `ëˆ„ì  íšŒì°¨í‰ê· `: ë³¸ë°©ì†¡ ë‹¹ì¼ VOD UV
        - **í‹°ë¹™ ì£¼ê°„ VOD UV** `ëˆ„ì  íšŒì°¨í‰ê· `: [íšŒì°¨ ë°©ì˜ì¼ë¶€í„° +6ì¼ê¹Œì§€ì˜ 7ì¼ê°„ VOD UV] - [í‹°ë¹™ ë‹¹ì¼ VOD]
        - **ë””ì§€í„¸ ì¡°íšŒ** `ëˆ„ì  íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ê°„ ì›”~ì¼ ë°œìƒ ì´í•© / ìœ íŠœë¸Œ,ì¸ìŠ¤íƒ€ê·¸ë¨,í‹±í†¡,ë„¤ì´ë²„TV,í˜ì´ìŠ¤ë¶
        - **ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰** `ëˆ„ì  íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•© / ì»¤ë®¤ë‹ˆí‹°,íŠ¸ìœ„í„°,ë¸”ë¡œê·¸                            
        - **í™”ì œì„± ì ìˆ˜** `ëˆ„ì  íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ì˜ í‰ê·  (í€ë±ìŠ¤)
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)

    # --- ë°ì´í„° ì „ì²˜ë¦¬ (Default ì„¤ì •ì„ ìœ„í•´ ìœ„ì¹˜ ì´ë™) ---
    date_col_for_filter = "í¸ì„±ì—°ë„"

    target_ip_rows = df_full[df_full["IP"] == ip_selected]
    
    # Default ì—°ë„/í¸ì„± ì¶”ì¶œ
    default_year_list = []
    sel_prog = None
    
    if not target_ip_rows.empty:
        try:
            if date_col_for_filter in target_ip_rows.columns:
                y_mode = target_ip_rows[date_col_for_filter].dropna().mode()
                if not y_mode.empty:
                    default_year_list = [y_mode.iloc[0]]
            
            sel_prog = target_ip_rows["í¸ì„±"].dropna().mode().iloc[0]
        except Exception:
            pass
            
    all_years = []
    if date_col_for_filter in df_full.columns:
        unique_vals = df_full[date_col_for_filter].dropna().unique()
        try:
            all_years = sorted(unique_vals, reverse=True)
        except:
            all_years = sorted([str(x) for x in unique_vals], reverse=True)

    # [Col 1] ë°©ì˜ ì—°ë„
    with filter_cols[1]:
        selected_years = st.multiselect(
            "ë°©ì˜ ì—°ë„",
            all_years,
            default=default_year_list,
            placeholder="ë°©ì˜ ì—°ë„ ì„ íƒ",
            label_visibility="collapsed"
        )

    # [Col 2] ë™ì¼ í¸ì„± ì—¬ë¶€ (ì…€ë ‰íŠ¸ë°•ìŠ¤)
    with filter_cols[2]:
        comp_options = ["ë™ì¼ í¸ì„±", "ì „ì²´", "ì›”í™”", "ìˆ˜ëª©", "í† ì¼", "í‰ì¼"]
        default_comp = "í‰ì¼" if (sel_prog == "ìˆ˜ëª©") else "ë™ì¼ í¸ì„±"
        comp_type = st.selectbox(
            "í¸ì„± ê¸°ì¤€",
            comp_options,
            index=comp_options.index(default_comp),
            label_visibility="collapsed"
        )

        use_same_prog = (comp_type == "ë™ì¼ í¸ì„±")

        # ë¹„êµ ê·¸ë£¹ í¸ì„± í•„í„°(ì—†ìœ¼ë©´ ì „ì²´)
        comp_prog_filter = None
        if comp_type == "í‰ì¼":
            comp_prog_filter = ["ì›”í™”", "ìˆ˜ëª©"]
        elif comp_type in ["ì›”í™”", "ìˆ˜ëª©", "í† ì¼"]:
            comp_prog_filter = [comp_type]
        elif use_same_prog:
            comp_prog_filter = [sel_prog] if sel_prog else None
# --- ì„ íƒ IP ë°ì´í„° í•„í„°ë§ ---
    f = target_ip_rows.copy()

    if "íšŒì°¨_numeric" in f.columns:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨_numeric"], errors="coerce")
    else:
        f["íšŒì°¨_num"] = pd.to_numeric(f["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")
    
    my_max_ep = f["íšŒì°¨_num"].max()

    def _week_to_num(x: str):
        m = re.search(r"-?\d+", str(x))
        return int(m.group(0)) if m else None

    has_week_col = "ì£¼ì°¨" in f.columns
    if has_week_col:
        f["ì£¼ì°¨_num"] = f["ì£¼ì°¨"].apply(_week_to_num)

    # --- ë² ì´ìŠ¤(ë¹„êµ ê·¸ë£¹) ë°ì´í„° í•„í„°ë§ ---
    base_raw = df_full.copy()
    group_name_parts = []

    # 1. í¸ì„± ê¸°ì¤€ í•„í„°
    if comp_prog_filter is not None:
        # 'ë™ì¼ í¸ì„±'ì¸ë° IP í¸ì„± ì •ë³´ê°€ ì—†ìœ¼ë©´, í•„í„°ë¥¼ ê±´ë„ˆëœ€
        if use_same_prog and not sel_prog:
            st.warning(f"'{ip_selected}'ì˜ í¸ì„± ì •ë³´ê°€ ì—†ì–´ 'ë™ì¼ í¸ì„±' ê¸°ì¤€ì€ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")
        else:
            base_raw = base_raw[base_raw["í¸ì„±"].isin(comp_prog_filter)]

            if comp_type == "í‰ì¼":
                group_name_parts.append("'í‰ì¼(ì›”í™”+ìˆ˜ëª©)'")
            elif comp_type in ["ì›”í™”", "ìˆ˜ëª©", "í† ì¼"]:
                group_name_parts.append(f"'{comp_type}'")
            elif use_same_prog and sel_prog:
                group_name_parts.append(f"'{sel_prog}'")

    # 2. ë°©ì˜ ì—°ë„ í•„í„°
    if selected_years:
        base_raw = base_raw[base_raw[date_col_for_filter].isin(selected_years)]
        
        if len(selected_years) <= 3:
            years_str = ",".join(map(str, sorted(selected_years)))
            group_name_parts.append(f"{years_str}")
        else:
            try:
                group_name_parts.append(f"{min(selected_years)}~{max(selected_years)}")
            except:
                group_name_parts.append("ì„ íƒì—°ë„")
    else:
        st.warning("ì„ íƒëœ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤. (ì „ì²´ ì—°ë„ ë°ì´í„°ì™€ ë¹„êµ)", icon="âš ï¸")

    if not group_name_parts:
        group_name_parts.append("ì „ì²´")
    
    prog_label = " & ".join(group_name_parts) + " í‰ê· "

    # --- (ì´í•˜ ë¡œì§ ë™ì¼) ---
    if "íšŒì°¨_numeric" in base_raw.columns:
        base_raw["íšŒì°¨_num"] = pd.to_numeric(base_raw["íšŒì°¨_numeric"], errors="coerce")
    else:
        base_raw["íšŒì°¨_num"] = pd.to_numeric(base_raw["íšŒì°¨"].str.extract(r"(\d+)", expand=False), errors="coerce")
    
    if pd.notna(my_max_ep):
        base = base_raw[base_raw["íšŒì°¨_num"] <= my_max_ep].copy()
    else:
        base = base_raw.copy()

    st.markdown(
        f"<div class='sub-title'>ğŸ“º {ip_selected} ì„±ê³¼ ìƒì„¸ ë¦¬í¬íŠ¸</div>",
        unsafe_allow_html=True
    )
    st.markdown("---")

    # --- Metric Normalizer & Formatters ---
    def _normalize_metric(s: str) -> str:
        if s is None: return ""
        s2 = re.sub(r"[^A-Za-z0-9ê°€-í£]+", "", str(s)).lower()
        return s2

    def _metric_filter(df: pd.DataFrame, name: str) -> pd.DataFrame:
        target = _normalize_metric(name)
        if "metric_norm" not in df.columns:
            df = df.copy()
            df["metric_norm"] = df["metric"].apply(_normalize_metric)
        return df[df["metric_norm"] == target]

    def fmt_kor(x):
        if pd.isna(x): return "0"
        val = float(x)
        if val == 0: return "0"
        rounded = int(round(val / 10000)) 
        if rounded == 0 and val > 0: return f"{val/10000:.1f}ë§Œ"
        uk = rounded // 10000; man = rounded % 10000
        if uk > 0: return f"{uk}ì–µ{man:04d}ë§Œ" if man > 0 else f"{uk}ì–µ"
        return f"{man}ë§Œ"

    def fmt_live_kor(x):
        if pd.isna(x): return "0"
        val = float(x)
        if val == 0: return "0"
        man = int(val // 10000); cheon = int((val % 10000) // 1000)
        if man > 0: return f"{man}ë§Œ{cheon}ì²œ" if cheon > 0 else f"{man}ë§Œ"
        return f"{cheon}ì²œ" if cheon > 0 else f"{int(val)}"

    def get_axis_ticks(max_val, formatter=fmt_kor):
        if pd.isna(max_val) or max_val <= 0: return None, None
        step = max_val / 4
        power = 10 ** int(np.log10(step))
        base = step / power
        if base < 1.5: step = 1 * power
        elif base < 3.5: step = 2 * power
        elif base < 7.5: step = 5 * power
        else: step = 10 * power
        vals = np.arange(0, max_val + step * 0.1, step)
        texts = [formatter(v) for v in vals]
        return vals, texts
    
    # --- Aggregation Helpers ---
    def _series_ip_metric(base_df: pd.DataFrame, metric_name: str, mode: str = "mean", media: List[str] | None = None):
        if metric_name == "ì¡°íšŒìˆ˜": sub = _get_view_data(base_df)
        else: sub = _metric_filter(base_df, metric_name).copy()
        if media is not None: sub = sub[sub["ë§¤ì²´"].isin(media)]
        if sub.empty: return pd.Series(dtype=float)

        # [ì‹ ê·œ] ë„·í”Œë¦­ìŠ¤ ìˆœìœ„ ë“± 'íšŒì°¨' ì •ë³´ê°€ ì—†ì„ ìˆ˜ ìˆëŠ” ì§€í‘œ ì˜ˆì™¸ ì²˜ë¦¬
        if metric_name == "N_Wìˆœìœ„":
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value"])
            if sub.empty: return pd.Series(dtype=float)
            if mode == "min": s = sub.groupby("IP")["value"].min()
            elif mode == "mean": s = sub.groupby("IP")["value"].mean()
            else: s = sub.groupby("IP")["value"].min()
            return pd.to_numeric(s, errors="coerce").dropna()

        ep_col = _episode_col(sub)
        sub = sub.dropna(subset=[ep_col])
        sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
        sub = sub.dropna(subset=["value"])
        if sub.empty: return pd.Series(dtype=float)

        if mode == "mean":
            ep_mean = sub.groupby(["IP", ep_col], as_index=False)["value"].mean()
            s = ep_mean.groupby("IP")["value"].mean()
        elif mode == "sum": s = sub.groupby("IP")["value"].sum()
        elif mode == "ep_sum_mean":
            ep_sum = sub.groupby(["IP", ep_col], as_index=False)["value"].sum()
            s = ep_sum.groupby("IP")["value"].mean()
        elif mode == "min": s = sub.groupby("IP")["value"].min()
        else: s = sub.groupby("IP")["value"].mean()
        return pd.to_numeric(s, errors="coerce").dropna()

    def _min_of_ip_metric(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty: return None
        s = pd.to_numeric(sub["value"], errors="coerce").dropna()
        return float(s.min()) if not s.empty else None

    def _mean_like_rating(df_src: pd.DataFrame, metric_name: str) -> float | None:
        sub = _metric_filter(df_src, metric_name).copy()
        if sub.empty: return None
        sub["val"] = pd.to_numeric(sub["value"], errors="coerce")
        sub = sub.dropna(subset=["val"])
        if sub.empty: return None
        if "íšŒì°¨_num" in sub.columns and sub["íšŒì°¨_num"].notna().any():
            g = sub.dropna(subset=["íšŒì°¨_num"]).groupby("íšŒì°¨_num", as_index=False)["val"].mean()
            return float(g["val"].mean())
        if date_col_for_filter in sub.columns and sub[date_col_for_filter].notna().any():
            g = sub.dropna(subset=[date_col_for_filter]).groupby(date_col_for_filter, as_index=False)["val"].mean()
            return float(g["val"].mean())
        return float(sub["val"].mean())

    # --- KPI Calculation ---
    val_T = mean_of_ip_episode_mean(f, "Tì‹œì²­ë¥ ")
    val_H = mean_of_ip_episode_mean(f, "Hì‹œì²­ë¥ ")
    val_live = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    val_quick = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"]) 
    val_vod = mean_of_ip_episode_sum(f, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])

    # [ì‹ ê·œ] Wavve VOD (metric="ì‹œì²­ììˆ˜", media="ì›¨ì´ë¸Œ")
    val_wavve = mean_of_ip_episode_sum(f, "ì‹œì²­ììˆ˜", ["ì›¨ì´ë¸Œ"])

    # [ì‹ ê·œ] Netflix Best Rank
    val_netflix_best = _min_of_ip_metric(f, "N_Wìˆœìœ„")

    val_buzz = mean_of_ip_sums(f, "ì–¸ê¸‰ëŸ‰")
    val_view = mean_of_ip_sums(f, "ì¡°íšŒìˆ˜")
    val_topic_min = _min_of_ip_metric(f, "F_Total")
    val_topic_avg = _mean_like_rating(f, "F_score")

    base_T = mean_of_ip_episode_mean(base, "Tì‹œì²­ë¥ ")
    base_H = mean_of_ip_episode_mean(base, "Hì‹œì²­ë¥ ")
    base_live = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    base_quick = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING QUICK"])
    base_vod = mean_of_ip_episode_sum(base, "ì‹œì²­ì¸êµ¬", ["TVING VOD"])

    # [ì‹ ê·œ] Wavve VOD Base
    base_wavve = mean_of_ip_episode_sum(base, "ì‹œì²­ììˆ˜", ["ì›¨ì´ë¸Œ"])

    # [ì‹ ê·œ] Netflix Base
    base_netflix_series = _series_ip_metric(base, "N_Wìˆœìœ„", mode="min")
    base_netflix_best = float(base_netflix_series.mean()) if not base_netflix_series.empty else None
    base_buzz = mean_of_ip_sums(base, "ì–¸ê¸‰ëŸ‰")
    base_view = mean_of_ip_sums(base, "ì¡°íšŒìˆ˜")
    base_topic_min_series = _series_ip_metric(base, "F_Total", mode="min")
    base_topic_min = float(base_topic_min_series.mean()) if not base_topic_min_series.empty else None
    base_topic_avg = _mean_like_rating(base, "F_score")

    # --- Ranking ---
    def _rank_within_program(base_df, metric_name, ip_name, value, mode="mean", media=None, low_is_good=False):
        s = _series_ip_metric(base_df, metric_name, mode=mode, media=media)
        if s.empty or value is None or pd.isna(value): return (None, 0)
        s = s.dropna()
        if ip_name not in s.index: return (None, int(s.shape[0]))
        ranks = s.rank(method="min", ascending=low_is_good)
        return (int(ranks.loc[ip_name]), int(s.shape[0]))

    rk_T     = _rank_within_program(base, "Tì‹œì²­ë¥ ", ip_selected, val_T,   mode="mean",        media=None)
    rk_H     = _rank_within_program(base, "Hì‹œì²­ë¥ ", ip_selected, val_H,   mode="mean",        media=None)
    rk_live  = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_live,  mode="ep_sum_mean", media=["TVING LIVE"])
    rk_quick = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_quick, mode="ep_sum_mean", media=["TVING QUICK"])
    rk_vod   = _rank_within_program(base, "ì‹œì²­ì¸êµ¬", ip_selected, val_vod,   mode="ep_sum_mean", media=["TVING VOD"])

    # [ì‹ ê·œ] Wavve Rank
    rk_wavve = _rank_within_program(base, "ì‹œì²­ììˆ˜", ip_selected, val_wavve, mode="ep_sum_mean", media=["ì›¨ì´ë¸Œ"])

    # [ì‹ ê·œ] Netflix Rank
    rk_netflix = _rank_within_program(base, "N_Wìˆœìœ„", ip_selected, val_netflix_best, mode="min", media=None, low_is_good=True)
    rk_buzz  = _rank_within_program(base, "ì–¸ê¸‰ëŸ‰",   ip_selected, val_buzz,  mode="sum",        media=None)
    rk_view  = _rank_within_program(base, "ì¡°íšŒìˆ˜",   ip_selected, val_view,  mode="sum",        media=None)
    rk_fmin  = _rank_within_program(base, "F_Total",  ip_selected, val_topic_min, mode="min",   media=None, low_is_good=True)
    rk_fscr  = _rank_within_program(base, "F_score",  ip_selected, val_topic_avg, mode="mean",  media=None, low_is_good=False)

    # --- KPI Render Helpers ---
    def _pct_color(val, base_val):
        if val is None or pd.isna(val) or base_val in (None, 0) or pd.isna(base_val): return "#888"
        pct = (val / base_val) * 100
        return "#d93636" if pct > 100 else ("#2a61cc" if pct < 100 else "#444")

    def sublines_html(prog_label: str, rank_tuple: tuple, val, base_val):
        rnk, total = rank_tuple if rank_tuple else (None, 0)
        
        if rnk is not None and total > 0:
            prefix = "ğŸ‘‘ " if rnk == 1 else ""
            rank_label = f"{prefix}{rnk}ìœ„<span style='font-size:11px;font-weight:400;color:#9ca3af;margin-left:2px'>(ì´{total}ê°œ)</span>"
        else:
            rank_label = "â€“ìœ„"

        pct_txt = "â€“"; col = "#888"
        try:
            if (val is not None) and (base_val not in (None, 0)) and (not (pd.isna(val) or pd.isna(base_val))):
                pct = (float(val) / float(base_val)) * 100.0
                pct_txt = f"{pct:.0f}%"; col = _pct_color(val, base_val)
        except Exception: pass
        return (
            "<div class='kpi-subwrap'>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ å…§</span> "
            f"<span class='kpi-substrong'>{rank_label}</span><br/>"
            "<span class='kpi-sublabel'>ê·¸ë£¹ í‰ê· æ¯”</span> "
            f"<span class='kpi-subpct' style='color:{col};'>{pct_txt}</span>"
            "</div>"
        )

    def sublines_dummy():
        return (
         "<div class='kpi-subwrap' style='visibility:hidden;'>"
         "<span class='kpi-sublabel'>_</span> <span class='kpi-substrong'>_</span><br/>"
         "<span class='kpi-sublabel'>_</span> <span class='kpi-subpct'>_</span>"
          "</div>"
        )

    def kpi_with_rank(col, title, value, base_val, rank_tuple, prog_label, intlike=False, digits=3, value_suffix=""):
        with col:
            main_val = fmt(value, digits=digits, intlike=intlike)
            st.markdown(
                f"<div class='kpi-card'><div class='kpi-title'>{title}</div>"
                f"<div class='kpi-value'>{main_val}{value_suffix}</div>"
                f"{sublines_html(prog_label, rank_tuple, value, base_val)}</div>",
                unsafe_allow_html=True
            )

    # === KPI ë°°ì¹˜ (Row 1) ===
    c1, c2, c3, c4, c5 = st.columns(5)
    kpi_with_rank(c1, "ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ",    val_T, base_T, rk_T, prog_label, digits=3)
    kpi_with_rank(c2, "ğŸ  ê°€êµ¬ì‹œì²­ë¥ ",    val_H, base_H, rk_H, prog_label, digits=3)
    kpi_with_rank(c3, "ğŸ“º í‹°ë¹™ LIVE UV",     val_live, base_live, rk_live, prog_label, intlike=True)
    kpi_with_rank(c4, "âš¡ í‹°ë¹™ ë‹¹ì¼ VOD UV",  val_quick, base_quick, rk_quick, prog_label, intlike=True)
    kpi_with_rank(c5, "â–¶ï¸ í‹°ë¹™ ì£¼ê°„ VOD UV", val_vod, base_vod, rk_vod, prog_label, intlike=True)

    # === KPI ë°°ì¹˜ (Row 2) ===
    c6, c7, c8, c9, c10 = st.columns(5)
    kpi_with_rank(c6, "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜", val_view, base_view, rk_view, prog_label, intlike=True)
    kpi_with_rank(c7, "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", val_buzz, base_buzz, rk_buzz, prog_label, intlike=True)
    with c8:
        v = val_topic_min
        main_val = "â€“" if (v is None or pd.isna(v)) else f"{int(round(v)):,d}ìœ„"
        st.markdown(
            f"<div class='kpi-card'><div class='kpi-title'>ğŸ† ìµœê³  í™”ì œì„± ìˆœìœ„</div>"
            f"<div class='kpi-value'>{main_val}</div>{sublines_dummy()}</div>",
            unsafe_allow_html=True
        )
    kpi_with_rank(c9, "ğŸ”¥ í™”ì œì„± ì ìˆ˜", val_topic_avg, base_topic_avg, rk_fscr, prog_label, intlike=True)
    with c10:
        if val_wavve is not None and not pd.isna(val_wavve):
            kpi_with_rank(c10, "ğŸŒŠ ì›¨ì´ë¸Œ VOD UV", val_wavve, base_wavve, rk_wavve, prog_label, intlike=True)

        elif val_netflix_best is not None and not pd.isna(val_netflix_best) and val_netflix_best > 0:
            main_val = f"{int(val_netflix_best)}ìœ„"
            st.markdown(
                f"<div class='kpi-card'><div class='kpi-title'>ğŸ¿ ë„·í”Œë¦­ìŠ¤ ìµœê³ ìˆœìœ„</div>"
                f"<div class='kpi-value'>{main_val}</div>{sublines_dummy()}</div>",
                unsafe_allow_html=True
            )
        else:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹„ì›Œë‘ê¸°
            st.markdown(
                f"<div class='kpi-card' style='opacity:0; pointer-events:none;'><div class='kpi-title'>-</div>"
                f"<div class='kpi-value'>-</div>{sublines_dummy()}</div>",
                unsafe_allow_html=True
            )


    st.divider()

    # --- Charts ---
    chart_h = 320
    common_cfg = {"scrollZoom": False, "staticPlot": False, "displayModeBar": False}

    # === [Row1] ì‹œì²­ë¥  | í‹°ë¹™ ===
    cA, cB = st.columns(2)
    with cA:
        st.markdown("<div class='sec-title'>ğŸ“ˆ ì‹œì²­ë¥ </div>", unsafe_allow_html=True)
        rsub = f[f["metric"].isin(["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "])].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        rsub = rsub.sort_values("íšŒì°¨_num")
        if not rsub.empty:
            ep_order = rsub[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            t_series = rsub[rsub["metric"] == "Tì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            h_series = rsub[rsub["metric"] == "Hì‹œì²­ë¥ "].groupby("íšŒì°¨", as_index=False)["value"].mean()
            ymax = pd.concat([t_series["value"], h_series["value"]]).max()
            y_upper = float(ymax) * 1.4 if pd.notna(ymax) else None

            fig_rate = go.Figure()
            fig_rate.add_trace(go.Scatter(
                x=h_series["íšŒì°¨"], y=h_series["value"], mode="lines+markers+text", name="ê°€êµ¬ì‹œì²­ë¥ ",
                line=dict(color='#90a4ae', width=2), text=[f"{v:.2f}" for v in h_series["value"]], textposition="top center"
            ))
            fig_rate.add_trace(go.Scatter(
                x=t_series["íšŒì°¨"], y=t_series["value"], mode="lines+markers+text", name="íƒ€ê¹ƒì‹œì²­ë¥ ",
                line=dict(color='#3949ab', width=3), text=[f"{v:.2f}" for v in t_series["value"]], textposition="top center"
            ))
            fig_rate.update_xaxes(categoryorder="array", categoryarray=ep_order, title=None, fixedrange=True)
            fig_rate.update_yaxes(title=None, fixedrange=True, range=[0, y_upper] if (y_upper and y_upper > 0) else None)
            fig_rate.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8), legend=dict(orientation='h', yanchor='bottom', y=1.02))
            st.plotly_chart(fig_rate, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì‹œì²­ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cB:
        # TVING ë°ì´í„°
        t_keep = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        tsub = f[(f["metric"] == "ì‹œì²­ì¸êµ¬") & (f["ë§¤ì²´"].isin(t_keep))].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        tsub = tsub.sort_values("íšŒì°¨_num")

        # [ì‹ ê·œ] Wavve ë°ì´í„° (ìˆìœ¼ë©´ ê°™ì€ ê·¸ë˜í”„ì— ì¶”ê°€)
        wsub = f[(f["metric"] == "ì‹œì²­ììˆ˜") & (f["ë§¤ì²´"] == "ì›¨ì´ë¸Œ")].dropna(subset=["íšŒì°¨", "íšŒì°¨_num"]).copy()
        wsub = wsub.sort_values("íšŒì°¨_num")
        has_wavve = not wsub.empty

        chart_title = "ğŸ“± TVING & Wavve ì‹œì²­ììˆ˜" if has_wavve else "ğŸ“± TVING ì‹œì²­ììˆ˜"
        st.markdown(f"<div class='sec-title'>{chart_title}</div>", unsafe_allow_html=True)

        if not tsub.empty or has_wavve:
            combined = pd.DataFrame()

            if not tsub.empty:
                media_map = {"TVING LIVE": "LIVE", "TVING QUICK": "ë‹¹ì¼ VOD", "TVING VOD": "ì£¼ê°„ VOD"}
                tsub["ë§¤ì²´_í‘œê¸°"] = tsub["ë§¤ì²´"].map(media_map)
                combined = pd.concat([combined, tsub[["íšŒì°¨", "íšŒì°¨_num", "ë§¤ì²´_í‘œê¸°", "value"]]])

            if has_wavve:
                wsub["ë§¤ì²´_í‘œê¸°"] = "Wavve"
                combined = pd.concat([combined, wsub[["íšŒì°¨", "íšŒì°¨_num", "ë§¤ì²´_í‘œê¸°", "value"]]])

            pvt = combined.pivot_table(index="íšŒì°¨", columns="ë§¤ì²´_í‘œê¸°", values="value", aggfunc="sum").fillna(0)
            ep_order = combined[["íšŒì°¨", "íšŒì°¨_num"]].drop_duplicates().sort_values("íšŒì°¨_num")["íšŒì°¨"].tolist()
            pvt = pvt.reindex(ep_order)

            tving_stack_order = ["LIVE", "ë‹¹ì¼ VOD", "ì£¼ê°„ VOD"]
            tving_colors = {"LIVE": "#90caf9", "ë‹¹ì¼ VOD": "#64b5f6", "ì£¼ê°„ VOD": "#1565c0"}

            fig_ott = go.Figure()

            # 1) TVING (í•­ìƒ í‘œì‹œ)
            for m in tving_stack_order:
                if m in pvt.columns:
                    fig_ott.add_trace(go.Bar(
                        name=m, x=pvt.index, y=pvt[m],
                        marker_color=tving_colors[m],
                        text=None,
                        hovertemplate=f"<b>%{{x}}</b><br>{m}: %{{y:,.0f}}<extra></extra>"
                    ))

            # 2) Wavve (ê¸°ë³¸ ìˆ¨ê¹€)
            if "Wavve" in pvt.columns:
                fig_ott.add_trace(go.Bar(
                    name="Wavve", x=pvt.index, y=pvt["Wavve"],
                    marker_color="#5c6bc0",
                    visible='legendonly',
                    text=None,
                    hovertemplate="<b>%{x}</b><br>Wavve: %{y:,.0f}<extra></extra>"
                ))

            # 3) Total í…ìŠ¤íŠ¸ëŠ” TVING í•©ê³„ ê¸°ì¤€ (ê¸°ë³¸ ë·° ìœ ì§€)
            tving_cols = [c for c in pvt.columns if c in tving_stack_order]
            if tving_cols:
                total_vals = pvt[tving_cols].sum(axis=1)
                max_val = total_vals.max()
                if "Wavve" in pvt.columns:
                    max_val = max(max_val, (total_vals + pvt["Wavve"]).max())
                total_txt = [fmt_live_kor(v) for v in total_vals]

                fig_ott.add_trace(go.Scatter(
                    x=pvt.index, y=total_vals, mode='text',
                    text=total_txt, textposition='top center',
                    textfont=dict(size=11, color='#333'),
                    showlegend=False, hoverinfo='skip'
                ))
            else:
                total_vals = pvt.sum(axis=1)
                max_val = total_vals.max()

            fig_ott.update_layout(
                barmode='stack',
                height=chart_h,
                margin=dict(l=8, r=8, t=10, b=8),
                legend=dict(orientation='h', yanchor='bottom', y=1.02),
                yaxis=dict(title=None, range=[0, max_val * 1.25] if pd.notna(max_val) else None),
                xaxis=dict(title=None, fixedrange=True),
            )
            st.plotly_chart(fig_ott, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  TVING ì‹œì²­ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Row2] ë°ëª¨ ë¶„í¬ ===
    cG, cH, cI = st.columns(3)

    def _render_pyramid_local(container, title, df_src, height=260):
        if df_src.empty:
            container.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

        COLOR_MALE_NEW = "#5B85D9"; COLOR_FEMALE_NEW = "#E66C6C"

        df_demo = df_src.copy()
        df_demo["ì„±ë³„"] = df_demo["ë°ëª¨"].apply(_gender_from_demo)
        df_demo["ì—°ë ¹ëŒ€_ëŒ€"] = df_demo["ë°ëª¨"].apply(_to_decade_label)
        df_demo = df_demo[df_demo["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & df_demo["ì—°ë ¹ëŒ€_ëŒ€"].notna()]

        if df_demo.empty: container.info("ë°ì´í„° ì—†ìŒ"); return

        order = ["60ëŒ€", "50ëŒ€", "40ëŒ€", "30ëŒ€", "20ëŒ€", "10ëŒ€"]

        pvt = df_demo.groupby(["ì—°ë ¹ëŒ€_ëŒ€","ì„±ë³„"])["value"].sum().unstack("ì„±ë³„").reindex(order).fillna(0)
        male = -pvt.get("ë‚¨", pd.Series(0, index=pvt.index))
        female = pvt.get("ì—¬", pd.Series(0, index=pvt.index))

        total_pop = male.abs().sum() + female.sum()
        if total_pop == 0: total_pop = 1
        
        male_share = (male.abs() / total_pop * 100)
        female_share = (female / total_pop * 100)
        max_abs = float(max(male.abs().max(), female.max()) or 1)

        male_text = [f"{v:.1f}%" if v > 0 else "" for v in male_share]
        female_text = [f"{v:.1f}%" if v > 0 else "" for v in female_share]

        fig = go.Figure()
        fig.add_trace(go.Bar(
            y=pvt.index, x=male, name="ë‚¨", orientation="h", marker_color=COLOR_MALE_NEW,
            text=male_text, textposition="inside", insidetextanchor="end",
            textfont=dict(color="#ffffff", size=11),
            hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ë‚¨ì„±=%{customdata[0]:,.0f}ëª…<br>ì „ì²´ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
            customdata=np.column_stack([male.abs(), male_share])
        ))
        fig.add_trace(go.Bar(
            y=pvt.index, x=female, name="ì—¬", orientation="h", marker_color=COLOR_FEMALE_NEW,
            text=female_text, textposition="inside", insidetextanchor="start",
            textfont=dict(color="#ffffff", size=11),
            hovertemplate="ì—°ë ¹ëŒ€=%{y}<br>ì—¬ì„±=%{customdata[0]:,.0f}ëª…<br>ì „ì²´ë¹„ì¤‘=%{customdata[1]:.1f}%<extra></extra>",
            customdata=np.column_stack([female, female_share])
        ))

        fig.update_layout(
            barmode="overlay", height=height, margin=dict(l=8, r=8, t=48, b=8),
            legend_title=None, bargap=0.15,
            title=dict(text=title, x=0.0, y=0.98, font=dict(size=14))
        )
        fig.update_yaxes(categoryorder="array", categoryarray=order, fixedrange=True)
        fig.update_xaxes(range=[-max_abs*1.1, max_abs*1.1], showticklabels=False, showgrid=False, zeroline=True, fixedrange=True)
        container.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    with cG:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TV</div>", unsafe_allow_html=True)
        tv_demo = f[(f["ë§¤ì²´"] == "TV") & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cG, "", tv_demo, height=260)

    with cH:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TVING LIVE</div>", unsafe_allow_html=True)
        live_demo = f[(f["ë§¤ì²´"] == "TVING LIVE") & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cH, "", live_demo, height=260)

    with cI:
        st.markdown("<div class='sec-title' style='font-size:18px;'>ğŸ‘¥ëˆ„ì  ì‹œì²­ì ë¶„í¬ - TVING VOD</div>", unsafe_allow_html=True)
        vod_demo = f[(f["ë§¤ì²´"].isin(["TVING VOD", "TVING QUICK"])) & (f["metric"] == "ì‹œì²­ì¸êµ¬") & f["ë°ëª¨"].notna()].copy()
        _render_pyramid_local(cI, "", vod_demo, height=260)

    # === [Row3] ë””ì§€í„¸&í™”ì œì„± ===
    digital_colors = ['#5c6bc0', '#7e57c2', '#26a69a', '#66bb6a', '#ffa726', '#ef5350']

    # ----------------------------
    # Row3-1: ë””ì§€í„¸ (2ì—´)
    # ----------------------------
    cC, cD = st.columns(2)

    with cC:
        st.markdown("<div class='sec-title'>ğŸ’» ë””ì§€í„¸ ì¡°íšŒìˆ˜</div>", unsafe_allow_html=True)
        dview = _get_view_data(f) 
        if not dview.empty:
            if has_week_col and dview["ì£¼ì°¨"].notna().any():
                order = (dview[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dview.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dview.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum").sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            total_view = pvt.sum(axis=1)
            max_view = total_view.max()
            view_ticks_val, view_ticks_txt = get_axis_ticks(max_view, formatter=fmt_kor)
            total_text = [fmt_kor(v) for v in total_view]

            fig_view = go.Figure()
            for i, col in enumerate(pvt.columns):
                h_texts = [fmt_kor(v) for v in pvt[col]]
                fig_view.add_trace(go.Bar(
                    name=col, x=x_vals, y=pvt[col], marker_color=digital_colors[i % len(digital_colors)],
                    hovertemplate="<b>%{x}</b><br>" + f"{col}: " + "%{text}<extra></extra>",
                    text=h_texts, textposition='none'
                ))
            
            fig_view.add_trace(go.Scatter(
                x=x_vals, y=total_view, mode='text', text=total_text, textposition='top center',
                textfont=dict(size=11, color='#333'), showlegend=False, hoverinfo='skip'
            ))
            fig_view.update_layout(
                barmode="stack", legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8),
                yaxis=dict(tickvals=view_ticks_val, ticktext=view_ticks_txt, fixedrange=True, range=[0, max_view * 1.15])
            )
            if use_category: fig_view.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
            st.plotly_chart(fig_view, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì¡°íšŒìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with cD:
        st.markdown("<div class='sec-title'>ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰</div>", unsafe_allow_html=True)
        dbuzz = f[f["metric"] == "ì–¸ê¸‰ëŸ‰"].copy()
        if not dbuzz.empty:
            if has_week_col and dbuzz["ì£¼ì°¨"].notna().any():
                order = (dbuzz[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                pvt = dbuzz.pivot_table(index="ì£¼ì°¨", columns="ë§¤ì²´", values="value", aggfunc="sum").fillna(0)
                pvt = pvt.reindex(order)
                x_vals = pvt.index.tolist(); use_category = True
            else:
                pvt = (dbuzz.pivot_table(index="ì£¼ì°¨ì‹œì‘ì¼", columns="ë§¤ì²´", values="value", aggfunc="sum").sort_index().fillna(0))
                x_vals = pvt.index.tolist(); use_category = False

            total_buzz = pvt.sum(axis=1)
            max_buzz = total_buzz.max()
            total_text = [f"{v:,.0f}" for v in total_buzz]

            fig_buzz = go.Figure()
            for i, col in enumerate(pvt.columns):
                h_texts = [f"{v:,.0f}" for v in pvt[col]]
                fig_buzz.add_trace(go.Bar(
                    name=col, x=x_vals, y=pvt[col], marker_color=digital_colors[(i+2) % len(digital_colors)],
                    hovertemplate="<b>%{x}</b><br>" + f"{col}: " + "%{text}<extra></extra>",
                    text=h_texts, textposition='none'
                ))
            
            fig_buzz.add_trace(go.Scatter(
                x=x_vals, y=total_buzz, mode='text', text=total_text, textposition='top center',
                textfont=dict(size=11, color='#333'), showlegend=False, hoverinfo='skip'
            ))
            fig_buzz.update_layout(
                barmode="stack", legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=10, b=8),
                yaxis=dict(fixedrange=True, range=[0, max_buzz * 1.15])
            )
            if use_category: fig_buzz.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
            st.plotly_chart(fig_buzz, use_container_width=True, config=common_cfg)
        else:
            st.info("í‘œì‹œí•  ì–¸ê¸‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ----------------------------
    # Row3-2: í™”ì œì„±/OTT (2ì—´)
    # ----------------------------
    cE, cF = st.columns(2)

    with cE:
        st.markdown("<div class='sec-title'>ğŸ”¥ í™”ì œì„± ì ìˆ˜ & ìˆœìœ„</div>", unsafe_allow_html=True)
        fdx = _metric_filter(f, "F_Total").copy(); fs = _metric_filter(f, "F_score").copy()
        if has_week_col and f["ì£¼ì°¨"].notna().any():
            order = (f[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
            key_col = "ì£¼ì°¨"; use_category = True
        else:
            key_col = "ì£¼ì°¨ì‹œì‘ì¼"; order = sorted(f[key_col].dropna().unique()); use_category = False
            
        if not fs.empty:
            fs["val"] = pd.to_numeric(fs["value"], errors="coerce")
            fs_agg = fs.dropna(subset=[key_col]).groupby(key_col, as_index=False)["val"].mean()
        else:
            fs_agg = pd.DataFrame(columns=[key_col, "val"])
            
        if not fdx.empty:
            fdx["rank"] = pd.to_numeric(fdx["value"], errors="coerce")
            fdx_agg = fdx.dropna(subset=[key_col]).groupby(key_col, as_index=False)["rank"].min()
        else:
            fdx_agg = pd.DataFrame(columns=[key_col, "rank"])
            
        if not fs_agg.empty:
            merged = pd.merge(fs_agg, fdx_agg, on=key_col, how="left")
            if use_category:
                merged = merged.set_index(key_col).reindex(order).dropna(subset=["val"]).reset_index()
            else:
                merged = merged.sort_values(key_col)
            
            if not merged.empty:
                x_vals = merged[key_col].tolist(); y_vals = merged["val"].tolist()
                labels = [
                    f"{int(r['rank'])}ìœ„<br>/{int(r['val']):,}ì " if pd.notna(r['rank']) else f"{int(r['val']):,}ì "
                    for _, r in merged.iterrows()
                ]
                
                fig_comb = go.Figure()
                fig_comb.add_trace(go.Scatter(
                    x=x_vals, y=y_vals, mode="lines+markers+text", name="í™”ì œì„± ì ìˆ˜",
                    text=labels, textposition="top center", textfont=dict(size=11, color="#333"),
                    line=dict(color='#ec407a', width=3), marker=dict(size=7, color='#ec407a')
                ))
                if y_vals:
                    fig_comb.update_yaxes(range=[0, max(y_vals) * 1.25], title=None, fixedrange=True)
                if use_category:
                    fig_comb.update_xaxes(categoryorder="array", categoryarray=x_vals, fixedrange=True)
                fig_comb.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=20, b=8))
                st.plotly_chart(fig_comb, use_container_width=True, config=common_cfg)
            else:
                st.info("ë°ì´í„° ì—†ìŒ")
        else:
            st.info("ë°ì´í„° ì—†ìŒ")

    with cF:
        st.markdown("<div class='sec-title'>ğŸ¿ ë„·í”Œë¦­ìŠ¤ ì£¼ê°„ ìˆœìœ„ ì¶”ì´</div>", unsafe_allow_html=True)
        n_df = _metric_filter(f, "N_Wìˆœìœ„").copy()
        n_df["val"] = pd.to_numeric(n_df["value"], errors="coerce").replace(0, np.nan)
        n_df = n_df.dropna(subset=["val"])

        if not n_df.empty:
            if has_week_col and f["ì£¼ì°¨"].notna().any():
                n_agg = n_df.groupby("ì£¼ì°¨", as_index=False)["val"].min()
                all_weeks = (f[["ì£¼ì°¨", "ì£¼ì°¨_num"]].dropna().drop_duplicates().sort_values("ì£¼ì°¨_num")["ì£¼ì°¨"].tolist())
                n_agg = n_agg.set_index("ì£¼ì°¨").reindex(all_weeks).dropna().reset_index()
                x_vals = n_agg["ì£¼ì°¨"]; use_cat = True
            else:
                n_agg = n_df.groupby("ì£¼ì°¨ì‹œì‘ì¼", as_index=False)["val"].min().sort_values("ì£¼ì°¨ì‹œì‘ì¼")
                x_vals = n_agg["ì£¼ì°¨ì‹œì‘ì¼"]; use_cat = False

            y_vals = n_agg["val"]
            labels = [f"{int(v)}ìœ„" for v in y_vals]

            fig_nf = go.Figure()
            fig_nf.add_trace(go.Scatter(
                x=x_vals, y=y_vals, mode="lines+markers+text",
                name="ë„·í”Œë¦­ìŠ¤ ìˆœìœ„",
                line=dict(color="#f44336", width=3),
                marker=dict(size=7, color="#f44336"),
                text=labels, textposition="top center", textfont=dict(size=11, color="#333"),
                hovertemplate="<b>%{x}</b><br>Rank: %{y:,.0f}<extra></extra>"
            ))

            # ìˆœìœ„ëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë‹ˆ ì¶•ì„ ë’¤ì§‘ì–´ ë³´ì´ê²Œ
            fig_nf.update_yaxes(autorange="reversed", title=None, fixedrange=True)
            if use_cat:
                fig_nf.update_xaxes(categoryorder="array", categoryarray=list(x_vals), fixedrange=True)
            fig_nf.update_layout(legend_title=None, height=chart_h, margin=dict(l=8, r=8, t=20, b=8))
            st.plotly_chart(fig_nf, use_container_width=True, config=common_cfg)
        else:
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)

    st.divider()

    # === [Row5] ë°ëª¨ë¶„ì„ ìƒì„¸ í‘œ (AgGrid) ===
    st.markdown("#### ğŸ‘¥ íšŒì°¨ë³„ ì‹œì²­ììˆ˜ ë¶„í¬")

    def _build_demo_table_numeric(df_src, medias):
        sub = df_src[
            (df_src["metric"] == "ì‹œì²­ì¸êµ¬")
            & (df_src["ë°ëª¨"].notna())
            & (df_src["ë§¤ì²´"].isin(medias))
        ].copy()

        if sub.empty:
            return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

        # ë°ëª¨ â†’ ì„±ë³„ / ì—°ë ¹ëŒ€
        sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(_gender_from_demo)
        sub["ì—°ë ¹ëŒ€_ëŒ€"] = sub["ë°ëª¨"].apply(_decade_label_clamped)
        sub = sub[sub["ì„±ë³„"].isin(["ë‚¨", "ì—¬"]) & sub["ì—°ë ¹ëŒ€_ëŒ€"].notna()].copy()
        if sub.empty:
            return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

        # íšŒì°¨ ìˆ«ìí™”
        if "íšŒì°¨_num" not in sub.columns:
            sub["íšŒì°¨_num"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        sub = sub.dropna(subset=["íšŒì°¨_num"])
        if sub.empty:
            return pd.DataFrame(columns=["íšŒì°¨"] + DEMO_COLS_ORDER)

        sub["íšŒì°¨_num"] = sub["íšŒì°¨_num"].astype(int)

        # ë¼ë²¨: "20ëŒ€ë‚¨ì„±", "30ëŒ€ì—¬ì„±"
        sub["ë¼ë²¨"] = sub.apply(
            lambda r: f"{r['ì—°ë ¹ëŒ€_ëŒ€']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}",
            axis=1,
        )

        # í”¼ë²—: íšŒì°¨ Ã— ë°ëª¨ ë§¤íŠ¸ë¦­ìŠ¤
        pvt = (
            sub.pivot_table(
                index="íšŒì°¨_num",
                columns="ë¼ë²¨",
                values="value",
                aggfunc="sum",
            )
            .fillna(0)
        )

        # ì—†ëŠ” ë°ëª¨ ì»¬ëŸ¼ 0ìœ¼ë¡œ ì±„ì›Œì„œ ìˆœì„œ í†µì¼
        for c in DEMO_COLS_ORDER:
            if c not in pvt.columns:
                pvt[c] = 0

        pvt = pvt[DEMO_COLS_ORDER].sort_index()
        pvt.insert(0, "íšŒì°¨", pvt.index.map(_fmt_ep))

        return pvt.reset_index(drop=True)

    # === JS ë Œë”ëŸ¬ (â–²/â–¾ + í–‰ë³„ ê·¸ë¼ë””ì–¸íŠ¸) ===

    # DiffRenderer: ì „ íšŒì°¨ ëŒ€ë¹„ â–²/â–¾ í‘œì‹œ
    diff_renderer = JsCode("""
    class DiffRenderer {
      init(params) {
        this.eGui = document.createElement('span');

        if (!params) {
          this.eGui.innerText = '';
          return;
        }

        const api = params.api;
        const colId = params.column ? params.column.getColId() : null;
        const rowIndex = params.node ? params.node.rowIndex : 0;
        const rawVal = (params.value === null || params.value === undefined) ? 0 : params.value;
        const val = Number(rawVal) || 0;

        // 1. ìˆ«ì í¬ë§·íŒ…
        let displayVal = (colId === "íšŒì°¨")
          ? (params.value || "")
          : Math.round(val).toLocaleString();

        // 2. í™”ì‚´í‘œ ë¡œì§
        let arrow = "";
        if (colId !== "íšŒì°¨" && api && typeof api.getDisplayedRowAtIndex === "function" && rowIndex > 0) {
          const prev = api.getDisplayedRowAtIndex(rowIndex - 1);
          if (prev && prev.data && prev.data[colId] != null) {
            const pv = Number(prev.data[colId] || 0);

            if (val > pv) {
              // ìƒìŠ¹: ì‘ì€ ì‚¼ê°í˜•(Red) -> HTML Entity ì‚¬ìš©
              arrow = '<span style="margin-left:4px;">(<span style="color:#d93636;">&#9652;</span>)</span>';
            } else if (val < pv) {
              // í•˜ë½: ì‘ì€ ì—­ì‚¼ê°í˜•(Blue) -> HTML Entity ì‚¬ìš©
              arrow = '<span style="margin-left:4px;">(<span style="color:#2a61cc;">&#9662;</span>)</span>';
            }
          }
        }

        this.eGui.innerHTML = displayVal + arrow;
      }

      getGui() {
        return this.eGui;
      }
    }
    """)

    # í–‰ ë‚´ì—ì„œ min~max ê¸°ì¤€ìœ¼ë¡œ ë¸”ë£¨ ê·¸ë¼ë””ì–¸íŠ¸
    _js_demo_cols = "[" + ",".join([f'"{c}"' for c in DEMO_COLS_ORDER]) + "]"
    cell_style_renderer = JsCode(f"""
    function(params){{
      const field = params.colDef.field;
      // íšŒì°¨ ì—´: ì¢Œì¸¡ ì •ë ¬, í° ë°°ê²½ ê³ ì •
      if (field === "íšŒì°¨") {{
        return {{
          'text-align': 'left',
          'font-weight': '600',
          'background-color': '#ffffff'
        }};
      }}

      if (!params || !params.data) {{
        return {{
          'background-color': '#ffffff',
          'text-align': 'right',
          'padding': '2px 4px',
          'font-weight': '500'
        }};
      }}

      const COLS = {_js_demo_cols};
      let rowVals = [];
      for (let k of COLS) {{
        if (params.data.hasOwnProperty(k)) {{
          const v = Number(params.data[k]);
          if (!isNaN(v)) rowVals.push(v);
        }}
      }}

      let bg = '#ffffff';
      if (rowVals.length > 0) {{
        const v = Number(params.value || 0);
        const mn = Math.min.apply(null, rowVals);
        const mx = Math.max.apply(null, rowVals);
        let norm = 0.5;
        if (mx > mn) {{
          norm = (v - mn) / (mx - mn);
        }}
        norm = Math.max(0, Math.min(1, norm));
        const alpha = 0.12 + 0.45 * norm;
        bg = 'rgba(30,90,255,' + alpha.toFixed(3) + ')';
      }}

      return {{
        'background-color': bg,
        'text-align': 'right',
        'padding': '2px 4px',
        'font-weight': '500'
      }};
    }}
    """)

    def _render_aggrid_table(df_numeric, title):
        st.markdown(f"###### {title}")
        if df_numeric.empty:
            st.info("ë°ì´í„° ì—†ìŒ")
            return

        gb = GridOptionsBuilder.from_dataframe(df_numeric)

        gb.configure_grid_options(
            rowHeight=34,
            suppressMenuHide=True,
        )

        gb.configure_default_column(
            sortable=False,
            resizable=True,
            filter=False,
            cellStyle={"textAlign": "right"},
            headerClass="centered-header bold-header",
        )

        gb.configure_column(
            "íšŒì°¨",
            header_name="íšŒì°¨",
            cellStyle={"textAlign": "left"},
        )

        # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼: JS ë Œë”ëŸ¬ ì ìš©
        for c in [col for col in df_numeric.columns if col != "íšŒì°¨"]:
            gb.configure_column(
                c,
                header_name=c,
                cellRenderer=diff_renderer,
                cellStyle=cell_style_renderer,
            )

        rows = len(df_numeric)
        base_row_height = 34
        header_height = 34
        max_visible_rows = 17 

        if rows <= max_visible_rows:
            height = base_row_height * rows + header_height + 24
        else:
            height = base_row_height * max_visible_rows + header_height + 24

        AgGrid(
            df_numeric,
            gridOptions=gb.build(),
            theme="streamlit",
            height=height,
            fit_columns_on_grid_load=True,
            update_mode=GridUpdateMode.NO_UPDATE,
            allow_unsafe_jscode=True,  
        )

    tv_numeric = _build_demo_table_numeric(f, ["TV"])
    _render_aggrid_table(tv_numeric, "ğŸ“º TV (ì‹œì²­ììˆ˜)")

    tving_numeric = _build_demo_table_numeric(
        f, ["TVING LIVE", "TVING QUICK", "TVING VOD"]
    )
    _render_aggrid_table(tving_numeric, "â–¶ï¸ TVING í•©ì‚° ì‹œì²­ììˆ˜")


# =====================================================

# ===== 10.0. í¬ë§·íŒ… í—¬í¼ (í˜ì´ì§€ 4 ì „ìš©) =====
def _fmt_kor_large(v):
    """Nì–µ NNNNë§Œ ë‹¨ìœ„ í¬ë§·íŒ…"""
    if v is None or pd.isna(v): return "â€“"
    val = float(v)
    if val == 0: return "0"
    
    uk = int(val // 100000000)
    man = int((val % 100000000) // 10000)
    
    if uk > 0:
        return f"{uk}ì–µ{man:04d}ë§Œ"
    elif man > 0:
        return f"{man}ë§Œ"
    else:
        return f"{int(val)}"

# ===== 10.1. [í˜ì´ì§€ 4] KPI ë°±ë¶„ìœ„ ê³„ì‚° (ìºì‹±) =====
@st.cache_data(ttl=600)
def get_kpi_data_for_all_ips(df_all: pd.DataFrame, max_ep: float = None) -> pd.DataFrame:
    """
    ëª¨ë“  IPì— ëŒ€í•´ KPI ì§‘ê³„ í›„ ë°±ë¶„ìœ„(0~100) ë³€í™˜
    max_epê°€ ìˆìœ¼ë©´ í•´ë‹¹ íšŒì°¨ê¹Œì§€ë§Œ ì˜ë¼ì„œ ì§‘ê³„
    """
    df = df_all.copy()
    
    # 1. íšŒì°¨ í•„í„°ë§
    if "íšŒì°¨_numeric" not in df.columns:
        df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    
    df = df.dropna(subset=["íšŒì°¨_numeric"])
    
    if max_ep is not None:
        df = df[df["íšŒì°¨_numeric"] <= max_ep]

    # 2. ê°’ ì „ì²˜ë¦¬
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df.loc[df["value"] == 0, "value"] = np.nan
    df = df.dropna(subset=["value"])

    # 3. ì§€í‘œë³„ ì§‘ê³„ í•¨ìˆ˜
    def _ip_mean_of_ep_mean(metric_name: str) -> pd.Series:
        sub = df[df["metric"] == metric_name]
        if sub.empty: return pd.Series(dtype=float, name=metric_name)
        ep_mean = sub.groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
        return ep_mean.groupby("IP")["value"].mean().rename(metric_name)

    kpi_t_rating = _ip_mean_of_ep_mean("Tì‹œì²­ë¥ ")
    kpi_h_rating = _ip_mean_of_ep_mean("Hì‹œì²­ë¥ ")

    # TVING VOD + QUICK
    sub_vod_all = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"].isin(["TVING VOD", "TVING QUICK"]))]
    if not sub_vod_all.empty:
        vod_ep_sum = sub_vod_all.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_vod = vod_ep_sum.groupby("IP")["value"].mean().rename("TVING VOD")
    else:
        kpi_vod = pd.Series(dtype=float, name="TVING VOD")

    # TVING LIVE
    sub_live = df[(df["metric"] == "ì‹œì²­ì¸êµ¬") & (df["ë§¤ì²´"] == "TVING LIVE")]
    if not sub_live.empty:
        live_ep_sum = sub_live.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
        kpi_live = live_ep_sum.groupby("IP")["value"].mean().rename("TVING LIVE")
    else:
        kpi_live = pd.Series(dtype=float, name="TVING LIVE")

    # ë””ì§€í„¸ ì¡°íšŒìˆ˜ / ì–¸ê¸‰ëŸ‰
    view_sub = _get_view_data(df) 
    if not view_sub.empty:
        kpi_view = view_sub.groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì¡°íšŒìˆ˜")
    else:
        kpi_view = pd.Series(dtype=float, name="ë””ì§€í„¸ ì¡°íšŒìˆ˜")

    buzz_sub = df[df["metric"] == "ì–¸ê¸‰ëŸ‰"]
    if not buzz_sub.empty:
        kpi_buzz = buzz_sub.groupby("IP")["value"].sum().rename("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰")
    else:
        kpi_buzz = pd.Series(dtype=float, name="ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰")

    kpi_f_score = _ip_mean_of_ep_mean("F_Score").rename("í™”ì œì„± ì ìˆ˜")

    # 4. í†µí•© ë° ë°±ë¶„ìœ„ ì‚°ì¶œ
    kpi_df = pd.concat([kpi_t_rating, kpi_h_rating, kpi_vod, kpi_live, kpi_view, kpi_buzz, kpi_f_score], axis=1)
    kpi_percentiles = kpi_df.rank(pct=True) * 100
    return kpi_percentiles.fillna(0)


# ===== 10.2. [í˜ì´ì§€ 4] ë‹¨ì¼ IP/ê·¸ë£¹ KPI ê³„ì‚° =====
def get_agg_kpis_for_ip_page4(df_ip: pd.DataFrame) -> Dict[str, float | None]:
    kpis = {}
    kpis["Tì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Tì‹œì²­ë¥ ")
    kpis["Hì‹œì²­ë¥ "] = mean_of_ip_episode_mean(df_ip, "Hì‹œì²­ë¥ ")
    kpis["TVING VOD"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING VOD", "TVING QUICK"])
    kpis["TVING LIVE"] = mean_of_ip_episode_sum(df_ip, "ì‹œì²­ì¸êµ¬", ["TVING LIVE"])
    kpis["ë””ì§€í„¸ ì¡°íšŒìˆ˜"] = mean_of_ip_sums(df_ip, "ì¡°íšŒìˆ˜")
    kpis["ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"] = mean_of_ip_sums(df_ip, "ì–¸ê¸‰ëŸ‰")
    kpis["í™”ì œì„± ì ìˆ˜"] = mean_of_ip_episode_mean(df_ip, "F_Score")
    return kpis


# ===== 10.3. [í˜ì´ì§€ 4] KPI ì¹´ë“œ ë Œë”ë§ (ìƒë‹¨) =====
def _render_kpi_row_ip_vs_group(kpis_ip, kpis_group, ranks, group_name):
    def _calc_delta(ip_val, group_val): 
        ip_val = ip_val or 0
        group_val = group_val or 0
        if group_val is None or group_val == 0: return None
        return (ip_val - group_val) / group_val

    def _kpi_card_html(title, val_str, delta, rank_tuple):
        if delta is None:
            delta_html = "<span style='color:#9ca3af; font-size:13px;'>-</span>"
        else:
            pct = delta * 100
            color = "#d93636" if pct > 0 else ("#2a61cc" if pct < 0 else "#9ca3af")
            symbol = "â–²" if pct > 0 else ("â–¼" if pct < 0 else "-")
            delta_html = f"<span style='color:{color}; font-size:13px; font-weight:600;'>{symbol} {abs(pct):.1f}%</span>"

        if rank_tuple and rank_tuple[1] > 0:
            rnk, total = rank_tuple
            rank_html = f"<span style='color:#6b7280; font-size:12px; margin-left:6px;'>({rnk}ìœ„/{total}ì‘í’ˆ)</span>"
        else:
            rank_html = ""
        
        return f"""
        <div class="kpi-card" style="padding: 14px 10px;">
            <div class="kpi-title">{title}</div>
            <div class="kpi-value" style="font-size: 22px; margin-bottom: 4px;">{val_str}</div>
            <div style="line-height: 1.2;">{delta_html}{rank_html}</div>
        </div>
        """

    st.markdown(f"#### 1. ì£¼ìš” ì„±ê³¼ ({group_name} ëŒ€ë¹„)")
    
    keys = ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "TVING LIVE", "TVING VOD", "ë””ì§€í„¸ ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰", "í™”ì œì„± ì ìˆ˜"]
    titles = ["ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", "ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", "âš¡ í‹°ë¹™ LIVE UV", "â–¶ï¸ í‹°ë¹™ VOD UV", "ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", "ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰", "ğŸ”¥ í™”ì œì„± ì ìˆ˜"]
    
    cols = st.columns(7)
    for i, key in enumerate(keys):
        val = kpis_ip.get(key)
        base_val = kpis_group.get(key)
        delta = _calc_delta(val, base_val)
        rank_info = ranks.get(key, (None, 0))
        
        if key in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "]:
            val_str = f"{val:.2f}%" if val is not None else "â€“"
        elif key == "ë””ì§€í„¸ ì¡°íšŒìˆ˜":
            val_str = _fmt_kor_large(val)
        else:
            val_str = f"{val:,.0f}" if val is not None else "â€“"
            
        with cols[i]:
            st.markdown(_kpi_card_html(titles[i], val_str, delta, rank_info), unsafe_allow_html=True)


def _render_kpi_row_ip_vs_ip(kpis1, kpis2, ip1, ip2):
    def _card(title, v1, v2, fmt, higher_good=True):
        v1_disp = fmt.format(v1) if v1 is not None else "â€“"
        v2_disp = fmt.format(v2) if v2 is not None else "â€“"
        win = 0
        if v1 is not None and v2 is not None:
            if higher_good: win = 1 if v1 > v2 else (2 if v2 > v1 else 0)
            else: win = 1 if v1 < v2 else (2 if v2 < v1 else 0)
        
        s1 = "color:#d93636;font-weight:700" if win==1 else "color:#333"
        s2 = "color:#aaaaaa;font-weight:700" if win==2 else "color:#888"

        st.markdown(f"""
        <div class="kpi-card" style="padding:10px 10px;">
            <div class="kpi-title" style="margin-bottom:4px;">{title}</div>
            <div style="font-size:14px; line-height:1.4;">
                <span style="{s1}"><span style="font-size:11px;color:#d93636">{ip1}:</span> {v1_disp}</span><br>
                <span style="{s2}"><span style="font-size:11px;color:#aaaaaa">{ip2}:</span> {v2_disp}</span>
            </div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("#### 1. ì£¼ìš” ì„±ê³¼ ìš”ì•½")
    c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
    with c1: _card("ğŸ¯ íƒ€ê¹ƒì‹œì²­ë¥ ", kpis1.get("Tì‹œì²­ë¥ "), kpis2.get("Tì‹œì²­ë¥ "), "{:.2f}%")
    with c2: _card("ğŸ  ê°€êµ¬ì‹œì²­ë¥ ", kpis1.get("Hì‹œì²­ë¥ "), kpis2.get("Hì‹œì²­ë¥ "), "{:.2f}%")
    with c3: _card("âš¡ í‹°ë¹™ LIVE UV", kpis1.get("TVING LIVE"), kpis2.get("TVING LIVE"), "{:,.0f}")
    with c4: _card("â–¶ï¸ í‹°ë¹™ VOD UV", kpis1.get("TVING VOD"), kpis2.get("TVING VOD"), "{:,.0f}")
    with c5: _card("ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒ", kpis1.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), kpis2.get("ë””ì§€í„¸ ì¡°íšŒìˆ˜"), "{:,.0f}")
    with c6: _card("ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰", kpis1.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), kpis2.get("ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"), "{:,.0f}")
    with c7: _card("ğŸ”¥ í™”ì œì„± ì ìˆ˜", kpis1.get("í™”ì œì„± ì ìˆ˜"), kpis2.get("í™”ì œì„± ì ìˆ˜"), "{:,.0f}")


# ===== 10.4. [í˜ì´ì§€ 4] í†µí•© ê·¸ë˜í”„ ì„¹ì…˜ =====
def _render_unified_charts(df_target, df_comp, target_name, comp_name, kpi_percentiles, comp_color="#aaaaaa"):
    st.divider()

    # --- 2. ì„±ê³¼ í¬ì§€ì…”ë‹ (Radar) & ì‹œì²­ë¥  ë¹„êµ (Line) ---
    st.markdown("#### 2. ì„±ê³¼ í¬ì§€ì…”ë‹ & ì‹œì²­ë¥ ")
    col_radar, col_rating = st.columns([1, 1])

    # [ì¢Œì¸¡] ì„±ê³¼ í¬ì§€ì…”ë‹
    with col_radar:
        st.markdown("###### ì„±ê³¼ ë°±ë¶„ìœ„ (Positioning)")
        
        radar_map = {
            "Tì‹œì²­ë¥ ": "íƒ€ê¹ƒì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ": "ê°€êµ¬ì‹œì²­ë¥ ", 
            "TVING LIVE": "í‹°ë¹™ LIVE", "TVING VOD": "í‹°ë¹™ VOD", 
            "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ì–¸ê¸‰ëŸ‰", "í™”ì œì„± ì ìˆ˜": "í™”ì œì„±"
        }
        radar_metrics = list(radar_map.keys())
        radar_labels = list(radar_map.values())

        # Target Score
        if target_name in kpi_percentiles.index:
            score_t = kpi_percentiles.loc[target_name][radar_metrics]
        else:
            score_t = pd.Series(0, index=radar_metrics)
            
        # Comp Score
        if comp_name in kpi_percentiles.index: # IP vs IP
            score_c = kpi_percentiles.loc[comp_name][radar_metrics]
        else: # IP vs Group (ê·¸ë£¹ì˜ í‰ê·  ë°±ë¶„ìœ„)
            group_ips = df_comp["IP"].unique()
            score_c = kpi_percentiles.loc[kpi_percentiles.index.isin(group_ips)].mean()[radar_metrics]

        fig_radar = go.Figure()
        fig_radar.add_trace(go.Scatterpolar(
            r=score_t.values, theta=radar_labels,
            fill='toself', name=target_name, line=dict(color="#d93636")
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=score_c.values, theta=radar_labels,
            fill='toself', name=comp_name, line=dict(color=comp_color)
        ))
        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True, height=350,
            margin=dict(l=50, r=50, t=30, b=30),
            legend=dict(orientation="h", yanchor="bottom", y=1.05)
        )
        st.plotly_chart(fig_radar, use_container_width=True)

    # [ìš°ì¸¡] ì‹œì²­ë¥  ë¹„êµ
    with col_rating:
        st.markdown(f"###### ì‹œì²­ë¥ ")
        
        df_target_rating = df_target[df_target["metric"].isin(["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ "])].copy()
        if "íšŒì°¨_numeric" not in df_target_rating.columns:
            df_target_rating["íšŒì°¨_numeric"] = df_target_rating["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
            
        max_ep = df_target_rating["íšŒì°¨_numeric"].max()
        if pd.isna(max_ep): max_ep = 999
        
        def _get_trend(df, metric):
            if "íšŒì°¨_numeric" not in df.columns:
                df["íšŒì°¨_numeric"] = df["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
            mask = (df["metric"] == metric)
            if pd.notna(max_ep):
                mask = mask & (df["íšŒì°¨_numeric"] <= max_ep)
            sub = df[mask].copy()
            return sub.groupby("íšŒì°¨_numeric")["value"].mean().sort_index()

        t_target = _get_trend(df_target, "Tì‹œì²­ë¥ ")
        h_target = _get_trend(df_target, "Hì‹œì²­ë¥ ")
        t_comp   = _get_trend(df_comp,   "Tì‹œì²­ë¥ ")
        h_comp   = _get_trend(df_comp,   "Hì‹œì²­ë¥ ")
        
        fig_line = go.Figure()
        fig_line.add_trace(go.Scatter(x=h_target.index, y=h_target.values, name=f"{target_name}(ê°€êµ¬)",
                                      mode='lines+markers', line=dict(color="#90a4ae", width=2)))
        fig_line.add_trace(go.Scatter(x=t_target.index, y=t_target.values, name=f"{target_name}(íƒ€ê¹ƒ)",
                                      mode='lines+markers', line=dict(color="#3949ab", width=2)))
        
        fig_line.add_trace(go.Scatter(x=h_comp.index, y=h_comp.values, name=f"{comp_name}(ê°€êµ¬)",
                                      mode='lines+markers', line=dict(color="#90a4ae", width=2, dash='dot')))
        fig_line.add_trace(go.Scatter(x=t_comp.index, y=t_comp.values, name=f"{comp_name}(íƒ€ê¹ƒ)",
                                      mode='lines+markers', line=dict(color="#3949ab", width=2, dash='dot')))
        
        fig_line.update_layout(height=350, margin=dict(t=30, b=10), 
                               legend=dict(orientation="h", yanchor="bottom", y=1.02),
                               yaxis_title="ì‹œì²­ë¥ (%)", xaxis_title="íšŒì°¨")
        st.plotly_chart(fig_line, use_container_width=True)

    st.divider()

    # --- 3. ì‹œì²­ì¸êµ¬ ë¹„êµ ---
    st.markdown("#### 3. ë§¤ì²´ë³„ í‰ê·  ì‹œì²­ì¸êµ¬")
    col_pop_tv, col_pop_tving = st.columns(2)

    def _get_demo_pop(df_src, medias):
        sub = df_src[(df_src["metric"]=="ì‹œì²­ì¸êµ¬") & (df_src["ë§¤ì²´"].isin(medias)) & df_src["ë°ëª¨"].notna()].copy()
        sub["ì„±ë³„"] = sub["ë°ëª¨"].apply(_gender_from_demo)
        sub["ì—°ë ¹"] = sub["ë°ëª¨"].apply(_to_decade_label)
        sub = sub[sub["ì„±ë³„"].isin(["ë‚¨","ì—¬"]) & (sub["ì—°ë ¹"]!="ê¸°íƒ€")]
        sub["label"] = sub.apply(lambda r: f"{r['ì—°ë ¹']}{'ë‚¨ì„±' if r['ì„±ë³„']=='ë‚¨' else 'ì—¬ì„±'}", axis=1)
        if "íšŒì°¨_numeric" not in sub.columns:
             sub["íšŒì°¨_numeric"] = sub["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
        agg = sub.groupby(["IP","íšŒì°¨_numeric","label"])["value"].sum().reset_index()
        return agg.groupby("label")["value"].mean()

    with col_pop_tv:
        st.markdown("###### ğŸ“º TV (í‰ê·  ì‹œì²­ì¸êµ¬)")
        pop_t = _get_demo_pop(df_target, ["TV"])
        pop_c = _get_demo_pop(df_comp,   ["TV"])
        df_bar = pd.DataFrame({target_name: pop_t, comp_name: pop_c}).fillna(0).reset_index()
        df_melt = df_bar.melt(id_vars="label", var_name="êµ¬ë¶„", value_name="ì¸êµ¬ìˆ˜")
        
        sort_map = {col: i for i, col in enumerate(DEMO_COLS_ORDER)}
        df_melt["s"] = df_melt["label"].map(sort_map).fillna(999)
        df_melt = df_melt.sort_values("s")
        
        if not df_melt.empty:
            fig_tv = px.bar(df_melt, x="label", y="ì¸êµ¬ìˆ˜", color="êµ¬ë¶„", barmode="group",
                            color_discrete_map={target_name: "#d93636", comp_name: comp_color},
                            text="ì¸êµ¬ìˆ˜")
            fig_tv.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_tv.update_layout(height=300, margin=dict(t=30), legend=dict(title=None, orientation="h", y=1.02),
                                 xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_tv, use_container_width=True)
        else:
            st.info("ë°ì´í„° ì—†ìŒ")

    with col_pop_tving:
        st.markdown("###### â–¶ï¸ TVING (í‰ê·  ì‹œì²­ì¸êµ¬)")
        tving_ms = ["TVING LIVE", "TVING QUICK", "TVING VOD"]
        pop_t = _get_demo_pop(df_target, tving_ms)
        pop_c = _get_demo_pop(df_comp,   tving_ms)
        df_bar = pd.DataFrame({target_name: pop_t, comp_name: pop_c}).fillna(0).reset_index()
        df_melt = df_bar.melt(id_vars="label", var_name="êµ¬ë¶„", value_name="ì¸êµ¬ìˆ˜")
        
        sort_map = {col: i for i, col in enumerate(DEMO_COLS_ORDER)}
        df_melt["s"] = df_melt["label"].map(sort_map).fillna(999)
        df_melt = df_melt.sort_values("s")
        
        if not df_melt.empty:
            fig_tv = px.bar(df_melt, x="label", y="ì¸êµ¬ìˆ˜", color="êµ¬ë¶„", barmode="group",
                            color_discrete_map={target_name: "#d93636", comp_name: comp_color},
                            text="ì¸êµ¬ìˆ˜")
            fig_tv.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
            fig_tv.update_layout(height=300, margin=dict(t=30), legend=dict(title=None, orientation="h", y=1.02),
                                 xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_tv, use_container_width=True)
        else:
            st.info("ë°ì´í„° ì—†ìŒ")

    st.divider()

    # --- 4. ë””ì§€í„¸ ë¹„êµ (ë„ë„›ì°¨íŠ¸) ---
    st.markdown("#### 4. ë””ì§€í„¸ ë°˜ì‘")
    col_dig_view, col_dig_buzz = st.columns(2)

    def _get_pie_data(df_src, metric):
        if metric == "ì¡°íšŒìˆ˜":
            sub = _get_view_data(df_src)
        else:
            sub = df_src[df_src["metric"] == metric].copy()
        
        if sub.empty: return pd.DataFrame(columns=["ë§¤ì²´", "val"])
        per_ip_media = sub.groupby(["IP", "ë§¤ì²´"])["value"].sum().reset_index()
        avg_per_media = per_ip_media.groupby("ë§¤ì²´")["value"].mean().reset_index().rename(columns={"value":"val"})
        return avg_per_media

    def _draw_scaled_donuts_fixed_color(df_t, df_c, title, t_name, c_name):
        from plotly.subplots import make_subplots
        all_media = set(df_t["ë§¤ì²´"].unique()) | set(df_c["ë§¤ì²´"].unique())
        sorted_media = sorted(list(all_media))
        base_colors = ['#5c6bc0', '#7e57c2', '#26a69a', '#66bb6a', '#ffa726', '#ef5350', '#8d6e63', '#78909c']
        color_map = {m: base_colors[i % len(base_colors)] for i, m in enumerate(sorted_media)}
        df_t["color"] = df_t["ë§¤ì²´"].map(color_map)
        df_c["color"] = df_c["ë§¤ì²´"].map(color_map)

        fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]],
                            subplot_titles=[f"{t_name}", f"{c_name}"])
        sum_t = df_t["val"].sum() if not df_t.empty else 0
        sum_c = df_c["val"].sum() if not df_c.empty else 0
        
        if not df_t.empty:
            fig.add_trace(go.Pie(
                labels=df_t["ë§¤ì²´"], values=df_t["val"], 
                name=t_name, scalegroup='one', hole=0.4,
                title=f"Total<br>{_fmt_kor_large(sum_t)}", title_font=dict(size=14),
                marker=dict(colors=df_t["color"]), domain=dict(column=0), sort=False 
            ), 1, 1)
        if not df_c.empty:
            fig.add_trace(go.Pie(
                labels=df_c["ë§¤ì²´"], values=df_c["val"], 
                name=c_name, scalegroup='one', hole=0.4,
                title=f"Total<br>{_fmt_kor_large(sum_c)}", title_font=dict(size=14),
                marker=dict(colors=df_c["color"]), domain=dict(column=1), sort=False
            ), 1, 2)
        fig.update_layout(height=320, margin=dict(t=30, b=10, l=10, r=10),
                          legend=dict(orientation="h", y=-0.15, x=0.5, xanchor="center"))
        return fig

    with col_dig_view:
        st.markdown("###### ğŸ‘€ ë””ì§€í„¸ ì¡°íšŒìˆ˜ ë¹„êµ")
        pie_t = _get_pie_data(df_target, "ì¡°íšŒìˆ˜")
        pie_c = _get_pie_data(df_comp,   "ì¡°íšŒìˆ˜")
        if pie_t.empty and pie_c.empty: st.info("ë°ì´í„° ì—†ìŒ")
        else:
            fig_pie = _draw_scaled_donuts_fixed_color(pie_t, pie_c, "ì¡°íšŒìˆ˜", target_name, comp_name)
            st.plotly_chart(fig_pie, use_container_width=True)

    with col_dig_buzz:
        st.markdown("###### ğŸ’¬ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰ ë¹„êµ")
        pie_t = _get_pie_data(df_target, "ì–¸ê¸‰ëŸ‰")
        pie_c = _get_pie_data(df_comp,   "ì–¸ê¸‰ëŸ‰")
        if pie_t.empty and pie_c.empty: st.info("ë°ì´í„° ì—†ìŒ")
        else:
            fig_pie = _draw_scaled_donuts_fixed_color(pie_t, pie_c, "ì–¸ê¸‰ëŸ‰", target_name, comp_name)
            st.plotly_chart(fig_pie, use_container_width=True)

    st.divider()

    # --- 5. [í†µí•©] ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ ---
    st.markdown("#### 5. ğŸ‘¥ IP ì˜¤ë””ì–¸ìŠ¤ íˆíŠ¸ë§µ")
    st.caption(f"ì„ íƒí•˜ì‹  **'{target_name}'**ê³¼ **'{comp_name}'**ì˜ íšŒì°¨ë³„/ë°ëª¨ë³„ ì‹œì²­ììˆ˜ ê²©ì°¨ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    heatmap_media = st.radio("ë¶„ì„ ë§¤ì²´", ["TV", "TVING"], index=0, horizontal=True, label_visibility="collapsed", key="heatmap_media_page4")
    media_list = ["TV"] if heatmap_media == "TV" else ["TVING LIVE", "TVING QUICK", "TVING VOD"]
    media_label = "TV" if heatmap_media == "TV" else "TVING"

    if "íšŒì°¨_numeric" not in df_target.columns: 
         df_target["íšŒì°¨_numeric"] = df_target["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)
    if "íšŒì°¨_numeric" not in df_comp.columns:
         df_comp["íšŒì°¨_numeric"] = df_comp["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)

    df_base_heat = get_avg_demo_pop_by_episode(df_target, media_list, max_ep=None) 
    df_comp_heat = get_avg_demo_pop_by_episode(df_comp, media_list, max_ep=None)

    if df_base_heat.empty:
        st.warning(f"ê¸°ì¤€ IP({target_name})ì˜ íˆíŠ¸ë§µ ë°ëª¨ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if df_comp_heat.empty:
             st.warning(f"ë¹„êµ ëŒ€ìƒ({comp_name})ì˜ íˆíŠ¸ë§µ ë°ì´í„°ê°€ ì—†ì–´ ë¹„êµê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
             df_comp_heat = pd.DataFrame({'íšŒì°¨': df_base_heat['íšŒì°¨']})
             for col in DEMO_COLS_ORDER: df_comp_heat[col] = 0.0

        df_merged = pd.merge(df_base_heat, df_comp_heat, on="íšŒì°¨", suffixes=('_base', '_comp'), how='left')
        df_index = df_merged[["íšŒì°¨"]].copy()

        for col in DEMO_COLS_ORDER: 
            base_col = col + '_base'
            comp_col = col + '_comp'
            df_merged[base_col] = pd.to_numeric(df_merged.get(base_col), errors='coerce').fillna(0.0)
            df_merged[comp_col] = pd.to_numeric(df_merged.get(comp_col), errors='coerce').fillna(0.0)
            base_values = df_merged[base_col].values
            comp_values = df_merged[comp_col].values
            index_values = np.where(
                comp_values != 0,
                ((base_values - comp_values) / comp_values) * 100,
                np.where(base_values == 0, 0.0, 999)
            )
            df_index[col] = index_values

        table_title = f"{media_label} ì—°ë ¹ëŒ€ë³„ ì‹œì²­ììˆ˜ ì°¨ì´ ({target_name} vs {comp_name})"
        render_heatmap(df_index, table_title)


# ===== 10.5. [í˜ì´ì§€ 4] ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====
def render_comparison():
    df_all = load_data() 
    if "íšŒì°¨_numeric" not in df_all.columns:
        df_all["íšŒì°¨_numeric"] = df_all["íšŒì°¨"].str.extract(r"(\d+)", expand=False).astype(float)

    kpi_percentiles = get_kpi_data_for_all_ips(df_all, max_ep=None)
    ip_options = sorted(df_all["IP"].dropna().unique().tolist())
    
    # ì „ì—­ IP ê°€ì ¸ì˜¤ê¸° (ê¸°ì¤€ IP)
    global_ip = st.session_state.get("global_ip")
    if not global_ip: st.error("IP ì„ íƒ í•„ìš”"); return
    
    selected_ip1 = global_ip
    selected_ip2 = None

    current_mode = st.session_state.get("comp_mode_page4", "IP vs ê·¸ë£¹ í‰ê· ")
    
    if current_mode == "IP vs IP":
        # íƒ€ì´í‹€(4) | ëª¨ë“œì„ íƒ(3) | ë¹„êµIP(3) | íšŒì°¨(2)
        filter_cols = st.columns([4, 3, 3, 2])
    else:
        # íƒ€ì´í‹€(4) | ëª¨ë“œì„ íƒ(3) | í¸ì„±(2) | ì—°ë„(2) | íšŒì°¨(1)
        filter_cols = st.columns([4, 3, 2, 2, 1])
    
    with filter_cols[0]:
        st.markdown(f"<div class='page-title'>âš–ï¸ {selected_ip1} <span style='font-size:18px;color:#666'>vs ...</span></div>", unsafe_allow_html=True)
        
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì§€í‘œ ê¸°ì¤€**
        - **ì‹œì²­ë¥ ** `íšŒì°¨í‰ê· `: ì „êµ­ ê¸°ì¤€ ê°€êµ¬ & íƒ€ê¹ƒ(2049) ì‹œì²­ë¥ 
        - **í‹°ë¹™ LIVE** `íšŒì°¨í‰ê· `: ì‹¤ì‹œê°„ ì‹œì²­ UV
        - **í‹°ë¹™ ë‹¹ì¼ VOD** `íšŒì°¨í‰ê· `: ë³¸ë°©ì†¡ ë‹¹ì¼ VOD UV
        - **í‹°ë¹™ ì£¼ê°„ VOD** `íšŒì°¨í‰ê· `: [íšŒì°¨ ë°©ì˜ì¼ë¶€í„° +6ì¼ê¹Œì§€ì˜ 7ì¼ê°„ VOD UV] - [í‹°ë¹™ ë‹¹ì¼ VOD]
        - **ë””ì§€í„¸ ì¡°íšŒ** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ê°„ ì›”~ì¼ ë°œìƒ ì´í•© / ìœ íŠœë¸Œ,ì¸ìŠ¤íƒ€ê·¸ë¨,í‹±í†¡,ë„¤ì´ë²„TV,í˜ì´ìŠ¤ë¶
        - **ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰** `íšŒì°¨ì´í•©`: ë°©ì˜ì£¼ì°¨(ì›”~ì¼) ë‚´ ì´í•© / ì»¤ë®¤ë‹ˆí‹°,íŠ¸ìœ„í„°,ë¸”ë¡œê·¸                            
        - **í™”ì œì„± ì ìˆ˜** `íšŒì°¨í‰ê· `: ë°©ì˜ê¸°ê°„ ì£¼ì°¨ë³„ í™”ì œì„± ì ìˆ˜ì˜ í‰ê·  (í€ë±ìŠ¤)
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)

    with filter_cols[1]:
        comparison_mode = st.radio(
            "ë¹„êµ ëª¨ë“œ", 
            ["IP vs IP", "IP vs ê·¸ë£¹ í‰ê· "], 
            index=1, horizontal=True, label_visibility="collapsed",
            key="comp_mode_page4" 
        ) 
    
    selected_max_ep = "ì „ì²´"

    # --- IP vs IP ëª¨ë“œ ---
    if comparison_mode == "IP vs IP":
        with filter_cols[2]:
            ip_options_2 = [ip for ip in ip_options if ip != selected_ip1]
            selected_ip2 = st.selectbox(
                "ë¹„êµ IP", ip_options_2, 
                index=0 if ip_options_2 else None, 
                label_visibility="collapsed"
            )
        
        target_rows = df_all[df_all["IP"] == selected_ip1]
        ep_opts = ["ì „ì²´"] + get_episode_options(target_rows)
        
        with filter_cols[3]:
            selected_max_ep = st.selectbox("íšŒì°¨ ë²”ìœ„", ep_opts, index=0, label_visibility="collapsed")
        
        use_same_prog = False; selected_years = []

    # --- IP vs ê·¸ë£¹ í‰ê·  ëª¨ë“œ ---
    else: 
        # ê¸°ì¤€ IP ì •ë³´ ìë™ ë¡œë“œ
        base_ip_info_rows = df_all[df_all["IP"] == selected_ip1]
        base_ip_prog = base_ip_info_rows["í¸ì„±"].dropna().mode().iloc[0] if (("í¸ì„±" in base_ip_info_rows.columns) and (not base_ip_info_rows["í¸ì„±"].dropna().empty)) else None
        
        all_years = []
        if "í¸ì„±ì—°ë„" in df_all.columns:
            unique_vals = df_all["í¸ì„±ì—°ë„"].dropna().unique()
            try: all_years = sorted(unique_vals, reverse=True)
            except: all_years = sorted([str(x) for x in unique_vals], reverse=True)

        default_year_list = []
        if "í¸ì„±ì—°ë„" in base_ip_info_rows.columns:
            y_mode = base_ip_info_rows["í¸ì„±ì—°ë„"].dropna().mode()
            if not y_mode.empty: default_year_list = [y_mode.iloc[0]]

        with filter_cols[2]:
            comp_options = ["ë™ì¼ í¸ì„±", "ì „ì²´", "ì›”í™”", "ìˆ˜ëª©", "í† ì¼", "í‰ì¼"]
            default_comp = "í‰ì¼" if (base_ip_prog == "ìˆ˜ëª©") else "ë™ì¼ í¸ì„±"
            comp_type = st.selectbox(
                "í¸ì„± ê¸°ì¤€",
                comp_options,
                index=comp_options.index(default_comp),
                key="comp_prog_page4",
                label_visibility="collapsed"
            )
            use_same_prog = (comp_type == "ë™ì¼ í¸ì„±")
        with filter_cols[3]:
            selected_years = st.multiselect(
                "ë°©ì˜ ì—°ë„", all_years, default=default_year_list,
                key="comp_year_page4", placeholder="ì—°ë„ ì„ íƒ", label_visibility="collapsed"
            )
        
        target_rows = df_all[df_all["IP"] == selected_ip1]
        ep_opts = ["ì „ì²´"] + get_episode_options(target_rows)

        with filter_cols[4]:
            selected_max_ep = st.selectbox("íšŒì°¨ ë²”ìœ„", ep_opts, index=0, label_visibility="collapsed")

    st.divider()

    # --- ë°ì´í„° ì¤€ë¹„ ë° í•„í„°ë§ (ì´í•˜ ë¡œì§ ê¸°ì¡´ê³¼ ë™ì¼) ---
    if not selected_ip1:
        st.info("ê¸°ì¤€ IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    ep_limit = None
    if selected_max_ep != "ì „ì²´":
        try: ep_limit = float(re.findall(r'\d+', str(selected_max_ep))[0])
        except: ep_limit = None
            
    kpi_percentiles = get_kpi_data_for_all_ips(df_all, max_ep=ep_limit)

    df_target = df_all[df_all["IP"] == selected_ip1].copy()
    if ep_limit is not None:
        df_target = df_target[df_target["íšŒì°¨_numeric"] <= ep_limit]
    
    kpis_target = get_agg_kpis_for_ip_page4(df_target)

    if comparison_mode == "IP vs ê·¸ë£¹ í‰ê· ":
        group_name_parts = []
        df_comp = df_all.copy()
        ip_prog = df_target["í¸ì„±"].dropna().mode().iloc[0] if not df_target["í¸ì„±"].dropna().empty else None

        # í¸ì„± ê¸°ì¤€ í•„í„°(ì—†ìœ¼ë©´ ì „ì²´)
        comp_prog_filter = None
        if comp_type == "í‰ì¼":
            comp_prog_filter = ["ì›”í™”", "ìˆ˜ëª©"]
        elif comp_type in ["ì›”í™”", "ìˆ˜ëª©", "í† ì¼"]:
            comp_prog_filter = [comp_type]
        elif comp_type == "ë™ì¼ í¸ì„±":
            comp_prog_filter = [ip_prog] if ip_prog else None

        if comp_prog_filter is not None:
            if (comp_type == "ë™ì¼ í¸ì„±") and (not ip_prog):
                st.warning("í¸ì„± ì •ë³´ ì—†ìŒ (ì œì™¸)")
            else:
                df_comp = df_comp[df_comp["í¸ì„±"].isin(comp_prog_filter)]

                if comp_type == "í‰ì¼":
                    group_name_parts.append("'í‰ì¼(ì›”í™”+ìˆ˜ëª©)'")
                elif comp_type in ["ì›”í™”", "ìˆ˜ëª©", "í† ì¼"]:
                    group_name_parts.append(f"'{comp_type}'")
                elif comp_type == "ë™ì¼ í¸ì„±" and ip_prog:
                    group_name_parts.append(f"'{ip_prog}'")

        if selected_years:
            df_comp = df_comp[df_comp["í¸ì„±ì—°ë„"].isin(selected_years)]
            if len(selected_years) <= 3:
                years_str = ",".join(map(str, sorted(selected_years)))
                group_name_parts.append(f"{years_str}")
            else:
                try: group_name_parts.append(f"{min(selected_years)}~{max(selected_years)}")
                except: group_name_parts.append("ì„ íƒì—°ë„")
        
        if not group_name_parts: group_name_parts.append("ì „ì²´")
        comp_name = " & ".join(group_name_parts) + " í‰ê· "

        if ep_limit is not None:
             df_comp = df_comp[df_comp["íšŒì°¨_numeric"] <= ep_limit]

        kpis_comp = get_agg_kpis_for_ip_page4(df_comp)
        
        ranks = {}
        def _calc_rank_in_group(df_g, target_val, metric_key, higher_good=True):
            if df_g.empty: return (None, 0)
            if metric_key in ["Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", "í™”ì œì„± ì ìˆ˜"]:
                agg = df_g[df_g["metric"] == (metric_key if metric_key != "í™”ì œì„± ì ìˆ˜" else "F_Score")]
                if agg.empty: return (None, 0)
                ep_agg = agg.groupby(["IP", "íšŒì°¨_numeric"])["value"].mean().reset_index()
                ip_series = ep_agg.groupby("IP")["value"].mean()
            elif metric_key in ["TVING VOD", "TVING LIVE"]:
                media_target = ["TVING LIVE"] if metric_key == "TVING LIVE" else ["TVING VOD", "TVING QUICK"]
                agg = df_g[(df_g["metric"] == "ì‹œì²­ì¸êµ¬") & (df_g["ë§¤ì²´"].isin(media_target))]
                if agg.empty: return (None, 0)
                ep_agg = agg.groupby(["IP", "íšŒì°¨_numeric"])["value"].sum().reset_index()
                ip_series = ep_agg.groupby("IP")["value"].mean()
            elif metric_key in ["ë””ì§€í„¸ ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰"]:
                if metric_key == "ë””ì§€í„¸ ì¡°íšŒìˆ˜": agg = _get_view_data(df_g)
                else: agg = df_g[df_g["metric"] == "ì–¸ê¸‰ëŸ‰"]
                if agg.empty: return (None, 0)
                ip_series = agg.groupby("IP")["value"].sum()
            else: return (None, 0)

            if target_val is not None: ip_series[selected_ip1] = target_val
            if ip_series.empty: return (None, 0)
            ranked = ip_series.rank(method='min', ascending=not higher_good)
            try: return (int(ranked[selected_ip1]), len(ip_series))
            except: return (None, len(ip_series))

        keys_map = {
            "Tì‹œì²­ë¥ ": "Tì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ": "Hì‹œì²­ë¥ ", 
            "TVING LIVE": "TVING LIVE", "TVING VOD": "TVING VOD",
            "ë””ì§€í„¸ ì¡°íšŒìˆ˜": "ë””ì§€í„¸ ì¡°íšŒìˆ˜", "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰": "ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰",
            "í™”ì œì„± ì ìˆ˜": "í™”ì œì„± ì ìˆ˜"
        }
        for k in keys_map:
            val = kpis_target.get(k)
            ranks[k] = _calc_rank_in_group(df_comp, val, k)

        _render_kpi_row_ip_vs_group(kpis_target, kpis_comp, ranks, comp_name)
        _render_unified_charts(df_target, df_comp, selected_ip1, comp_name, kpi_percentiles, comp_color="#aaaaaa")

    else: # IP vs IP
        if not selected_ip2: st.warning("ë¹„êµí•  IPë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."); return
        df_comp = df_all[df_all["IP"] == selected_ip2].copy()
        if ep_limit is not None: df_comp = df_comp[df_comp["íšŒì°¨_numeric"] <= ep_limit]
        kpis_comp = get_agg_kpis_for_ip_page4(df_comp)
        comp_name = selected_ip2
        _render_kpi_row_ip_vs_ip(kpis_target, kpis_comp, selected_ip1, selected_ip2)
        _render_unified_charts(df_target, df_comp, selected_ip1, comp_name, kpi_percentiles, comp_color="#aaaaaa")


# =====================================================

# ---------- [ê³µí†µ] ì„¤ì • ìƒìˆ˜ ----------
EP_CHOICES = [2, 4, 6, 8, 10, 12, 14, 16]
ROW_LABELS = ["S","A","B","C","D"]
COL_LABELS = ["+2","+1","0","-1","-2"]
ABS_SCORE  = {"S":5,"A":4,"B":3,"C":2,"D":1}
SLO_SCORE  = {"+2":5,"+1":4,"0":3,"-1":2,"-2":1}
SLOPE_LABELS = ["+2", "+1", "0", "-1", "-2"]
ABS_NUM = {"S":5, "A":4, "B":3, "C":2, "D":1}
NETFLIX_VOD_FACTOR = 1.4

# ë°©ì˜ì§€í‘œìš© ì •ì˜
METRICS_DEF_BROADCAST = [
    ("ê°€êµ¬ì‹œì²­ë¥ ", "Hì‹œì²­ë¥ ", None),
    ("íƒ€ê¹ƒì‹œì²­ë¥ ", "Tì‹œì²­ë¥ ", None),
    ("TVING LIVE", "ì‹œì²­ì¸êµ¬", "LIVE"),
    ("TVING VOD",  "ì‹œì²­ì¸êµ¬", "VOD"),
]

# ë””ì§€í„¸ìš© ì •ì˜ (Display, Metric, AggFunc, UseSlope)
METRICS_DEF_DIGITAL = [
    ("ì¡°íšŒìˆ˜", "ì¡°íšŒìˆ˜", "sum", True),
    ("í™”ì œì„±", "F_Score", "mean", True),
]

# ---------- [ë°©ì˜ì§€í‘œ] ìºì‹±ëœ ê³„ì‚° í•¨ìˆ˜ ----------
@st.cache_data(show_spinner=False)
def _calc_growth_grades_cached(df_filtered: pd.DataFrame, target_ips: List[str], cutoffs: List[int], ep_cutoff_target: int):
    # 1. ë°ì´í„° ì¤€ë¹„ (Numpy ë³€í™˜ìš© ìºì‹œ)
    ip_metric_cache = {}
    
    def _get_full_series(sub_df, metric, media):
        sub = sub_df[sub_df["metric"] == metric].copy()
        if media == "LIVE":
            sub = sub[sub["ë§¤ì²´"] == "TVING LIVE"]
        elif media == "VOD":
            sub = sub[sub["ë§¤ì²´"] == "TVING VOD"]
            if "ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘" in sub.columns:
                is_netflix = (sub["ë„·í”Œë¦­ìŠ¤í¸ì„±ì‘"] == 1)
                if is_netflix.any():
                    sub.loc[is_netflix, "value"] *= NETFLIX_VOD_FACTOR
        sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
        if sub.empty: return None
        if metric in ["Hì‹œì²­ë¥ ", "Tì‹œì²­ë¥ "]:
            s = sub.groupby("íšŒì°¨_numeric")["value"].mean().reset_index()
        else:
            s = sub.groupby("íšŒì°¨_numeric")["value"].sum().reset_index()
        s = s.sort_values("íšŒì°¨_numeric")
        return s["íšŒì°¨_numeric"].values.astype(float), s["value"].values.astype(float)

    for ip in target_ips:
        ip_metric_cache[ip] = {}
        ip_df = df_filtered[df_filtered["IP"] == ip]
        for disp, metric, media in METRICS_DEF_BROADCAST:
            ip_metric_cache[ip][disp] = _get_full_series(ip_df, metric, media)

    # 2. í†µê³„ ê³„ì‚°
    def _calc_stats(xy_tuple, n_limit):
        if xy_tuple is None: return np.nan, np.nan
        x, y = xy_tuple
        mask = x <= float(n_limit)
        x_sub, y_sub = x[mask], y[mask]
        if len(x_sub) == 0: return np.nan, np.nan
        abs_val = np.mean(y_sub)
        slope = np.polyfit(x_sub, y_sub, 1)[0] if len(x_sub) >= 2 else np.nan
        return abs_val, slope

    # 3. ë“±ê¸‰ ì‚°ì • í—¬í¼
    def _quintile_grade(series, labels):
        s = pd.Series(series).astype(float)
        valid = s.dropna()
        if valid.empty: return pd.Series(index=s.index, data=np.nan)
        ranks = valid.rank(method="average", ascending=False, pct=True)
        bins = [0, .2, .4, .6, .8, 1.0000001]
        idx = np.digitize(ranks.values, bins, right=True) - 1
        idx = np.clip(idx, 0, 4)
        return pd.Series([labels[i] for i in idx], index=valid.index).reindex(s.index)

    def _to_percentile(s):
        return pd.Series(s).astype(float).rank(pct=True) * 100

    evo_rows = []
    base_df = pd.DataFrame()

    for n in cutoffs:
        tmp_rows = []
        for ip in target_ips:
            row = {"IP": ip}
            for disp, _, _ in METRICS_DEF_BROADCAST:
                xy = ip_metric_cache[ip][disp]
                a, s = _calc_stats(xy, n)
                row[f"{disp}_ì ˆëŒ€"] = a
                row[f"{disp}_ê¸°ìš¸ê¸°"] = s
            tmp_rows.append(row)
        
        tmp_df = pd.DataFrame(tmp_rows)
        if tmp_df.empty: continue

        for disp, _, _ in METRICS_DEF_BROADCAST:
            tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ì ˆëŒ€"], ["S","A","B","C","D"])
            tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
            tmp_df[f"{disp}_ì¢…í•©"] = tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")
        
        tmp_df["_ABS_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ì ˆëŒ€"]) for d,_,_ in METRICS_DEF_BROADCAST], axis=1).mean(axis=1)
        tmp_df["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile(tmp_df[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_ in METRICS_DEF_BROADCAST], axis=1).mean(axis=1)
        tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade(tmp_df["_ABS_PCT_MEAN"], ["S","A","B","C","D"])
        tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade(tmp_df["_SLOPE_PCT_MEAN"], SLOPE_LABELS)
        tmp_df["ì¢…í•©ë“±ê¸‰"] = tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")

        if n == ep_cutoff_target:
            base_df = tmp_df.copy()

        for idx, r in tmp_df.iterrows():
            ag = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
            if ag:
                sg = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
                evo_rows.append({
                    "IP": r["IP"], "N": n, "íšŒì°¨ë¼ë²¨": f"{n}íšŒì°¨",
                    "ABS_GRADE": ag, "SLOPE_GRADE": sg, "ABS_NUM": ABS_NUM.get(ag, np.nan)
                })

    return base_df, pd.DataFrame(evo_rows)


# ---------- [ë©”ì¸] í†µí•© ë Œë”ë§ í•¨ìˆ˜ ----------
def render_growth_score():
    df_all = load_data().copy()
    all_ip_list = sorted(df_all["IP"].dropna().unique().tolist())
    if not all_ip_list:
        st.warning("IP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    # ìŠ¤íƒ€ì¼ ì£¼ì…
    st.markdown("""
    <style>
      div[data-testid="stVerticalBlockBorderWrapper"]:has(.growth-kpi) .kpi-card {
          border-radius:16px;border:1px solid #e7ebf3;background:#fff;padding:12px 14px;
          box-shadow:0 1px 2px rgba(0,0,0,0.04);
      }
      .growth-kpi .kpi-title{font-size:13px;color:#5b6b83;margin-bottom:4px;font-weight:600}
      .growth-kpi .kpi-value{font-weight:800;letter-spacing:-0.2px}
    </style>
    """, unsafe_allow_html=True)

    # ì „ì—­ IP ì‚¬ìš©
    selected_ip = st.session_state.get("global_ip")
    if not selected_ip or selected_ip not in all_ip_list:
        st.error("IP ì„ íƒ í•„ìš”"); return

    # ë°ì´í„° ì „ì²˜ë¦¬ (íšŒì°¨ ìˆ«ìí˜•)
    if "íšŒì°¨_numeric" not in df_all.columns:
        df_all["íšŒì°¨_numeric"] = df_all["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False).astype(float)

    # --- í—¤ë” & í† ê¸€ ë ˆì´ì•„ì›ƒ ---
    # í˜„ì¬ ë·° ëª¨ë“œ ê°€ì ¸ì˜¤ê¸° (Radioê°€ ë Œë”ë§ë˜ê¸° ì „ì— ê¸°ë³¸ê°’ ì„¤ì • í•„ìš”ì‹œ ì‚¬ìš©, ì—¬ê¸°ì„  Radioê°€ Stateë¥¼ ì œì–´)
    current_view = st.session_state.get("growth_view_mode", "ë°©ì˜ì§€í‘œ")
    
    # ë ˆì´ì•„ì›ƒ ë¶„ê¸° (ë°©ì˜ì§€í‘œëŠ” ë¹„êµê·¸ë£¹ í•„í„°ê°€ ë” ìˆìŒ)
    if current_view == "ë°©ì˜ì§€í‘œ":
        head = st.columns([5, 3, 3, 2]) # Title, Toggle, CompGroup, EpCutoff
    else:
        head = st.columns([5, 3, 3])    # Title, Toggle, EpCutoff

    # [Col 1] íƒ€ì´í‹€
    _ep_display = st.session_state.get("growth_ep_cutoff", 4)
    with head[0]:
        st.markdown(
            f"<div class='page-title'>ğŸš€ {selected_ip} ì„±ì¥ìŠ¤ì½”ì–´ <span style='font-size:20px;color:#6b7b93'>(~{_ep_display}íšŒ)</span></div>",
            unsafe_allow_html=True
        )

    # [Col 2] ë·° ëª¨ë“œ í† ê¸€
    with head[1]:
        view_mode = st.radio(
            "ì§€í‘œ ì„ íƒ", ["ë°©ì˜ì§€í‘œ", "ë””ì§€í„¸"], 
            index=0, horizontal=True, 
            key="growth_view_mode", label_visibility="collapsed"
        )

    # [ê³µí†µ] ì•ˆë‚´ ë¬¸êµ¬
    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        if view_mode == "ë°©ì˜ì§€í‘œ":
            st.markdown("""
            **ë“±ê¸‰ ì²´ê³„**
            - **ì ˆëŒ€ê°’ ë“±ê¸‰**: í•­ëª©ë³„ ìˆ˜ì¹˜ ìˆœìœ„ â†’ `S / A / B / C / D`
            - **ìƒìŠ¹ë¥  ë“±ê¸‰**: í•­ëª©ë³„ íšŒì°¨ë³„ ì¦ê°ì •ë„ ìˆœìœ„ â†’ `+2 / +1 / 0 / -1 / -2`
            - **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€ê°’ + ìƒìŠ¹ë¥  (ì˜ˆ: `A+2`).
            **ë³´ì •ê¸°ì¤€**
            - ë„·í”Œë¦­ìŠ¤ í¸ì„±ì‘í’ˆì€ TVING VOD ìˆ˜ì¹˜ë¥¼ ì•½ 40% ë³´ì •
            """)
        else:
            st.markdown("""
            **ë“±ê¸‰ ì²´ê³„**
            - **ì ˆëŒ€ê°’ ë“±ê¸‰**: ê° í•­ëª©ë³„(ë””ì§€í„¸ì¡°íšŒ, í™”ì œì„±ì ìˆ˜) ìˆ˜ì¹˜ë¥¼ ë¹„êµêµ° ë‚´ ìˆœìœ„í™”â†’ `S / A / B / C / D`
            - **ìƒìŠ¹ë¥  ë“±ê¸‰**: ê° í•­ëª©ë³„ì˜ ì£¼ì°¨ë³„ ì¦ê°ì •ë„ë¥¼ ë¹„êµêµ° ë‚´ ìˆœìœ„í™” â†’ `+2 / +1 / 0 / -1 / -2`
            - **ì¢…í•©ë“±ê¸‰**: ì ˆëŒ€ê°’ê³¼ ìƒìŠ¹ë¥  ë“±ê¸‰ì„ ê²°í•©í•´ í‘œê¸° (ì˜ˆ: A+2).  
            """)

    # =========================================================
    # [CASE 1] ë°©ì˜ì§€í‘œ ë¡œì§
    # =========================================================
    if view_mode == "ë°©ì˜ì§€í‘œ":
        # [Col 3, 4] ì¶”ê°€ í•„í„°
        with head[2]:
            comp_group_mode = st.selectbox("ë¹„êµ ê·¸ë£¹", ["ì „ì²´ ë¹„êµ", "ë™ì¼ í¸ì„±ë§Œ"], index=0, key="growth_comp_mode", label_visibility="collapsed")
        with head[3]:
            ep_cutoff = st.selectbox("íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1, key="growth_ep_cutoff", label_visibility="collapsed")

        # IP í•„í„°ë§
        ips = all_ip_list[:]
        if comp_group_mode == "ë™ì¼ í¸ì„±ë§Œ":
            target_info = df_all[df_all["IP"] == selected_ip]
            if not target_info.empty:
                target_prog = target_info["í¸ì„±"].dropna().mode()
                if not target_prog.empty:
                    prog_val = target_prog.iloc[0]
                    ips = sorted(df_all[df_all["í¸ì„±"] == prog_val]["IP"].unique().tolist())
                    if selected_ip not in ips: ips.append(selected_ip)
                    st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸° (ë¹„êµêµ°: {prog_val} / ì´ {len(ips)}ì‘í’ˆ)</span>", unsafe_allow_html=True)
                else:
                    st.warning(f"'{selected_ip}'ì˜ í¸ì„± ì •ë³´ê°€ ì—†ì–´ ì „ì²´ IPì™€ ë¹„êµí•©ë‹ˆë‹¤.")
            else:
                st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>", unsafe_allow_html=True)
        else:
            st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸° (ì „ì²´ ë¹„êµ / ì´ {len(ips)}ì‘í’ˆ)</span>", unsafe_allow_html=True)

        # ë°ì´í„° ì¤€ë¹„ ë° ê³„ì‚° (Loop ìµœì í™”)
        sel_ip_row = df_all[df_all["IP"] == selected_ip]
        _max_ep_val = pd.to_numeric(sel_ip_row["íšŒì°¨_numeric"], errors="coerce").max() if not sel_ip_row.empty else 0
        
        if pd.isna(_max_ep_val) or _max_ep_val == 0: _Ns = [min(EP_CHOICES)]
        else: _Ns = [n for n in EP_CHOICES if n <= _max_ep_val]
        
        needed_cutoffs = sorted(list(set(_Ns) | {ep_cutoff}))
        df_filtered = df_all[df_all["IP"].isin(ips)].copy()

        # [í•µì‹¬] ê³„ì‚° ì‹¤í–‰
        base, evo_all = _calc_growth_grades_cached(df_filtered, ips, needed_cutoffs, ep_cutoff)

        if base.empty: st.error("ë°ì´í„° ê³„ì‚° ì‹¤íŒ¨"); return
        try:
            focus = base[base["IP"] == selected_ip].iloc[0]
        except IndexError: st.error("ë°ì´í„° ê³„ì‚° ì˜¤ë¥˜"); return

        # [UI] ìš”ì•½ ì¹´ë“œ
        st.markdown("<div class='growth-kpi'>", unsafe_allow_html=True)
        card_cols = st.columns([2, 1, 1, 1, 1])
        with card_cols[0]:
            st.markdown(f"""
                <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
                  <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
                  <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
                </div>""", unsafe_allow_html=True)
        
        def _grade_card(col, title, val):
            with col:
                st.markdown(f"""<div class="kpi-card" style="height:110px;"><div class="kpi-title">{title}</div><div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div></div>""", unsafe_allow_html=True)
        
        _grade_card(card_cols[1], "ê°€êµ¬ì‹œì²­ë¥  ë“±ê¸‰", focus["ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©"])
        _grade_card(card_cols[2], "íƒ€ê¹ƒì‹œì²­ë¥  ë“±ê¸‰", focus["íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©"])
        _grade_card(card_cols[3], "TVING LIVE ë“±ê¸‰", focus["TVING LIVE_ì¢…í•©"])
        _grade_card(card_cols[4], "TVING VOD ë“±ê¸‰",  focus["TVING VOD_ì¢…í•©"])
        st.markdown("</div>", unsafe_allow_html=True)
        st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)

        # [UI] ë“±ê¸‰ ì¶”ì´ ê·¸ë˜í”„
        evo_ip = evo_all[evo_all["IP"] == selected_ip].copy() if not evo_all.empty else pd.DataFrame()
        if not evo_ip.empty:
            fig_e = go.Figure()
            fig_e.add_vrect(x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5, fillcolor="rgba(0,90,200,0.12)", line_width=0)
            fig_e.add_trace(go.Scatter(x=evo_ip["N"], y=evo_ip["ABS_NUM"], mode="lines+markers", line=dict(shape="spline", width=3), marker=dict(size=8), name=selected_ip, hoverinfo="skip"))
            for xi, yi, ag, sg in zip(evo_ip["N"], evo_ip["ABS_NUM"], evo_ip["ABS_GRADE"], evo_ip["SLOPE_GRADE"]):
                label = f"{ag}{sg}" if isinstance(ag, str) and sg else ag
                fig_e.add_annotation(x=xi, y=yi, text=label, showarrow=False, font=dict(size=12, color="#333", family="sans-serif"), yshift=14)
            fig_e.update_xaxes(tickmode="array", tickvals=evo_ip["N"].tolist(), ticktext=[f"{int(n)}íšŒì°¨" for n in evo_ip["N"].tolist()], showgrid=False, zeroline=False, showline=False)
            fig_e.update_yaxes(tickmode="array", tickvals=[5,4,3,2,1], ticktext=["S","A","B","C","D"], range=[0.7, 5.3], showgrid=False, zeroline=False, showline=False)
            fig_e.update_layout(height=200, margin=dict(l=8, r=8, t=8, b=8), showlegend=False)
            st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})
        
        st.divider()

        # [UI] í¬ì§€ì…”ë‹ ë§µ & ì „ì²´ í‘œ
        # (ê¸°ì¡´ ë¡œì§ ë™ì¼ - ê°„ëµí™” ìœ„í•´ ì¼ë¶€ ê³µí†µ í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜ ì›ë³¸ ìœ ì§€)
        pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
        for _, r in base.iterrows():
            ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
            rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
            if ra in ROW_LABELS and rs in COL_LABELS: pos_map[(ra, rs)].append(r["IP"])

        z = [[(ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0 for cc in COL_LABELS] for rr in ROW_LABELS]
        fig = px.imshow(z, x=COL_LABELS, y=ROW_LABELS, origin="upper", color_continuous_scale="Blues", range_color=[1, 5], text_auto=False, aspect="auto").update_traces(xgap=0.0, ygap=0.0)
        fig.update_xaxes(showticklabels=False, title=None, ticks="")
        fig.update_yaxes(showticklabels=False, title=None, ticks="")
        fig.update_layout(height=760, margin=dict(l=2, r=2, t=2, b=2), coloraxis_showscale=False)
        fig.update_traces(hovertemplate="<extra></extra>")

        for r_idx, rr in enumerate(ROW_LABELS):
            for c_idx, cc in enumerate(COL_LABELS):
                cell_val = z[r_idx][c_idx]
                names = pos_map[(rr, cc)]
                color = "#FFFFFF" if cell_val >= 3.3 else "#111111"
                fig.add_annotation(x=cc, y=rr, xref="x", yref="y", text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>", showarrow=False, font=dict(size=22, color=color, family="sans-serif"), xanchor="center", yanchor="top", yshift=80)
                if names: fig.add_annotation(x=cc, y=rr, xref="x", yref="y", text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>", showarrow=False, font=dict(size=12, color=color, family="sans-serif"), xanchor="center", yanchor="middle", yshift=6)
        
        st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

        # AgGrid
        table_view = base[["IP","ì¢…í•©ë“±ê¸‰","ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©","TVING LIVE_ì¢…í•©","TVING VOD_ì¢…í•©"]].rename(columns={"ì¢…í•©ë“±ê¸‰":"ì¢…í•©","ê°€êµ¬ì‹œì²­ë¥ _ì¢…í•©":"ê°€êµ¬ì‹œì²­ë¥ ","íƒ€ê¹ƒì‹œì²­ë¥ _ì¢…í•©":"íƒ€ê¹ƒì‹œì²­ë¥ ","TVING LIVE_ì¢…í•©":"TVING LIVE","TVING VOD_ì¢…í•©":"TVING VOD"})
        
        grade_cell = JsCode("""function(params){ try{ const raw=params.value; if(raw==null)return{'text-align':'center'}; const v=String(raw); let bg=null,color=null,fw='700'; if(v.startsWith('S')){bg='rgba(0,91,187,0.14)';color='#003d80';}else if(v.startsWith('A')){bg='rgba(0,91,187,0.08)';color='#004a99';}else if(v.startsWith('B')){bg='rgba(0,0,0,0.03)';color='#333';fw='600';}else if(v.startsWith('C')){bg='rgba(42,97,204,0.08)';color='#2a61cc';}else if(v.startsWith('D')){bg='rgba(42,97,204,0.14)';color='#1a44a3';} return{'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'}; }catch(e){return{'text-align':'center'};} }""")
        
        gb = GridOptionsBuilder.from_dataframe(table_view.fillna("â€“"))
        gb.configure_default_column(resizable=True, sortable=True, filter=False, headerClass='centered-header bold-header', cellStyle={'textAlign':'center'})
        gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
        for colname in ["ì¢…í•©","ê°€êµ¬ì‹œì²­ë¥ ","íƒ€ê¹ƒì‹œì²­ë¥ ","TVING LIVE","TVING VOD"]: gb.configure_column(colname, cellStyle=grade_cell, width=120)
        
        st.markdown("#### ğŸ“‹ IPì „ì²´")
        AgGrid(table_view.fillna("â€“"), gridOptions=gb.build(), theme="streamlit", height=420, fit_columns_on_grid_load=True, update_mode=GridUpdateMode.NO_UPDATE, allow_unsafe_jscode=True)

    # =========================================================
    # [CASE 2] ë””ì§€í„¸ ë¡œì§
    # =========================================================
    else:
        # [Col 3] í•„í„°
        with head[2]:
            ep_cutoff = st.selectbox("íšŒì°¨ ê¸°ì¤€", EP_CHOICES, index=1, key="growth_d_ep_cutoff", label_visibility="collapsed")
            
        st.markdown(f"#### {selected_ip} <span style='font-size:16px;color:#6b7b93'>ìì„¸íˆë³´ê¸°</span>", unsafe_allow_html=True)
        
        ips = all_ip_list
        
        # --- [Logic] ë””ì§€í„¸ìš© ê³„ì‚° í—¬í¼ (ë¡œì»¬ ì •ì˜) ---
        def _get_full_series_digital(ip_df, metric_name, mtype):
            if metric_name == "ì¡°íšŒìˆ˜": sub = _get_view_data(ip_df)
            else: sub = ip_df[ip_df["metric"] == metric_name].copy()
            sub["value"] = pd.to_numeric(sub["value"], errors="coerce").replace(0, np.nan)
            sub = sub.dropna(subset=["value", "íšŒì°¨_numeric"])
            if sub.empty: return None
            if mtype == "sum": s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].sum()
            else: s = sub.groupby("íšŒì°¨_numeric", as_index=False)["value"].mean()
            s = s.sort_values("íšŒì°¨_numeric")
            return s["íšŒì°¨_numeric"].values.astype(float), s["value"].values.astype(float)
            
        def _calc_stats_digital(xy_tuple, n_cutoff, use_slope):
            if xy_tuple is None: return np.nan, np.nan
            x, y = xy_tuple
            mask = (x >= 1) & (x <= float(n_cutoff))
            x_sub, y_sub = x[mask], y[mask]
            if len(x_sub) == 0: return np.nan, np.nan
            abs_val = float(np.nanmean(y_sub))
            slope = float(np.polyfit(x_sub, y_sub, 1)[0]) if (use_slope and len(x_sub) >= 2) else np.nan
            return abs_val, slope

        def _quintile_grade_d(series, labels):
            s = pd.Series(series).astype(float)
            valid = s.dropna()
            if valid.empty: return pd.Series(index=s.index, data=np.nan)
            ranks = valid.rank(method="average", ascending=False, pct=True)
            bins = [0, .2, .4, .6, .8, 1.0000001]
            idx = np.digitize(ranks.values, bins, right=True) - 1
            idx = np.clip(idx, 0, 4)
            return pd.Series([labels[i] for i in idx], index=valid.index).reindex(s.index)

        def _to_percentile_d(s):
            return pd.Series(s).astype(float).rank(pct=True) * 100

        # --- ê³„ì‚° ì‹¤í–‰ ---
        # 1. IPë³„ Series ìºì‹±
        ip_metric_cache = {}
        for ip in ips:
            ip_metric_cache[ip] = {}
            curr_df = df_all[df_all["IP"] == ip]
            for disp, metric_name, mtype, _ in METRICS_DEF_DIGITAL:
                ip_metric_cache[ip][disp] = _get_full_series_digital(curr_df, metric_name, mtype)

        # 2. ë£¨í”„ ê³„ì‚°
        sel_ip_df = df_all[df_all["IP"] == selected_ip]
        _max_ep_val = pd.to_numeric(sel_ip_df["íšŒì°¨_numeric"], errors="coerce").max() if not sel_ip_df.empty else 0
        if pd.isna(_max_ep_val) or _max_ep_val == 0: _Ns = [min(EP_CHOICES)]
        else: _Ns = [n for n in EP_CHOICES if n <= _max_ep_val]
        
        sorted_cutoffs = sorted(list(set(_Ns) | {ep_cutoff}))
        evo_rows = []
        base = pd.DataFrame() # ì´ˆê¸°í™”

        for n in sorted_cutoffs:
            tmp_rows = []
            for ip in ips:
                row = {"IP": ip}
                for disp, _, _, use_slope in METRICS_DEF_DIGITAL:
                    xy = ip_metric_cache[ip][disp]
                    abs_v, slope_v = _calc_stats_digital(xy, n, use_slope)
                    row[f"{disp}_ì ˆëŒ€"] = abs_v
                    row[f"{disp}_ê¸°ìš¸ê¸°"] = slope_v
                tmp_rows.append(row)
            
            tmp_df = pd.DataFrame(tmp_rows)
            for disp, _, _, _ in METRICS_DEF_DIGITAL:
                tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade_d(tmp_df[f"{disp}_ì ˆëŒ€"], ["S","A","B","C","D"])
                tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade_d(tmp_df[f"{disp}_ê¸°ìš¸ê¸°"], SLOPE_LABELS)
                tmp_df[f"{disp}_ì¢…í•©"] = tmp_df[f"{disp}_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df[f"{disp}_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")
            
            tmp_df["_ABS_PCT_MEAN"] = pd.concat([_to_percentile_d(tmp_df[f"{d}_ì ˆëŒ€"]) for d,_,_,_ in METRICS_DEF_DIGITAL], axis=1).mean(axis=1)
            tmp_df["_SLOPE_PCT_MEAN"] = pd.concat([_to_percentile_d(tmp_df[f"{d}_ê¸°ìš¸ê¸°"]) for d,_,_,_ in METRICS_DEF_DIGITAL], axis=1).mean(axis=1)
            tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"] = _quintile_grade_d(tmp_df["_ABS_PCT_MEAN"], ["S","A","B","C","D"])
            tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"] = _quintile_grade_d(tmp_df["_SLOPE_PCT_MEAN"], SLOPE_LABELS)
            tmp_df["ì¢…í•©ë“±ê¸‰"] = tmp_df["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"].astype(str) + tmp_df["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"].astype(str).replace("nan", "")

            if n == ep_cutoff:
                base = tmp_df.copy()

            if n in _Ns:
                row = tmp_df[tmp_df["IP"] == selected_ip]
                if not row.empty and pd.notna(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]):
                    ag = str(row.iloc[0]["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"])
                    sg = str(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(row.iloc[0]["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else ""
                    evo_rows.append({ "N": n, "ABS_GRADE": ag, "SLOPE_GRADE": sg, "ABS_NUM": ABS_NUM.get(ag, np.nan) })
        
        # [UI] ìš”ì•½ ì¹´ë“œ
        if base.empty: st.error("ê³„ì‚° ê²°ê³¼ ì—†ìŒ"); return
        focus = base[base["IP"] == selected_ip].iloc[0]

        st.markdown("<div class='growth-kpi'>", unsafe_allow_html=True)
        card_cols = st.columns([2, 1, 1, 1, 1])
        with card_cols[0]:
            st.markdown(f"""
                <div class="kpi-card" style="height:110px;border:2px solid #004a99;background:linear-gradient(180deg,#e8f0ff, #ffffff);">
                  <div class="kpi-title" style="font-size:15px;color:#003d80;">ì¢…í•©ë“±ê¸‰</div>
                  <div class="kpi-value" style="font-size:40px;color:#003d80;">{focus['ì¢…í•©ë“±ê¸‰'] if pd.notna(focus['ì¢…í•©ë“±ê¸‰']) else 'â€“'}</div>
                </div>""", unsafe_allow_html=True)
        def _grade_card(col, title, val):
            with col: st.markdown(f"""<div class="kpi-card" style="height:110px;"><div class="kpi-title">{title}</div><div class="kpi-value" style="font-size:28px;">{val if pd.notna(val) else 'â€“'}</div></div>""", unsafe_allow_html=True)
        
        _grade_card(card_cols[1], "ì¡°íšŒìˆ˜ ë“±ê¸‰", focus["ì¡°íšŒìˆ˜_ì¢…í•©"])
        _grade_card(card_cols[2], "í™”ì œì„± ë“±ê¸‰", focus["í™”ì œì„±_ì¢…í•©"])
        _grade_card(card_cols[3], " ", " ")
        _grade_card(card_cols[4], " ", " ")
        st.markdown("</div>", unsafe_allow_html=True)
        st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)

        # [UI] ë“±ê¸‰ ì¶”ì´ ê·¸ë˜í”„
        # ìœ íš¨ íšŒì°¨ í™•ì¸
        _v_view = _get_view_data(df_all[df_all["IP"] == selected_ip])
        _v_view["ep"] = pd.to_numeric(_v_view["íšŒì°¨_numeric"] if "íšŒì°¨_numeric" in _v_view.columns else _v_view["íšŒì°¨"].astype(str).str.extract(r"(\d+)", expand=False), errors="coerce")
        _v_view["val"] = pd.to_numeric(_v_view["value"], errors="coerce").replace(0, np.nan)
        has_ep1 = bool(_v_view.loc[_v_view["ep"] == 1, "val"].notna().any())
        has_ep2 = bool(_v_view.loc[_v_view["ep"] == 2, "val"].notna().any())

        evo = pd.DataFrame(evo_rows)
        if not evo.empty:
            fig_e = go.Figure()
            fig_e.add_vrect(x0=ep_cutoff - 0.5, x1=ep_cutoff + 0.5, fillcolor="rgba(0,90,200,0.12)", line_width=0)
            fig_e.add_trace(go.Scatter(x=evo["N"], y=evo["ABS_NUM"], mode="lines+markers", line=dict(shape="spline", width=3), marker=dict(size=8), name=selected_ip, hoverinfo="skip"))
            for xi, yi, ag, sg in zip(evo["N"], evo["ABS_NUM"], evo["ABS_GRADE"], evo["SLOPE_GRADE"]):
                label = f"{ag}{sg}" if isinstance(ag, str) and sg else ag
                if int(xi) == 2 and (not has_ep1 or not has_ep2): label = "-"
                fig_e.add_annotation(x=xi, y=yi, text=label, showarrow=False, font=dict(size=12, color="#333", family="sans-serif"), yshift=14)
            fig_e.update_xaxes(tickmode="array", tickvals=evo["N"].tolist(), ticktext=[f"{int(n)}íšŒì°¨" for n in evo["N"].tolist()], showgrid=False, zeroline=False, showline=False)
            fig_e.update_yaxes(tickmode="array", tickvals=[5,4,3,2,1], ticktext=["S","A","B","C","D"], range=[0.7, 5.3], showgrid=False, zeroline=False, showline=False)
            fig_e.update_layout(height=200, margin=dict(l=8, r=8, t=8, b=8), showlegend=False)
            st.plotly_chart(fig_e, use_container_width=True, config={"displayModeBar": False})
        
        st.divider()

        # [UI] í¬ì§€ì…”ë‹ ë§µ (ë””ì§€í„¸)
        pos_map = {(r, c): [] for r in ROW_LABELS for c in COL_LABELS}
        for _, r in base.iterrows():
            ra = str(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ì ˆëŒ€ë“±ê¸‰"]) else None
            rs = str(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) if pd.notna(r["ì¢…í•©_ìƒìŠ¹ë“±ê¸‰"]) else None
            if ra in ROW_LABELS and rs in COL_LABELS: pos_map[(ra, rs)].append(r["IP"])

        z = [[(ABS_SCORE[rr] + SLO_SCORE[cc]) / 2.0 for cc in COL_LABELS] for rr in ROW_LABELS]
        fig = px.imshow(z, x=COL_LABELS, y=ROW_LABELS, origin="upper", color_continuous_scale="Blues", range_color=[1, 5], text_auto=False, aspect="auto").update_traces(xgap=0.0, ygap=0.0)
        fig.update_xaxes(showticklabels=False, title=None, ticks="")
        fig.update_yaxes(showticklabels=False, title=None, ticks="")
        fig.update_layout(height=760, margin=dict(l=2, r=2, t=2, b=2), coloraxis_showscale=False)
        fig.update_traces(hovertemplate="<extra></extra>")

        for r_idx, rr in enumerate(ROW_LABELS):
            for c_idx, cc in enumerate(COL_LABELS):
                cell_val = z[r_idx][c_idx]
                names = pos_map[(rr, cc)]
                color = "#FFFFFF" if cell_val >= 3.3 else "#111111"
                fig.add_annotation(x=cc, y=rr, xref="x", yref="y", text=f"<b style='letter-spacing:0.5px'>{rr}{cc}</b>", showarrow=False, font=dict(size=22, color=color, family="sans-serif"), xanchor="center", yanchor="top", yshift=80)
                if names: fig.add_annotation(x=cc, y=rr, xref="x", yref="y", text=f"<span style='line-height:1.04'>{'<br>'.join(names)}</span>", showarrow=False, font=dict(size=12, color=color, family="sans-serif"), xanchor="center", yanchor="middle", yshift=6)

        st.markdown("#### ğŸ—ºï¸ í¬ì§€ì…”ë‹ë§µ")
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

        # AgGrid (ë””ì§€í„¸)
        table_view = base[["IP","ì¢…í•©ë“±ê¸‰","ì¡°íšŒìˆ˜_ì¢…í•©","í™”ì œì„±_ì¢…í•©"]].rename(columns={"ì¢…í•©ë“±ê¸‰":"ì¢…í•©","ì¡°íšŒìˆ˜_ì¢…í•©":"ì¡°íšŒìˆ˜","í™”ì œì„±_ì¢…í•©":"í™”ì œì„±"})
        grade_cell = JsCode("""function(params){ try{ const raw=params.value; if(raw==null)return{'text-align':'center'}; const v=String(raw); let bg=null,color=null,fw='700'; if(v.startsWith('S')){bg='rgba(0,91,187,0.14)';color='#003d80';}else if(v.startsWith('A')){bg='rgba(0,91,187,0.08)';color='#004a99';}else if(v.startsWith('B')){bg='rgba(0,0,0,0.03)';color='#333';fw='600';}else if(v.startsWith('C')){bg='rgba(42,97,204,0.08)';color='#2a61cc';}else if(v.startsWith('D')){bg='rgba(42,97,204,0.14)';color='#1a44a3';} return{'background-color':bg,'color':color,'font-weight':fw,'text-align':'center'}; }catch(e){return{'text-align':'center'};} }""")
        gb = GridOptionsBuilder.from_dataframe(table_view.fillna("â€“"))
        gb.configure_default_column(resizable=True, sortable=True, filter=False, headerClass='centered-header bold-header', cellStyle={'textAlign':'center'})
        gb.configure_column("IP", pinned='left', cellStyle={'textAlign':'left','fontWeight':'700'})
        for colname in ["ì¢…í•©","ì¡°íšŒìˆ˜","í™”ì œì„±"]: gb.configure_column(colname, cellStyle=grade_cell, width=120)

        st.markdown("#### ğŸ“‹ IPì „ì²´-ë””ì§€í„¸")
        AgGrid(table_view.fillna("â€“"), gridOptions=gb.build(), theme="streamlit", height=420, fit_columns_on_grid_load=True, update_mode=GridUpdateMode.NO_UPDATE, allow_unsafe_jscode=True)

# =====================================================
# [ìˆ˜ì •] 7. ì‚¬ì „ì§€í‘œ ë¶„ì„ í˜ì´ì§€ ë Œë”ëŸ¬ (v2.3 - ì‹œì‚¬ì§€í‘œ ë°•ìŠ¤ ì œê±°)
def render_pre_launch_analysis():
    df_all = load_data()
    
    # --- 1. ìƒ‰ìƒ ë° ìŠ¤íƒ€ì¼ ì •ì˜ ---
    C_TARGET = "#283593"  # Target (Deep Indigo)
    C_PREV   = "#78909C"  # Previous (Blue Grey)
    C_GROUP  = "#EEEEEE"  # Group (Light Grey)
    
    # --- 2. ë¶„ì„ ëŒ€ìƒ ì§€í‘œ ì„¤ì • ---
    SISA_MAP = {
        "ì‹œì‚¬ì§€í‘œ_ì¥ë¥´": "ì¥ë¥´ ë° ì†Œì¬",
        "ì‹œì‚¬ì§€í‘œ_ìºë¦­í„°": "ìºë¦­í„° ë° ìºìŠ¤íŒ…",
        "ì‹œì‚¬ì§€í‘œ_ì „ê°œ": "ì „ê°œì™€ êµ¬ì„±",
        "ì‹œì‚¬ì§€í‘œ_ê³µê°": "ê³µê°ì„±",
        "ì‹œì‚¬ì§€í‘œ_ê°œì—°ì„±": "ê°œì—°ì„±",
        "ì‹œì‚¬ì§€í‘œ_ëŒ€ì‚¬": "ëŒ€ì‚¬ ë° í‘œí˜„",
        "ì‹œì‚¬ì§€í‘œ_ì—°ì¶œ": "ì—°ì¶œ ë° ì™„ì„±ë„"
    }
    METRICS_SISA = list(SISA_MAP.keys())
    
    WEEKS_DIGITAL = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1"]
    WEEKS_MPI = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1", "W+1", "W+2"]

    # --- 3. ì‚¬ì´ë“œë°” / í—¤ë” ---
    global_ip = st.session_state.get("global_ip")
    if not global_ip or global_ip not in df_all["IP"].unique():
        st.error("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  IPë¥¼ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    filter_cols = st.columns([4, 2, 2])
    with filter_cols[0]:
        st.markdown(f"<div class='page-title'>ğŸŒ± {global_ip} ì‚¬ì „ì§€í‘œ ë¶„ì„</div>", unsafe_allow_html=True)

    with st.expander("â„¹ï¸ ì§€í‘œ ê¸°ì¤€ ì•ˆë‚´", expanded=False):
        st.markdown("<div class='gd-guideline'>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
            **ì‚¬ì „ì§€í‘œ ì•ˆë‚´**
            - **ì‹œì‚¬ì§€í‘œ**: ì‚¬ì „ ì‹œì‚¬ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ í•­ëª©ë³„ í‰ê°€ ì ìˆ˜ (5ì  ë§Œì )
            - **MPI**: ì´ˆê¸° ì¸ì§€/ì„ í˜¸/ì‹œì²­ì˜í–¥ ì¡°ì‚¬ ê²°ê³¼
            - **ë””ì§€í„¸ ì¡°íšŒ**: ì£¼ê°„ ì›”~ì¼ ì¡°íšŒìˆ˜ ë°œìƒ ì´í•© / ìœ íŠœë¸Œ,ì¸ìŠ¤íƒ€ê·¸ë¨,í‹±í†¡,ë„¤ì´ë²„TV,í˜ì´ìŠ¤ë¶
            - **ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰**: ì£¼ê°„ ì›”~ì¼ ë””ì§€í„¸ ì–¸ê¸‰ëŸ‰ ì´í•© / ì»¤ë®¤ë‹ˆí‹°,íŠ¸ìœ„í„°,ë¸”ë¡œê·¸                     
        """).strip())
        st.markdown("</div>", unsafe_allow_html=True)

    # --- 4. ë¹„êµêµ° í•„í„°ë§ ---
    target_row = df_all[df_all["IP"] == global_ip]
    default_year = []
    default_prog = None
    
    if not target_row.empty:
        if "í¸ì„±ì—°ë„" in target_row.columns:
            ymode = target_row["í¸ì„±ì—°ë„"].dropna().mode()
            if not ymode.empty: default_year = [ymode.iloc[0]]
        default_prog = target_row["í¸ì„±"].dropna().mode().iloc[0] if not target_row["í¸ì„±"].dropna().empty else None

    all_years = sorted(df_all["í¸ì„±ì—°ë„"].dropna().unique().astype(str), reverse=True) if "í¸ì„±ì—°ë„" in df_all.columns else []
    
    with filter_cols[1]:
        sel_years = st.multiselect("ë¹„êµêµ° ì—°ë„", all_years, default=default_year, placeholder="ì—°ë„ ì„ íƒ", label_visibility="collapsed")
    
    with filter_cols[2]:
        comp_prog_opt = st.selectbox("ë¹„êµêµ° í¸ì„± ê¸°ì¤€", ["ë™ì¼ í¸ì„±", "ì „ì²´"], index=0, label_visibility="collapsed")

    # --- 5. ë°ì´í„°ì…‹ ì¤€ë¹„ ---
    df_target = df_all[df_all["IP"] == global_ip].copy()

    df_group = df_all.copy()
    if sel_years:
        df_group = df_group[df_group["í¸ì„±ì—°ë„"].isin(sel_years)]
    if comp_prog_opt == "ë™ì¼ í¸ì„±" and default_prog:
        df_group = df_group[df_group["í¸ì„±"] == default_prog]
    df_group = df_group[df_group["IP"] != global_ip]

    prev_ip_name = get_previous_work_ip(df_all, global_ip)
    df_prev = pd.DataFrame()
    prev_label = "ì „ì‘(ì •ë³´ì—†ìŒ)"
    if prev_ip_name:
        df_prev = df_all[df_all["IP"] == prev_ip_name].copy()
        prev_label = f"ì „ì‘({prev_ip_name})"
    
    group_label = "ê·¸ë£¹ í‰ê· "

    st.divider()

    # --- 6. ì‹œê°í™” í—¬í¼ í•¨ìˆ˜ ---

    # (A) ì‹œì‚¬ì§€í‘œ (Bar)
    def _draw_sisa_bar(metric_list):
        def _get_metric_mean(df, m_list):
            if df.empty: return {m: 0 for m in m_list}
            sub = df[df["metric"].isin(m_list)].copy()
            sub["val"] = pd.to_numeric(sub["value"], errors="coerce")
            grp = sub.groupby("metric")["val"].mean()
            return grp.to_dict()

        val_target = _get_metric_mean(df_target, metric_list)
        val_group  = _get_metric_mean(df_group,  metric_list)
        val_prev   = _get_metric_mean(df_prev,   metric_list)

        data = []
        for m in metric_list:
            display_name = SISA_MAP.get(m, m)
            data.append({"ì§€í‘œ": display_name, "êµ¬ë¶„": group_label, "ê°’": val_group.get(m, 0), "color": C_GROUP})
            data.append({"ì§€í‘œ": display_name, "êµ¬ë¶„": prev_label,  "ê°’": val_prev.get(m, 0),   "color": C_PREV})
            data.append({"ì§€í‘œ": display_name, "êµ¬ë¶„": global_ip,    "ê°’": val_target.get(m, 0), "color": C_TARGET})
        
        plot_df = pd.DataFrame(data)
        
        # [ìˆ˜ì •] ë°•ìŠ¤(.kpi-card) ì œê±°: div íƒœê·¸ ì‚­ì œ
        st.markdown("###### ğŸ“Š ì‹œì‚¬ì§€í‘œ ìƒì„¸")

        if plot_df["ê°’"].sum() == 0:
            st.info("ì‹œì‚¬ì§€í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig = px.bar(
            plot_df, x="ì§€í‘œ", y="ê°’", color="êµ¬ë¶„", barmode="group",
            color_discrete_map={global_ip: C_TARGET, prev_label: C_PREV, group_label: C_GROUP},
            text="ê°’"
        )
        fig.update_traces(
            texttemplate='%{text:.1f}', textposition='outside', width=0.25,
            hovertemplate='%{x}<br>%{data.name}: %{y:.1f}<extra></extra>'
        )
        fig.update_layout(
            height=320, margin=dict(t=20, b=10, l=10, r=10),
            xaxis_title=None, yaxis_title=None,
            
            # [ìˆ˜ì •] ë°°ê²½ ì™„ì „ íˆ¬ëª…í™”
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            
            yaxis=dict(range=[0, 5.5], fixedrange=True, showgrid=True, gridcolor='#f0f0f0'),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, title=None)
        )
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # (B) íŠ¸ë Œë“œ ì°¨íŠ¸ (Line)
    def _fmt_view_detail(x):
        if pd.isna(x) or x == 0: return "0"
        v = int(x)
        uk = v // 100000000
        rem = v % 100000000
        man = rem // 10000
        cheon = (rem % 10000) // 1000
        res = ""
        if uk > 0: res += f"{uk}ì–µ"
        if man > 0: res += f"{man:04d}ë§Œ"
        if cheon > 0: res += f"{cheon:04d}ì²œ"
        if res == "": return f"{v}"
        return res

    def _draw_trend_line_chart(metric_name, title, target_weeks):
        def _fetch_trend_data(df_src, m_name):
            if df_src.empty: return pd.Series(dtype=float)
            if m_name == "ì¡°íšŒìˆ˜":
                sub = _get_view_data(df_src)
            else:
                sub = df_src[df_src["metric"] == m_name].copy()

            if "ì£¼ì°¨" in sub.columns:
                sub = sub[sub["ì£¼ì°¨"].isin(target_weeks)]
            
            sub["val"] = pd.to_numeric(sub["value"], errors="coerce")
            ip_weekly_sum = sub.groupby(["IP", "ì£¼ì°¨"])["val"].sum().reset_index()
            grp = ip_weekly_sum.groupby("ì£¼ì°¨")["val"].mean()
            
            sorter = {k: v for v, k in enumerate(target_weeks)}
            return grp.sort_index(key=lambda x: x.map(sorter))

        s_target = _fetch_trend_data(df_target, metric_name)
        s_group  = _fetch_trend_data(df_group,  metric_name)
        s_prev   = _fetch_trend_data(df_prev,   metric_name)

        if s_target.empty and s_group.empty and s_prev.empty:
            st.info(f"{title} ë°ì´í„° ì—†ìŒ")
            return

        fig = go.Figure()

        if metric_name == "ì¡°íšŒìˆ˜":
            custom_target = [_fmt_view_detail(v) for v in s_target.values]
            custom_group  = [_fmt_view_detail(v) for v in s_group.values]
            custom_prev   = [_fmt_view_detail(v) for v in s_prev.values]
            hover_template = "%{x}<br>%{data.name}: %{customdata}<extra></extra>"
        elif metric_name == "ì–¸ê¸‰ëŸ‰":
            custom_target, custom_group, custom_prev = None, None, None
            hover_template = "%{x}<br>%{data.name}: %{y:,.0f}<extra></extra>"
        else:
            custom_target, custom_group, custom_prev = None, None, None
            hover_template = "%{x}<br>%{data.name}: %{y:.1f}<extra></extra>"

        fig.add_trace(go.Scatter(
            x=s_group.index, y=s_group.values, mode='lines',
            name=group_label, 
            line=dict(color=C_GROUP, width=2),
            hovertemplate=hover_template, customdata=custom_group
        ))
        
        fig.add_trace(go.Scatter(
            x=s_prev.index, y=s_prev.values, mode='lines+markers',
            name=prev_label, 
            line=dict(color=C_PREV, width=2, dash='dot'),
            marker=dict(size=6),
            hovertemplate=hover_template, customdata=custom_prev
        ))

        if metric_name == "ì¡°íšŒìˆ˜":
            text_vals = [f"{int(v/10000)}ë§Œ" if v > 10000 else f"{int(v)}" for v in s_target.values]
        elif metric_name == "ì–¸ê¸‰ëŸ‰":
            text_vals = [f"{v:,.0f}" for v in s_target.values]
        else:
            text_vals = [f"{v:.1f}" for v in s_target.values]

        fig.add_trace(go.Scatter(
            x=s_target.index, y=s_target.values, mode='lines+markers+text',
            name=global_ip, 
            line=dict(color=C_TARGET, width=3),
            marker=dict(size=8, color=C_TARGET),
            text=text_vals, textposition="top center",
            textfont=dict(size=12, color=C_TARGET, weight="bold"),
            hovertemplate=hover_template, customdata=custom_target
        ))

        fig.update_layout(
            title=dict(text=f"ğŸ“ˆ {title}", font=dict(size=15)),
            height=280, margin=dict(t=40, b=20, l=10, r=10),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            xaxis=dict(categoryorder="array", categoryarray=target_weeks, showgrid=False),
            yaxis=dict(showgrid=True, gridcolor='#f0f0f0', zeroline=False, showticklabels=False),
            plot_bgcolor='rgba(0,0,0,0)',
            hovermode="x unified"
        )
        st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    # --- 7. í™”ë©´ ë°°ì¹˜ ---
    _draw_sisa_bar(METRICS_SISA)
    
    st.markdown("---")
    
    st.markdown("###### ğŸ§  MPI ì¶”ì´")
    c_m1, c_m2, c_m3 = st.columns(3)
    with c_m1: _draw_trend_line_chart("MPI_ì¸ì§€", "ì¸ì§€ë„", WEEKS_MPI)
    with c_m2: _draw_trend_line_chart("MPI_ì„ í˜¸", "ì„ í˜¸ë„", WEEKS_MPI)
    with c_m3: _draw_trend_line_chart("MPI_ì‹œì²­ì˜í–¥", "ì‹œì²­ì˜í–¥", WEEKS_MPI)

    st.markdown("---")

    st.markdown("###### ğŸ’» ì‚¬ì „ ë””ì§€í„¸ ë°˜ì‘ (W-6 ~ W-1)")
    c_d1, c_d2 = st.columns(2)
    with c_d1: _draw_trend_line_chart("ì¡°íšŒìˆ˜", "ì¡°íšŒìˆ˜ í•©ê³„", WEEKS_DIGITAL)
    with c_d2: _draw_trend_line_chart("ì–¸ê¸‰ëŸ‰", "ì–¸ê¸‰ëŸ‰ í•©ê³„", WEEKS_DIGITAL)



    # --- 7-1. ğŸ”® W+1 í™”ì œì„±ì ìˆ˜ ì˜ˆì¸¡ (MVP) ---
    # ëª©í‘œ: ì‚¬ìš©ìì—ê²ŒëŠ” 'ì˜ˆì¸¡ê°’ 1ê°œ + ê°„ë‹¨í•œ ê·¼ê±° + (ë°©ì˜ì‘) ì˜ˆì¸¡ vs ì‹¤ì œ'ë§Œ ë³´ì—¬ì¤Œ
    # ì…ë ¥ì€ ì‚¬ì „ì§€í‘œ(W-6~W-1)ë§Œ ì‚¬ìš©í•˜ë©°, ë°ì´í„°ê°€ ëˆ„ì ë˜ë©´ ìë™ìœ¼ë¡œ ì¬í•™ìŠµë¨.

    def _safe_num(s: pd.Series) -> pd.Series:
        return pd.to_numeric(s, errors="coerce").fillna(0)

    def _parse_date_any(x):
        try:
            if pd.isna(x):
                return pd.NaT
            s = str(x).strip()
            if not s:
                return pd.NaT
            # allow 'YYYY. M. D' or 'YYYY-MM-DD'
            s = s.replace(".", "-").replace("/", "-")
            return pd.to_datetime(s, errors="coerce")
        except Exception:
            return pd.NaT

    def build_prelaunch_model_frame(df: pd.DataFrame) -> tuple[pd.DataFrame, list[str], str]:
        """IP ë‹¨ìœ„ í•™ìŠµ í”„ë ˆì„ ìƒì„±.
        - X: ì‹œì‚¬ì§€í‘œ(í•­ëª©ë³„), MPI 3ì¢…(ë‹¤ì£¼ì°¨ ìš”ì•½), ì‚¬ì „ ë””ì§€í„¸(ì¡°íšŒ/ì–¸ê¸‰: ë‹¤ì£¼ì°¨ ìš”ì•½)
        - y: W+1 í™”ì œì„± ì ìˆ˜(F_Score)
        """

        # ---- Meta(í¸ì„±/ì—°ë„/ë°©ì˜ì‹œì‘ ë“±) IP ë‹¨ìœ„ë¡œ ëª¨ìœ¼ê¸° ----
        meta_cols = [c for c in ["í¸ì„±", "í¸ì„±ì—°ë„", "ë°©ì˜ì‹œì‘"] if c in df.columns]
        meta = df.groupby("IP")[meta_cols].first() if meta_cols else pd.DataFrame(index=sorted(df["IP"].unique()))
        if "ë°©ì˜ì‹œì‘" in meta.columns:
            meta["ë°©ì˜ì‹œì‘_dt"] = meta["ë°©ì˜ì‹œì‘"].apply(_parse_date_any)

        # ---- (1) ì‹œì‚¬ì§€í‘œ: í•­ëª©ë³„ í‰ê·  ----
        sisa_keys = list(SISA_MAP.keys())
        s_sub = df[df["metric"].isin(sisa_keys)].copy()
        if not s_sub.empty:
            s_sub["val"] = _safe_num(s_sub["value"])
            sisa_wide = s_sub.pivot_table(index="IP", columns="metric", values="val", aggfunc="mean")
        else:
            sisa_wide = pd.DataFrame(index=meta.index, columns=sisa_keys).fillna(0)

        # ---- (2) MPI 3ì¢…: ì£¼ì°¨ë³„ -> ìš”ì•½ í”¼ì²˜ ----
        # [ì¤‘ìš”] ì¼ë¶€ IPëŠ” W-3ê¹Œì§€ë§Œ ì¡´ì¬í•˜ëŠ” ë“± ì£¼ì°¨ê°€ ëœ ì±„ì›Œì§„ ê²½ìš°ê°€ ìˆìŒ.
        # ì´ë•Œ 'ì¡´ì¬í•˜ëŠ” ì£¼ì°¨ë§Œ' í‰ê· /ê¸°ìš¸ê¸°ë¥¼ ë‚´ë©´ ê³¼ëŒ€í‰ê°€ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
        # í•­ìƒ W-6~W-1ì˜ ê³ ì • 6ì£¼ í”„ë ˆì„ìœ¼ë¡œ ë§ì¶˜ ë’¤(ëˆ„ë½=0) ìš”ì•½ í”¼ì²˜ë¥¼ ë§Œë“ ë‹¤.
        mpi_metrics = ["MPI_ì¸ì§€", "MPI_ì„ í˜¸", "MPI_ì‹œì²­ì˜í–¥"]
        mpi_weeks = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1"]

        mpi_sub = df[(df["metric"].isin(mpi_metrics)) & (df["ì£¼ì°¨"].isin(mpi_weeks))].copy()
        mpi_wide_all = pd.DataFrame(index=meta.index)

        if not mpi_sub.empty:
            mpi_sub["val"] = pd.to_numeric(mpi_sub["value"], errors="coerce")
            mpi_pv = mpi_sub.pivot_table(index="IP", columns=["metric", "ì£¼ì°¨"], values="val", aggfunc="mean")

            for m in mpi_metrics:
                # ê³ ì • 6ì£¼ ì»¬ëŸ¼ í”„ë ˆì„ ìƒì„± (ëˆ„ë½=0)
                fixed_cols = [f"{m}_{w}" for w in mpi_weeks]
                tmp = pd.DataFrame(index=meta.index, columns=fixed_cols, dtype=float).fillna(0.0)

                # ì¡´ì¬í•˜ëŠ” ì£¼ì°¨ë§Œ ì±„ìš°ê¸°
                for w in mpi_weeks:
                    key = (m, w)
                    if key in mpi_pv.columns:
                        tmp[f"{m}_{w}"] = mpi_pv[key].reindex(meta.index).fillna(0.0)

                # level (W-1)
                mpi_wide_all[f"{m}_level_W-1"] = tmp[f"{m}_W-1"]

                # mean level (W-6~W-1)  â€» í•­ìƒ 6ì£¼ í‰ê· 
                mpi_wide_all[f"{m}_mean_W-6_W-1"] = tmp.mean(axis=1)

                # momentum: W-1 - W-3 (ëˆ„ë½=0 ì²˜ë¦¬ í›„ ê³„ì‚°)
                mpi_wide_all[f"{m}_mom_W-1_minus_W-3"] = tmp[f"{m}_W-1"] - tmp[f"{m}_W-3"]

                # slope across fixed weeks (W-6~W-1)
                vals = tmp.values  # shape: (n_ip, 6)
                x = np.arange(vals.shape[1], dtype=float)  # 0..5
                x_mean = x.mean()
                denom = ((x - x_mean) ** 2).sum()
                slope = ((vals * (x - x_mean)).sum(axis=1) / denom) if denom != 0 else np.zeros(vals.shape[0])
                mpi_wide_all[f"{m}_slope_W-6_W-1"] = slope

        mpi_wide_all = mpi_wide_all.fillna(0)

        # ---- (3) ì‚¬ì „ ë””ì§€í„¸: ì¡°íšŒìˆ˜/ì–¸ê¸‰ëŸ‰ ì£¼ì°¨ë³„ -> ìš”ì•½ ----
        dig_weeks = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1"]

        v_sub = _get_view_data(df)
        v_sub = v_sub[v_sub["ì£¼ì°¨"].isin(dig_weeks)].copy() if not v_sub.empty else pd.DataFrame()
        if not v_sub.empty:
            v_sub["val"] = _safe_num(v_sub["value"])
            v_pv = v_sub.pivot_table(index="IP", columns="ì£¼ì°¨", values="val", aggfunc="sum").reindex(meta.index).fillna(0)
        else:
            v_pv = pd.DataFrame(index=meta.index, columns=dig_weeks).fillna(0)

        b_sub = df[(df["metric"] == "ì–¸ê¸‰ëŸ‰") & (df["ì£¼ì°¨"].isin(dig_weeks))].copy()
        if not b_sub.empty:
            b_sub["val"] = _safe_num(b_sub["value"])
            b_pv = b_sub.pivot_table(index="IP", columns="ì£¼ì°¨", values="val", aggfunc="sum").reindex(meta.index).fillna(0)
        else:
            b_pv = pd.DataFrame(index=meta.index, columns=dig_weeks).fillna(0)

        dig_feats = pd.DataFrame(index=meta.index)

        # ì›ë³¸ ì¹´ìš´íŠ¸(ì¡°íšŒ/ì–¸ê¸‰)ëŠ” ìŠ¤ì¼€ì¼ì´ ë§¤ìš° í¬ê³  ë¡±í…Œì¼ì´ì–´ì„œ ê³¼ëŒ€ì˜ˆì¸¡ì„ ìœ ë°œí•˜ê¸° ì‰¬ì›€.
        # â†’ ëª¨ë¸ ì…ë ¥ì€ log1p ë³€í™˜ ë° ëª¨ë©˜í…€ì˜ signed-log ë³€í™˜ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í•œë‹¤.
        view_sum = v_pv.sum(axis=1)
        buzz_sum = b_pv.sum(axis=1)
        view_w1 = v_pv.get("W-1", 0)
        buzz_w1 = b_pv.get("W-1", 0)
        view_mom = v_pv.get("W-1", 0) - v_pv.get("W-3", 0)
        buzz_mom = b_pv.get("W-1", 0) - b_pv.get("W-3", 0)

        dig_feats["log1p_ì¡°íšŒìˆ˜_sum_W-6_W-1"] = np.log1p(view_sum.clip(lower=0))
        dig_feats["log1p_ì–¸ê¸‰ëŸ‰_sum_W-6_W-1"] = np.log1p(buzz_sum.clip(lower=0))
        dig_feats["log1p_ì¡°íšŒìˆ˜_level_W-1"]   = np.log1p(pd.Series(view_w1, index=meta.index).clip(lower=0))
        dig_feats["log1p_ì–¸ê¸‰ëŸ‰_level_W-1"]   = np.log1p(pd.Series(buzz_w1, index=meta.index).clip(lower=0))

        # ëª¨ë©˜í…€ì€ ìŒìˆ˜ë„ ê°€ëŠ¥í•˜ë¯€ë¡œ signed-log1pë¡œ ë³€í™˜
        dig_feats["slog_ì¡°íšŒìˆ˜_mom_W-1_minus_W-3"] = np.sign(view_mom) * np.log1p(np.abs(view_mom))
        dig_feats["slog_ì–¸ê¸‰ëŸ‰_mom_W-1_minus_W-3"] = np.sign(buzz_mom) * np.log1p(np.abs(buzz_mom))

        # ë°ì´í„° ì»¤ë²„ë¦¬ì§€(ì£¼ì°¨ê°€ ëœ ìŒ“ì¸ IPì— ëŒ€í•œ ê³¼ëŒ€ì¶”ì • ì™„í™”ìš©)
        # 0ì´ 'ì‹¤ì œë¡œ 0'ì¼ ìˆ˜ë„ ìˆì§€ë§Œ, ì‚¬ì „ êµ¬ê°„ì—ì„œ ì™„ì „ 0ì´ ë°˜ë³µë˜ë©´ ì •ë³´ê°€ ë¶€ì¡±í•œ ì¼€ì´ìŠ¤ê°€ ë§ì•„ ë³´ì •ì— ë„ì›€ì´ ë¨.
        dig_feats["ì¡°íšŒìˆ˜_week_coverage_W-6_W-1"] = (v_pv.fillna(0) > 0).mean(axis=1)
        dig_feats["ì–¸ê¸‰ëŸ‰_week_coverage_W-6_W-1"] = (b_pv.fillna(0) > 0).mean(axis=1)

        # ---- (4) íƒ€ê¹ƒ: 1ì£¼ì°¨ í™”ì œì„± ì ìˆ˜(F_Score) ----
        target_metric = "F_Score"
        # ë°ì´í„°ì— ë”°ë¼ 1ì£¼ì°¨ í‘œê¸°ê°€ W+1 ë˜ëŠ” W1ì¼ ìˆ˜ ìˆì–´ ìë™ ê°ì§€
        week_candidates = ["W+1", "W1", "W+01", "1ì£¼ì°¨", "1"]
        weeks_avail = set(df["ì£¼ì°¨"].astype(str).unique())
        target_week = next((w for w in week_candidates if w in weeks_avail), "W+1")

        y_sub = df[(df["metric"] == target_metric) & (df["ì£¼ì°¨"] == target_week)].copy()
        if not y_sub.empty:
            y_sub["y"] = pd.to_numeric(y_sub["value"], errors="coerce")
            y = y_sub.groupby("IP")["y"].mean().reindex(meta.index)
        else:
            y = pd.Series(index=meta.index, dtype=float)

        X = pd.concat([sisa_wide.reindex(meta.index).fillna(0), mpi_wide_all, dig_feats], axis=1).fillna(0)
        frame = X.copy()
        frame[f"y_{target_week}_í™”ì œì„±"] = y

        if not meta.empty:
            for c in meta.columns:
                frame[c] = meta[c]
            if "ë°©ì˜ì‹œì‘_dt" in meta.columns:
                frame["ë°©ì˜ì‹œì‘_dt"] = meta["ë°©ì˜ì‹œì‘_dt"]

        feature_cols = list(X.columns)
        return frame.reset_index().rename(columns={"index": "IP"}), feature_cols, f"y_{target_week}_í™”ì œì„±", target_week

    def fit_and_predict_mvp(frame: pd.DataFrame, feature_cols: list[str], target_col: str, target_ip: str):
        """ì˜ˆì¸¡(ìš´ì˜ ë‹¨ìˆœí™”: ALL-TRAIN)

        - í•™ìŠµ: íƒ€ê¹ƒ(ì˜ˆ: F_Score, W1)ì´ ì¡´ì¬í•˜ëŠ” ëª¨ë“  IPë¥¼ ì‚¬ìš©í•´ 1íšŒ í•™ìŠµ
        - ê²€ì¦í‘œ: (ì°¸ê³ ìš©) ë™ì¼ ë°ì´í„° ê¸°ì¤€ ì˜ˆì¸¡ vs ì‹¤ì œë¥¼ ì „ IPì— ëŒ€í•´ í‘œì‹œ
        - ì‹ ê·œ IP: target_ipì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ê°„ë‹¨í•œ ê¸°ì—¬ë„(ì„ í˜• ê³„ìˆ˜ ê¸°ë°˜)ë¥¼ ì œê³µ
        """
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import StandardScaler
        from sklearn.linear_model import Lasso  # ===== ìˆ˜ì •: Ridge -> Lasso =====
        from sklearn.metrics import mean_absolute_error

        # --- counts for UI ---
        total_ip_cnt = int(frame["IP"].nunique()) if "IP" in frame.columns else 0
        # labelled rows (have target)
        trainable = frame[pd.to_numeric(frame[target_col], errors="coerce").notna()].copy()
        trainable[target_col] = pd.to_numeric(trainable[target_col], errors="coerce")
        trainable = trainable.dropna(subset=[target_col])

        target_ip_cnt = int(trainable["IP"].nunique()) if "IP" in trainable.columns else int(trainable.shape[0])
        feature_any_cnt = int(frame[feature_cols].notna().any(axis=1).sum()) if len(feature_cols) > 0 else 0

        # minimum guard (too few supervised labels)
        if trainable.shape[0] < 12:
            meta = {
                "total_ip_cnt": total_ip_cnt,
                "target_ip_cnt": target_ip_cnt,
                "feature_ready_cnt": feature_any_cnt,
                "trainable_rows": int(trainable.shape[0]),
                "note": "insufficient_labels",
            }
            return None, None, None, None, None, meta

        # ----- Fit once on ALL labelled data -----
        model = Pipeline([
            ("scaler", StandardScaler(with_mean=True, with_std=True)),
            ("lasso", Lasso(alpha=0.1, random_state=42)),  # ===== ìˆ˜ì •: Ridge -> Lasso, alpha 0.1 =====
        ])

        X_all = trainable[feature_cols].replace([np.inf, -np.inf], 0).fillna(0)
        y_all_raw = trainable[target_col].values
        # íƒ€ê¹ƒë„ ë¡±í…Œì¼ì´ì–´ì„œ log1pë¡œ í•™ìŠµ í›„ expm1ë¡œ ë³µì›(ê³¼ëŒ€ì˜ˆì¸¡ ì™„í™”)
        y_all = np.log1p(np.clip(y_all_raw, a_min=0, a_max=None))
        model.fit(X_all, y_all)

        # ----- In-sample validation table (reference only) -----
        all_df = trainable.copy()
        all_df["_pred_log"] = model.predict(X_all)
        y_p05, y_p95 = np.percentile(y_all_raw, [5, 95])
        all_df["_pred"] = np.expm1(all_df["_pred_log"]).clip(lower=0)
        all_df["_pred"] = all_df["_pred"].clip(lower=y_p05, upper=y_p95)

        mae = float(mean_absolute_error(all_df[target_col].values, all_df["_pred"].values))

        # ----- Predict for the selected IP (can be pre-launch without label) -----
        pred_ip_val = None
        contrib_df = None
        group_contrib_df = None

        row_ip = frame[frame["IP"] == target_ip].copy()
        if not row_ip.empty:
            x_ip = row_ip[feature_cols].replace([np.inf, -np.inf], 0).fillna(0)

            try:
                pred_ip_val_log = float(model.predict(x_ip)[0])
                pred_ip_val = float(np.expm1(pred_ip_val_log))
                # ì˜ˆì¸¡ê°’ í´ë¦¬í•‘(í•™ìŠµ ë°ì´í„° ë¶„í¬ ê¸°ì¤€) - ê·¹ë‹¨ ê³¼ëŒ€ì˜ˆì¸¡ ë°©ì§€
                y_p05, y_p95 = np.percentile(y_all_raw, [5, 95])
                pred_ip_val = float(np.clip(pred_ip_val, y_p05, y_p95))
                # ì£¼ì°¨ ì»¤ë²„ë¦¬ì§€(ë°ì´í„° ëˆ„ë½) ë³´ì •: W-3ê¹Œì§€ë§Œ ì¡´ì¬ ë“± ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìœ¼ë©´ ì¤‘ì•™ê°’ ìª½ìœ¼ë¡œ ìˆ˜ì¶•
                try:
                    cov_cols = [c for c in x_ip.columns if "week_coverage" in c]
                    cov = float(min([float(x_ip.iloc[0][c]) for c in cov_cols])) if cov_cols else 1.0
                    if cov < 0.75:
                        y_med = float(np.median(y_all_raw))
                        pred_ip_val = float(0.7 * pred_ip_val + 0.3 * y_med)
                except Exception:
                    pass
            except Exception:
                pred_ip_val = None

            # contributions (linear, scaled)
            try:
                scaler = model.named_steps["scaler"]
                lasso = model.named_steps["lasso"]  # ===== ìˆ˜ì •: ridge -> lasso =====

                def _grp(feat: str) -> str:
                    """ë³€ìˆ˜ë¥¼ 4ê°œ ê·¸ë£¹(ì‚¬ì „ ë””ì§€í„¸/ì–¸ê¸‰, ì‹œì‚¬ì§€í‘œ, MPI, ë³´ì •)ìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜"""
                    f = str(feat)
                    if f.startswith("ì‹œì‚¬ì§€í‘œ_"):
                        return "ì‹œì‚¬ì§€í‘œ"
                    if f.startswith("MPI_"):
                        return "MPI"
                    # ì‚¬ì „ ë””ì§€í„¸/ì–¸ê¸‰: ì¡°íšŒ/ì–¸ê¸‰ + íŒŒìƒ(log1p_/slog_)
                    if f.startswith("log1p_") or f.startswith("slog_"):
                        return "ì‚¬ì „ ë””ì§€í„¸/ì–¸ê¸‰"
                    if ("ì¡°íšŒ" in f) or ("ì¡°íšŒìˆ˜" in f) or ("ì–¸ê¸‰" in f) or ("ì–¸ê¸‰ëŸ‰" in f):
                        return "ì‚¬ì „ ë””ì§€í„¸/ì–¸ê¸‰"
                    return "ë³´ì •"

                def _pretty_name(feat: str) -> str:
                    """ê°œë°œìí‹± ë³€ìˆ˜ëª…ì„ ì‚¬ìš©ì ì¹œí™” ë¼ë²¨ë¡œ ë³€í™˜(í‘œì‹œìš©)"""
                    f = str(feat)

                    # --- ì‹œì‚¬ì§€í‘œ ---
                    if f.startswith("ì‹œì‚¬ì§€í‘œ_"):
                        return f"ì‹œì‚¬: {f.replace('ì‹œì‚¬ì§€í‘œ_', '')}"

                    # --- MPI ---
                    if f.startswith("MPI_"):
                        s = f.replace("MPI_", "")
                        parts = s.split("_")
                        mpi_kind = parts[0] if parts else s
                        label_map = {"level": "ìˆ˜ì¤€", "mean": "í‰ê· ", "mom": "ìµœê·¼ë³€í™”", "slope": "ì¶”ì„¸"}
                        feat_type = None
                        for k in ["level", "mean", "mom", "slope"]:
                            if k in parts:
                                feat_type = k
                                break

                        week_txt = ""
                        if "W-6" in f and "W-1" in f and ("sum" in f or "mean" in f or "slope" in f):
                            week_txt = "(W-6~W-1)"
                        if "W-1_minus_W-3" in f:
                            week_txt = "(W-1 - W-3)"
                        elif "_W-1" in f:
                            week_txt = "(W-1)"

                        ft = label_map.get(feat_type, "ì§€í‘œ")
                        return f"MPI {mpi_kind}: {ft} {week_txt}".strip()

                    # --- ë³´ì •(ì»¤ë²„ë¦¬ì§€ ë“±) ---
                    if "week_coverage" in f:
                        base = f.replace("_week_coverage_", " ì£¼ì°¨ì»¤ë²„ë¦¬ì§€ ")
                        base = base.replace("_W-6_W-1", " (W-6~W-1)")
                        base = base.replace("_", " ")
                        return f"ë³´ì •: {base}"

                    # --- ì‚¬ì „ ë””ì§€í„¸/ì–¸ê¸‰ ---
                    def _pretty_common(s: str) -> str:
                        s = s.replace("_W-6_W-1", " (W-6~W-1)")
                        s = s.replace("_W-1_minus_W-3", " (W-1 - W-3)")
                        s = s.replace("_W-1", " (W-1)")
                        s = s.replace("_", " ")
                        s = s.replace("sum", "ì´ëŸ‰").replace("level", "ë§ˆì§€ë§‰ê°’").replace("mom", "ìµœê·¼ë³€í™”").replace("slope", "ì¶”ì„¸").replace("minus", "-")
                        return s

                    if f.startswith("log1p_"):
                        return f"ì‚¬ì „: {_pretty_common(f.replace('log1p_', ''))}"
                    if f.startswith("slog_"):
                        s = f.replace("slog_", "")
                        s = _pretty_common(s).replace("ì´ëŸ‰", "ì´ëŸ‰").replace("ë§ˆì§€ë§‰ê°’", "ë§ˆì§€ë§‰ê°’")
                        return f"ì‚¬ì „: {s}"

                    if ("ì¡°íšŒ" in f) or ("ì¡°íšŒìˆ˜" in f) or ("ì–¸ê¸‰" in f) or ("ì–¸ê¸‰ëŸ‰" in f):
                        return f"ì‚¬ì „: {_pretty_common(f)}"

                    return f

                x_scaled = scaler.transform(x_ip.values)[0]
                coefs = lasso.coef_  # ===== ìˆ˜ì •: ridge.coef_ -> lasso.coef_ =====
                contrib_vals = coefs * x_scaled

                contrib_df = pd.DataFrame({"feature": feature_cols, "contribution": contrib_vals})
                contrib_df["group"] = contrib_df["feature"].apply(_grp)
                contrib_df["pretty"] = contrib_df["feature"].apply(_pretty_name)

                # sort by absolute contribution (for display)
                contrib_df["_abs"] = contrib_df["contribution"].abs()
                contrib_df = contrib_df.sort_values("_abs", ascending=False).drop(columns=["_abs"])

                group_contrib_df = (
                    contrib_df.groupby("group")["contribution"]
                    .sum()
                    .reset_index()
                    .assign(_abs=lambda d: d["contribution"].abs())
                    .sort_values("_abs", ascending=False)
                    .drop(columns=["_abs"])
                )
            except Exception:
                contrib_df = None
                group_contrib_df = None


        meta = {
            "total_ip_cnt": total_ip_cnt,
            "target_ip_cnt": target_ip_cnt,
            "feature_ready_cnt": feature_any_cnt,
            "trainable_rows": int(trainable.shape[0]),
            "note": "ok_alltrain",
        }

        return all_df, mae, pred_ip_val, contrib_df, group_contrib_df, meta


    # =====================================================
    # ğŸ”® W+1(=1ì£¼ì°¨) í™”ì œì„±ì ìˆ˜ ì˜ˆì¸¡ â€” ì»·ì˜¤í”„ë³„ ë©€í‹°ëª¨ë¸(W-3/W-2/W-1)
    #   - íƒ€ê¹ƒì€ í•­ìƒ ë™ì¼: W+1(=1ì£¼ì°¨) í™”ì œì„±(F_Score)
    #   - ì…ë ¥ì€ ê°€ìš©í•œ ì‚¬ì „ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì£¼ì°¨(ì»·ì˜¤í”„)ì— ë§ì¶° 3ê°œ ëª¨ë¸ì„ ë³„ë„ í•™ìŠµ
    #   - ì‹ ê·œ IPëŠ” ë³´ìœ í•œ ìµœì‹  ì£¼ì°¨ì— ë§ëŠ” ëª¨ë¸ì„ ìë™ ì„ íƒ
    # =====================================================

    # --- sklearn (runtime dependency) ---
    try:
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import StandardScaler
        from sklearn.linear_model import Lasso  # ===== ìˆ˜ì •: Ridge -> Lasso =====
    except Exception as _e:
        raise ModuleNotFoundError(
            "scikit-learn is required for the multi-model predictor. "
            "Add 'scikit-learn' to requirements.txt and redeploy."
        ) from _e

    WEEK_ORDER = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1"]

    def _week_leq(week: str, cutoff: str) -> bool:
        if week not in WEEK_ORDER:
            return False
        return WEEK_ORDER.index(week) <= WEEK_ORDER.index(cutoff)

    def _detect_target_week(_df: pd.DataFrame) -> str:
        cand = ["W+1", "W1", "W 1", "W+01"]
        w = set(_df.loc[_df.get("metric") == "F_Score", "ì£¼ì°¨"].dropna().astype(str))
        for c in cand:
            if c in w:
                return c
        if len(w) == 0:
            return "W+1"
        return sorted(list(w))[-1]

    target_week = _detect_target_week(df_all)

    def _safe_num(s: pd.Series) -> pd.Series:
        return pd.to_numeric(s, errors="coerce").fillna(0)

    def _calc_slope(vals: list[float]) -> float:
        if vals is None or len(vals) < 2:
            return 0.0
        return (float(vals[-1]) - float(vals[0])) / float(len(vals) - 1)

    def _build_features_for_cutoff(_df: pd.DataFrame, cutoff: str) -> tuple[pd.DataFrame, list[str], str]:
        # 1) cutoff ì£¼ì°¨ê¹Œì§€ë§Œ ì‚¬ìš©
        sub = _df[_df["ì£¼ì°¨"].astype(str).apply(lambda w: _week_leq(str(w), cutoff))].copy()

        # 2) íƒ€ê¹ƒ(y): í•­ìƒ W+1(=1ì£¼ì°¨) í™”ì œì„±(F_Score)
        y_sub = _df[(_df.get("metric") == "F_Score") & (_df.get("ì£¼ì°¨").astype(str) == str(target_week))].copy()
        y_sub["y"] = pd.to_numeric(y_sub.get("value"), errors="coerce")
        y_ip = y_sub.groupby("IP")["y"].mean()

        # 3) ì‹œì‚¬ì§€í‘œ(í•­ëª©ë³„)
        sisa_keys = list(SISA_MAP.keys()) if "SISA_MAP" in globals() else []
        sisa = _df[_df.get("metric").isin(sisa_keys)].copy() if sisa_keys else pd.DataFrame(columns=["IP","metric","value"])
        if not sisa.empty:
            sisa["v"] = pd.to_numeric(sisa.get("value"), errors="coerce").fillna(0)
            sisa_wide = sisa.pivot_table(index="IP", columns="metric", values="v", aggfunc="mean").reset_index()
        else:
            sisa_wide = pd.DataFrame({"IP": _df["IP"].dropna().unique()})

        # 4) ì‹œê³„ì—´ ì§€í‘œ: (ì¡°íšŒìˆ˜/ì–¸ê¸‰ëŸ‰/MPI 3ì¢…) â†’ level/sum/mean/mom/slope
        ts_metrics = ["ì–¸ê¸‰ëŸ‰", "MPI_ì¸ì§€", "MPI_ì„ í˜¸", "MPI_ì‹œì²­ì˜í–¥"]

        frames = []

        # ì¡°íšŒìˆ˜: ê¸°ì¡´ ëŒ€ì‹œë³´ë“œ helperê°€ ìˆìœ¼ë©´ í™œìš©
        if "_get_view_data" in globals():
            try:
                v = _get_view_data(_df).copy()
                v = v[v["ì£¼ì°¨"].astype(str).apply(lambda w: _week_leq(str(w), cutoff))]
                v["val"] = pd.to_numeric(v.get("value"), errors="coerce").fillna(0)
                v["metric"] = "ì¡°íšŒìˆ˜"
                frames.append(v[["IP","ì£¼ì°¨","metric","val"]])
            except Exception:
                pass

        for m in ts_metrics:
            tmp = sub[sub.get("metric") == m].copy()
            if tmp.empty:
                continue
            tmp["val"] = pd.to_numeric(tmp.get("value"), errors="coerce").fillna(0)
            frames.append(tmp[["IP","ì£¼ì°¨","metric","val"]])

        ts = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=["IP","ì£¼ì°¨","metric","val"])

        feat_rows = []
        for ip, g in ts.groupby("IP"):
            row = {"IP": ip}
            for m, gm in g.groupby("metric"):
                wm = gm.set_index(gm["ì£¼ì°¨"].astype(str))["val"].to_dict()
                vals = [float(wm.get(w, 0.0)) for w in WEEK_ORDER if _week_leq(w, cutoff)]
                if len(vals) == 0:
                    continue
                last = vals[-1]
                first = vals[0]
                mean = float(sum(vals) / len(vals))
                sm = float(sum(vals))
                ref = vals[-3] if len(vals) >= 3 else first
                mom = float(last - ref)
                slope = _calc_slope(vals)

                if m in ["ì¡°íšŒìˆ˜", "ì–¸ê¸‰ëŸ‰"]:
                    row[f"ì‚¬ì „:{m}_ì´ëŸ‰(log)"] = float(np.log1p(sm))
                    row[f"ì‚¬ì „:{m}_ìˆ˜ì¤€({cutoff},log)"] = float(np.log1p(last))
                    row[f"ì‚¬ì „:{m}_ìµœê·¼ë³€í™”({cutoff},log)"] = float(np.sign(mom) * np.log1p(abs(mom)))
                    row[f"ì‚¬ì „:{m}_ì¶”ì„¸({cutoff})"] = float(slope)
                else:
                    row[f"{m}_ì´ëŸ‰"] = float(sm)
                    row[f"{m}_ìˆ˜ì¤€({cutoff})"] = float(last)
                    row[f"{m}_ìµœê·¼ë³€í™”({cutoff})"] = float(mom)
                    row[f"{m}_ì¶”ì„¸({cutoff})"] = float(slope)
            feat_rows.append(row)

        feat_df = pd.DataFrame(feat_rows) if feat_rows else pd.DataFrame(columns=["IP"])

        merged = sisa_wide.merge(feat_df, on="IP", how="left").fillna(0)
        merged["__y"] = merged["IP"].map(y_ip)
        target_col = "__y"
        feature_cols = [c for c in merged.columns if c not in ["IP", target_col]]
        return merged, feature_cols, target_col

    def _fit_predict_one(frame_df: pd.DataFrame, feature_cols: list[str], target_col: str, ip_pick: str | None):
        d = frame_df.copy()
        y = pd.to_numeric(d[target_col], errors="coerce")
        d = d[y.notna()].copy()
        y = pd.to_numeric(d[target_col], errors="coerce")

        if d.shape[0] < 12:
            return None, None, float("nan"), None

        X = d[feature_cols].apply(_safe_num)
        y_log = np.log1p(y.clip(lower=0))

        pipe = Pipeline([
            ("scaler", StandardScaler(with_mean=True, with_std=True)),
            ("lasso", Lasso(alpha=0.1, random_state=42)),  # ===== ìˆ˜ì •: Ridge -> Lasso, alpha 0.1 =====
        ])
        pipe.fit(X, y_log)

        pred = np.maximum(np.expm1(pipe.predict(X)), 0.0)

        yv = y.to_numpy(dtype=float)
        pe = np.where((yv != 0) & np.isfinite(yv), np.abs(pred - yv) / np.abs(yv) * 100.0, np.nan)
        mape = float(np.nanmean(pe)) if np.isfinite(pe).any() else float("nan")

        out = d[["IP", target_col]].copy()
        out["_pred"] = pred

        pred_ip = None
        if ip_pick is not None:
            r = frame_df[frame_df["IP"] == ip_pick]
            if not r.empty:
                Xp = r[feature_cols].apply(_safe_num)
                pred_ip = float(np.maximum(np.expm1(pipe.predict(Xp)[0]), 0.0))
        return out, pred_ip, mape, pipe

    # --- train 3 models ---
    preds = {}
    mapes = {}
    for cutoff in ["W-3", "W-2", "W-1"]:
        fr, feat_cols, tcol = _build_features_for_cutoff(df_all, cutoff=cutoff)
        p_df, p_ip, mape, _model = _fit_predict_one(fr, feat_cols, tcol, ip_pick=global_ip)
        preds[cutoff] = {"df": p_df, "ip": p_ip}
        mapes[cutoff] = mape

    def _has_week(ip: str, w: str) -> bool:
        try:
            # key metrics ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨
            sub = df_all[(df_all["IP"] == ip) & (df_all["ì£¼ì°¨"].astype(str) == str(w))].copy()
            sub = sub[sub.get("metric").isin(["ì–¸ê¸‰ëŸ‰", "MPI_ì¸ì§€", "MPI_ì„ í˜¸", "MPI_ì‹œì²­ì˜í–¥"])].copy()
            if not sub.empty:
                return True
            if "_get_view_data" in globals():
                v = _get_view_data(df_all)
                v = v[(v["IP"] == ip) & (v["ì£¼ì°¨"].astype(str) == str(w))]
                return not v.empty
            return False
        except Exception:
            return False

    chosen = None
    if _has_week(global_ip, "W-1"):
        chosen = "W-1"
    elif _has_week(global_ip, "W-2"):
        chosen = "W-2"
    elif _has_week(global_ip, "W-3"):
        chosen = "W-3"

    # actual value
    actual_val = None
    try:
        _a = df_all[(df_all.get("metric") == "F_Score") & (df_all.get("ì£¼ì°¨").astype(str) == str(target_week)) & (df_all.get("IP") == global_ip)].copy()
        if not _a.empty:
            _a["__v"] = pd.to_numeric(_a.get("value"), errors="coerce")
            if _a["__v"].notna().any():
                actual_val = float(_a["__v"].dropna().iloc[-1])
    except Exception:
        actual_val = None

    st.markdown(f"#### ğŸ”® 1ì£¼ì°¨({target_week}) í™”ì œì„±ì ìˆ˜ ì˜ˆì¸¡")

    if chosen is None:
        st.info("í˜„ì¬ ì‚¬ì „ ë°ì´í„°ê°€ ë¶€ì¡±í•´ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ W-3 ë°ì´í„° í•„ìš”)")
    elif preds.get(chosen, {}).get("ip") is None:
        st.info(f"ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•œ ë°©ì˜ì‘ í•™ìŠµ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ({target_week} í™”ì œì„± ë°ì´í„°ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤)")
    else:
        pred_val = float(preds[chosen]["ip"])
        mape_val = mapes.get(chosen, float("nan"))
        mape_text = f"{mape_val:.1f}%" if np.isfinite(mape_val) else "-"

        st.markdown(f"""
        <div class="kpi-card" style="padding:16px 14px;">
            <div class="kpi-title">ì˜ˆì¸¡ í™”ì œì„±ì ìˆ˜ ({target_week})</div>
            <div class="kpi-value" style="font-size:34px; margin-top:6px;">{pred_val:,.0f}</div>
            <div style="color:#111827; font-size:13px; margin-top:8px;">
                ì‹¤ì œ í™”ì œì„±ì ìˆ˜ ({target_week}): <b>{(f"{actual_val:,.0f}" if actual_val is not None else "ë°©ì˜ì „ì…ë‹ˆë‹¤")}</b>
            </div>
            <div style="color:#6b7280; font-size:12.5px; margin-top:6px; line-height:1.35;">
                ì‚¬ì „ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì£¼ì°¨(ì»·ì˜¤í”„)ì— ë§ì¶° í•™ìŠµëœ ëª¨ë¸ë¡œ 1ì£¼ì°¨ í™”ì œì„±ì ìˆ˜ë¥¼ ì¶”ì •í–ˆìŠµë‹ˆë‹¤.<br/>
                <b>ì ìš© ëª¨ë¸:</b> {chosen} ê¸°ë°˜ Â· <b>í‰ê· ì˜¤ì°¨ìœ¨:</b> {mape_text}<br/>
                ë°ì´í„°ê°€ ëˆ„ì ë˜ë©´(ì˜ˆ: W-2 â†’ W-1) ë” ë§ì€ ì •ë³´ë¥¼ ë°˜ì˜í•œ ëª¨ë¸ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.
            </div>
        </div>
        """, unsafe_allow_html=True)

    with st.expander("âœ… ì˜ˆì¸¡ ì •í™•ë„(ë°©ì˜ì‘ ê²€ì¦)", expanded=False):
        y_all = df_all[(df_all.get("metric") == "F_Score") & (df_all.get("ì£¼ì°¨").astype(str) == str(target_week))].copy()
        y_all["y"] = pd.to_numeric(y_all.get("value"), errors="coerce")
        y_ip = y_all.groupby("IP")["y"].mean().dropna()
        if y_ip.empty:
            st.info("ê²€ì¦ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            acc = pd.DataFrame({"IP": y_ip.index, "ì‹¤ì œ": y_ip.values})

            def _attach_pred(colname: str, cutoff: str):
                pdf = preds.get(cutoff, {}).get("df")
                if pdf is None or pdf.empty:
                    acc[colname] = np.nan
                    return
                m = pdf.set_index("IP")["_pred"]
                acc[colname] = acc["IP"].map(m)

            _attach_pred("W-3ê¸°ë°˜ì˜ˆì¸¡", "W-3")
            _attach_pred("W-2ê¸°ë°˜ì˜ˆì¸¡", "W-2")
            _attach_pred("W-1ê¸°ë°˜ì˜ˆì¸¡(ìµœì¢…)", "W-1")

            # ===== [ìˆ˜ì • 4] ì˜¤ì°¨ìœ¨ ë°©í–¥(+/-) í‘œê¸°ë¥¼ ìœ„í•´ ë¶„ì ë¶€ë¶„ì˜ abs() ì œê±° =====
            def _err_pct(p, a):
                if pd.isna(p) or pd.isna(a) or a == 0:
                    return np.nan
                return (p - a) / abs(a) * 100.0

            acc["ì˜¤ì°¨"] = np.nan  # placeholder

            acc["ì˜¤ì°¨(W-3)"] = [ _err_pct(p,a) for p,a in zip(acc["W-3ê¸°ë°˜ì˜ˆì¸¡"], acc["ì‹¤ì œ"]) ]
            acc["ì˜¤ì°¨(W-2)"] = [ _err_pct(p,a) for p,a in zip(acc["W-2ê¸°ë°˜ì˜ˆì¸¡"], acc["ì‹¤ì œ"]) ]
            acc["ì˜¤ì°¨(W-1)"] = [ _err_pct(p,a) for p,a in zip(acc["W-1ê¸°ë°˜ì˜ˆì¸¡(ìµœì¢…)"], acc["ì‹¤ì œ"]) ]

            for c in ["W-3ê¸°ë°˜ì˜ˆì¸¡","W-2ê¸°ë°˜ì˜ˆì¸¡","W-1ê¸°ë°˜ì˜ˆì¸¡(ìµœì¢…)","ì‹¤ì œ"]:
                acc[c] = pd.to_numeric(acc[c], errors="coerce").round(0)

            # ===== [ìˆ˜ì • 3] ì˜ˆì¸¡ê°’ê³¼ ì˜¤ì°¨ìœ¨ì„ ê²°í•©í•˜ì—¬ ì§ê´€ì ì¸ í…ìŠ¤íŠ¸ ìƒì„± =====
            def _combine_pred_err(pred, err):
                if pd.isna(pred): return "-"
                p_str = f"{int(pred):,}"
                if pd.isna(err): return p_str
                sign = "+" if err > 0 else ""
                return f"{p_str} ({sign}{err:.1f}%)"

            acc["W-1 ì˜ˆì¸¡(ì˜¤ì°¨)"] = [ _combine_pred_err(p, e) for p, e in zip(acc["W-1ê¸°ë°˜ì˜ˆì¸¡(ìµœì¢…)"], acc["ì˜¤ì°¨(W-1)"]) ]
            acc["W-2 ì˜ˆì¸¡(ì˜¤ì°¨)"] = [ _combine_pred_err(p, e) for p, e in zip(acc["W-2ê¸°ë°˜ì˜ˆì¸¡"], acc["ì˜¤ì°¨(W-2)"]) ]
            acc["W-3 ì˜ˆì¸¡(ì˜¤ì°¨)"] = [ _combine_pred_err(p, e) for p, e in zip(acc["W-3ê¸°ë°˜ì˜ˆì¸¡"], acc["ì˜¤ì°¨(W-3)"]) ]

            # ===== [ìˆ˜ì • 2] W-1ì´ ê°€ì¥ ë¨¼ì € ì˜¤ë„ë¡ ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì¹˜ =====
            grid = acc[["IP", "ì‹¤ì œ", "W-1 ì˜ˆì¸¡(ì˜¤ì°¨)", "W-2 ì˜ˆì¸¡(ì˜¤ì°¨)", "W-3 ì˜ˆì¸¡(ì˜¤ì°¨)"]].copy()

            # Formatter: ì‹¤ì œê°’ ìˆ«ì í¬ë§·íŒ…
            fmt_int = JsCode("""
                function(params){
                    if (params.value === null || params.value === undefined || params.value === '' || isNaN(params.value)) return '-';
                    return Math.round(params.value).toLocaleString();
                }
            """)
            right_align = JsCode("""function(params){ return {'textAlign':'right'}; }""")
            actual_style = JsCode("""function(params){ return {'backgroundColor':'#FFF2CC','fontWeight':'700','textAlign':'right'}; }""")

            # ì‹¬í”Œí•´ì§„ ì»¬ëŸ¼ ì •ì˜ (flex ì†ì„±ì„ ì¶”ê°€í•˜ì—¬ ë‚¨ëŠ” ê³µê°„ì„ ë¹„ìœ¨ëŒ€ë¡œ ê½‰ ì±„ì›€)
            column_defs = [
                {"headerName": "IP", "field": "IP", "pinned": "left", "flex": 1.5},
                {"headerName": "ì‹¤ì œ í™”ì œì„±(W1)", "field": "ì‹¤ì œ", "flex": 1, "valueFormatter": fmt_int, "cellStyle": actual_style},
                {"headerName": "W-1 ì˜ˆì¸¡(ì˜¤ì°¨)", "field": "W-1 ì˜ˆì¸¡(ì˜¤ì°¨)", "flex": 1, "cellStyle": right_align},
                {"headerName": "W-2 ì˜ˆì¸¡(ì˜¤ì°¨)", "field": "W-2 ì˜ˆì¸¡(ì˜¤ì°¨)", "flex": 1, "cellStyle": right_align},
                {"headerName": "W-3 ì˜ˆì¸¡(ì˜¤ì°¨)", "field": "W-3 ì˜ˆì¸¡(ì˜¤ì°¨)", "flex": 1, "cellStyle": right_align},
            ]

            gb_val = GridOptionsBuilder.from_dataframe(grid)
            gb_val.configure_default_column(resizable=True, sortable=True, filter=True)
            gb_val.configure_grid_options(domLayout="normal", suppressDragLeaveHidesColumns=True)
            
            grid_options = gb_val.build()
            grid_options["columnDefs"] = column_defs

            AgGrid(
                grid,
                gridOptions=grid_options,
                height=420,
                fit_columns_on_grid_load=True, # ===== [ìˆ˜ì • 1] ì—´ ë„ˆë¹„ ê½‰ì°¨ê²Œ ì„¤ì • =====
                allow_unsafe_jscode=True,
                update_mode=GridUpdateMode.NO_UPDATE,
                theme="alpine",
            )
    st.divider()

    # --- 8. [ìµœì¢… ìˆ˜ì •] ì „ì²´ IP ì‚¬ì „ì§€í‘œ ì¢…í•© í…Œì´ë¸” (AgGrid) ---
    st.markdown("#### ğŸ“‹ ì „ì²´ IP ì‚¬ì „ì§€í‘œ ì¢…í•© í˜„í™©")
    
    # 1) ë°ì´í„° ì§‘ê³„ í•¨ìˆ˜
    def calculate_pre_performance(df):
        all_unique_ips = df["IP"].unique()
        if len(all_unique_ips) == 0: return pd.DataFrame(), []

        # (1) ë””ì§€í„¸ í•©ê³„
        target_weeks_dig = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1"]
        
        v_sub = _get_view_data(df)
        v_sub = v_sub[v_sub["ì£¼ì°¨"].isin(target_weeks_dig)]
        v_sub["val"] = pd.to_numeric(v_sub["value"], errors="coerce").fillna(0)
        view_sum = v_sub.groupby("IP")["val"].sum()

        b_sub = df[(df["metric"] == "ì–¸ê¸‰ëŸ‰") & (df["ì£¼ì°¨"].isin(target_weeks_dig))].copy()
        b_sub["val"] = pd.to_numeric(b_sub["value"], errors="coerce").fillna(0)
        buzz_sum = b_sub.groupby("IP")["val"].sum()

        # (2) ì‹œì‚¬ì§€í‘œ í•©ì‚°
        sisa_keys = list(SISA_MAP.keys())
        s_sub = df[df["metric"].isin(sisa_keys)].copy()
        s_sub["val"] = pd.to_numeric(s_sub["value"], errors="coerce").fillna(0)
        sisa_total = s_sub.groupby("IP")["val"].sum()

        # (3) MPI ì¸ì§€ë„ ì£¼ì°¨ë³„ (Pivot)
        m_sub = df[df["metric"] == "MPI_ì¸ì§€"].copy()
        m_sub["val"] = pd.to_numeric(m_sub["value"], errors="coerce")
        
        mpi_pivot = m_sub.pivot_table(index="IP", columns="ì£¼ì°¨", values="val", aggfunc="mean")
        
        desired_mpi_weeks = ["W-6", "W-5", "W-4", "W-3", "W-2", "W-1", "W+1", "W+2"]
        available_cols = [c for c in desired_mpi_weeks if c in mpi_pivot.columns]
        mpi_pivot = mpi_pivot[available_cols] 
        
        # [ì¤‘ìš”] ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ëª…ì„ 'MPIì¸ì§€ë„_W-n' í˜•ì‹ìœ¼ë¡œ ìƒì„±
        mpi_pivot.columns = [f"MPIì¸ì§€ë„_{c}" for c in mpi_pivot.columns]

        # 4) ì „ì²´ ë³‘í•©
        base_df = pd.DataFrame({
            "ì‹œì‚¬í•©ê³„": sisa_total,
            "ì‚¬ì „ì¡°íšŒìˆ˜": view_sum,
            "ì‚¬ì „ì–¸ê¸‰ëŸ‰": buzz_sum
        })
        
        merged = base_df.join(mpi_pivot, how="outer").reindex(all_unique_ips).fillna(0)
        mpi_cols = list(mpi_pivot.columns)
        
        return merged.reset_index().rename(columns={"index": "IP"}), mpi_cols

    # 2) í…Œì´ë¸” ë°ì´í„° ìƒì„±
    df_pre_perf, mpi_columns = calculate_pre_performance(df_all)

    # 3) AgGrid ì„¤ì •
    fmt_thousands = JsCode("""function(params){ if(params.value==null||isNaN(params.value))return '-'; return Math.round(params.value).toLocaleString(); }""")
    fmt_fixed1 = JsCode("""function(params){ if(params.value==null||isNaN(params.value)||params.value==0)return '-'; return Number(params.value).toFixed(1); }""")

    highlight_jscode = JsCode(f"""
    function(params) {{
        if (params.data.IP === '{global_ip}') {{
            return {{
                'background-color': '#fffde7',
                'font-weight': 'bold',
                'border-left': '5px solid #d93636'
            }};
        }}
        return {{}};
    }}
    """)

    gb = GridOptionsBuilder.from_dataframe(df_pre_perf)
    gb.configure_default_column(
        sortable=True, resizable=True, filter=False,
        cellStyle={'textAlign': 'center'},
        headerClass='centered-header'
    )
    gb.configure_grid_options(
        rowHeight=34, 
        suppressMenuHide=True, 
        domLayout='normal',
        getRowStyle=highlight_jscode 
    )
    
    # [ê·¸ë£¹í•‘ ì»¬ëŸ¼ ì •ì˜]
    custom_defs = [
        { "headerName": "IP", "field": "IP", "pinned": "left", "width": 140, "cellStyle": {'textAlign': 'left'} },
        { "headerName": "ì‹œì‚¬ì§€í‘œ(í•©)", "field": "ì‹œì‚¬í•©ê³„", "valueFormatter": fmt_fixed1, "width": 90 },
        { "headerName": "ì‚¬ì „ ì¡°íšŒìˆ˜", "field": "ì‚¬ì „ì¡°íšŒìˆ˜", "valueFormatter": fmt_thousands, "width": 100 },
        { "headerName": "ì‚¬ì „ ì–¸ê¸‰ëŸ‰", "field": "ì‚¬ì „ì–¸ê¸‰ëŸ‰", "valueFormatter": fmt_thousands, "width": 100 }
    ]

    # MPI ê·¸ë£¹ ìƒì„± (children)
    mpi_children = []
    for col in mpi_columns:
        # [í•µì‹¬ ìˆ˜ì •] ë°ì´í„° ì»¬ëŸ¼ëª…(MPIì¸ì§€ë„_W-6)ì—ì„œ ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•˜ì—¬ í—¤ë”ëª…(W-6) ìƒì„±
        clean_header = col.replace("MPIì¸ì§€ë„_", "")
        
        mpi_children.append({
            "headerName": clean_header, 
            "field": col,
            "valueFormatter": fmt_fixed1,
            "width": 60, 
            "cellStyle": {'textAlign': 'center'}
        })

    if mpi_children:
        custom_defs.append({
            "headerName": "MPI ì¸ì§€ë„", # ìƒìœ„ ê·¸ë£¹ í—¤ë”
            "children": mpi_children,   # í•˜ìœ„ ì»¬ëŸ¼ë“¤ (W-6, W-5...)
            "headerClass": "centered-header"
        })

    grid_options = gb.build()
    grid_options['columnDefs'] = custom_defs

    AgGrid(
        df_pre_perf,
        gridOptions=grid_options,
        theme="streamlit",
        height=400,
        fit_columns_on_grid_load=True, 
        update_mode=GridUpdateMode.NO_UPDATE,
        allow_unsafe_jscode=True
    )
    
# =====================================================
#endregion

#region [ 7. ë¼ìš°í„° / ì—”íŠ¸ë¦¬ ]
if st.session_state["page"] == "Overview":
    render_overview() # [ 7. í˜ì´ì§€ 1 ]
elif st.session_state["page"] == "IP ì„±ê³¼":
    render_ip_detail() # [ 8. í˜ì´ì§€ 2 ]
elif st.session_state["page"] == "ì‚¬ì „ì§€í‘œ": 
    render_pre_launch_analysis()
elif st.session_state["page"] == "ë¹„êµë¶„ì„":
    render_comparison() # [ 10. í˜ì´ì§€ 4 ]
elif st.session_state["page"] == "ì„±ì¥ìŠ¤ì½”ì–´":
    render_growth_score() # [ 10. í˜ì´ì§€ 5 (í†µí•©ë¨) ]
else:
    render_overview() # ê¸°ë³¸ê°’ìœ¼ë¡œ Overview ë Œë”ë§
    #endregion